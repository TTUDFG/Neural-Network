{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0bcd5cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.autograd import Variable\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "11838ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1\n",
    "# Get the image and change every image to an 256-dimention vector\n",
    "dataSet = np.zeros([10, 256])\n",
    "for i in range(0, 10):\n",
    "    inputImageDir = './input/' + str(i) + '.png'\n",
    "    inputImage = Image.open(inputImageDir)\n",
    "    inputImage = inputImage.convert(\"1\")\n",
    "    inputImage.save(inputImageDir)\n",
    "    data = inputImage.getdata()\n",
    "    array = np.array(data)/255\n",
    "    dataSet[i] = array\n",
    "dataSet = np.array(dataSet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f1478743",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2\n",
    "# define a neural network\n",
    "class Perceptron(nn.Module):\n",
    "\n",
    "    def __init__(self, input_size, num_hidden, num_classes):\n",
    "        super(Perceptron, self).__init__()\n",
    "        self.inputlayer = nn.Linear(input_size, num_hidden)\n",
    "        self.hiddenlayer = nn.Linear(num_hidden, num_hidden)\n",
    "        self.outputlayer = nn.Linear(num_hidden, num_classes)\n",
    "        self.activate = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        res = self.inputlayer(x)\n",
    "        res = self.activate(res)\n",
    "        res = self.hiddenlayer(x)\n",
    "        res = self.activate(res)\n",
    "        res = self.outputlayer(x)\n",
    "        res = self.activate(res)\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "634a9eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DigitDataset(Dataset):\n",
    "    def __init__(self, dataset, label_list):\n",
    "        self.dataset = dataset\n",
    "        self.label_list = label_list\n",
    "    def __len__(self):\n",
    "        return len(self.label_list)\n",
    "    def __getitem__(self, idx):\n",
    "        data = self.dataset[idx]\n",
    "        label = self.label_list[idx]\n",
    "        return {\n",
    "            'data': torch.from_numpy(data).float(),\n",
    "            'label': torch.from_numpy(label).float()\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "fc25a099",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters of training\n",
    "input_size = 256\n",
    "num_classes = 256\n",
    "num_hidden = 256\n",
    "learning_rate = 0.001\n",
    "batch_size = 10\n",
    "num_epochs = 600\n",
    "\n",
    "# Load the dataset\n",
    "train_dataset = DigitDataset(dataset = dataSet, label_list = dataSet)\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=False)\n",
    "device = torch.device('cpu')\n",
    "model = Perceptron(input_size=input_size, num_hidden=num_hidden, num_classes=num_classes).to(device)\n",
    "\n",
    "if not os.path.exists('./models'):\n",
    "    os.mkdir('./models')\n",
    "torch.save(model, './models/net_untrained.pkl')\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "452b7bfa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0/600] Loss: 0.2706 MAE: 0.5050 Mean Error: 0.4222 STD: 0.3040\n",
      "[10/600] Loss: 0.0444 MAE: 0.1608 Mean Error: 0.0989 STD: 0.1861\n",
      "[20/600] Loss: 0.0306 MAE: 0.0921 Mean Error: 0.0352 STD: 0.1715\n",
      "[30/600] Loss: 0.0280 MAE: 0.0785 Mean Error: 0.0208 STD: 0.1660\n",
      "[40/600] Loss: 0.0262 MAE: 0.0735 Mean Error: 0.0170 STD: 0.1611\n",
      "[50/600] Loss: 0.0247 MAE: 0.0707 Mean Error: 0.0148 STD: 0.1566\n",
      "[60/600] Loss: 0.0233 MAE: 0.0688 Mean Error: 0.0136 STD: 0.1522\n",
      "[70/600] Loss: 0.0220 MAE: 0.0674 Mean Error: 0.0130 STD: 0.1479\n",
      "[80/600] Loss: 0.0208 MAE: 0.0656 Mean Error: 0.0125 STD: 0.1438\n",
      "[90/600] Loss: 0.0197 MAE: 0.0639 Mean Error: 0.0124 STD: 0.1398\n",
      "[100/600] Loss: 0.0186 MAE: 0.0624 Mean Error: 0.0121 STD: 0.1359\n",
      "[110/600] Loss: 0.0176 MAE: 0.0608 Mean Error: 0.0118 STD: 0.1321\n",
      "[120/600] Loss: 0.0166 MAE: 0.0592 Mean Error: 0.0116 STD: 0.1285\n",
      "[130/600] Loss: 0.0157 MAE: 0.0576 Mean Error: 0.0113 STD: 0.1250\n",
      "[140/600] Loss: 0.0149 MAE: 0.0561 Mean Error: 0.0110 STD: 0.1216\n",
      "[150/600] Loss: 0.0141 MAE: 0.0547 Mean Error: 0.0108 STD: 0.1183\n",
      "[160/600] Loss: 0.0134 MAE: 0.0532 Mean Error: 0.0106 STD: 0.1151\n",
      "[170/600] Loss: 0.0127 MAE: 0.0519 Mean Error: 0.0103 STD: 0.1121\n",
      "[180/600] Loss: 0.0120 MAE: 0.0505 Mean Error: 0.0101 STD: 0.1091\n",
      "[190/600] Loss: 0.0114 MAE: 0.0493 Mean Error: 0.0099 STD: 0.1063\n",
      "[200/600] Loss: 0.0108 MAE: 0.0480 Mean Error: 0.0097 STD: 0.1036\n",
      "[210/600] Loss: 0.0103 MAE: 0.0468 Mean Error: 0.0095 STD: 0.1009\n",
      "[220/600] Loss: 0.0098 MAE: 0.0457 Mean Error: 0.0093 STD: 0.0984\n",
      "[230/600] Loss: 0.0093 MAE: 0.0446 Mean Error: 0.0091 STD: 0.0960\n",
      "[240/600] Loss: 0.0089 MAE: 0.0435 Mean Error: 0.0089 STD: 0.0937\n",
      "[250/600] Loss: 0.0084 MAE: 0.0425 Mean Error: 0.0088 STD: 0.0915\n",
      "[260/600] Loss: 0.0081 MAE: 0.0415 Mean Error: 0.0086 STD: 0.0894\n",
      "[270/600] Loss: 0.0077 MAE: 0.0406 Mean Error: 0.0084 STD: 0.0874\n",
      "[280/600] Loss: 0.0074 MAE: 0.0397 Mean Error: 0.0083 STD: 0.0854\n",
      "[290/600] Loss: 0.0070 MAE: 0.0388 Mean Error: 0.0081 STD: 0.0835\n",
      "[300/600] Loss: 0.0067 MAE: 0.0380 Mean Error: 0.0079 STD: 0.0817\n",
      "[310/600] Loss: 0.0065 MAE: 0.0371 Mean Error: 0.0078 STD: 0.0800\n",
      "[320/600] Loss: 0.0062 MAE: 0.0364 Mean Error: 0.0077 STD: 0.0783\n",
      "[330/600] Loss: 0.0059 MAE: 0.0356 Mean Error: 0.0075 STD: 0.0767\n",
      "[340/600] Loss: 0.0057 MAE: 0.0349 Mean Error: 0.0074 STD: 0.0752\n",
      "[350/600] Loss: 0.0055 MAE: 0.0342 Mean Error: 0.0073 STD: 0.0737\n",
      "[360/600] Loss: 0.0053 MAE: 0.0336 Mean Error: 0.0071 STD: 0.0723\n",
      "[370/600] Loss: 0.0051 MAE: 0.0329 Mean Error: 0.0070 STD: 0.0709\n",
      "[380/600] Loss: 0.0049 MAE: 0.0323 Mean Error: 0.0069 STD: 0.0696\n",
      "[390/600] Loss: 0.0047 MAE: 0.0317 Mean Error: 0.0068 STD: 0.0683\n",
      "[400/600] Loss: 0.0045 MAE: 0.0312 Mean Error: 0.0067 STD: 0.0670\n",
      "[410/600] Loss: 0.0044 MAE: 0.0306 Mean Error: 0.0066 STD: 0.0659\n",
      "[420/600] Loss: 0.0042 MAE: 0.0301 Mean Error: 0.0065 STD: 0.0647\n",
      "[430/600] Loss: 0.0041 MAE: 0.0295 Mean Error: 0.0064 STD: 0.0636\n",
      "[440/600] Loss: 0.0039 MAE: 0.0291 Mean Error: 0.0063 STD: 0.0625\n",
      "[450/600] Loss: 0.0038 MAE: 0.0286 Mean Error: 0.0062 STD: 0.0615\n",
      "[460/600] Loss: 0.0037 MAE: 0.0281 Mean Error: 0.0061 STD: 0.0604\n",
      "[470/600] Loss: 0.0036 MAE: 0.0276 Mean Error: 0.0060 STD: 0.0595\n",
      "[480/600] Loss: 0.0035 MAE: 0.0272 Mean Error: 0.0059 STD: 0.0585\n",
      "[490/600] Loss: 0.0033 MAE: 0.0268 Mean Error: 0.0059 STD: 0.0576\n",
      "[500/600] Loss: 0.0032 MAE: 0.0264 Mean Error: 0.0058 STD: 0.0567\n",
      "[510/600] Loss: 0.0031 MAE: 0.0260 Mean Error: 0.0057 STD: 0.0558\n",
      "[520/600] Loss: 0.0031 MAE: 0.0256 Mean Error: 0.0056 STD: 0.0550\n",
      "[530/600] Loss: 0.0030 MAE: 0.0252 Mean Error: 0.0056 STD: 0.0542\n",
      "[540/600] Loss: 0.0029 MAE: 0.0248 Mean Error: 0.0055 STD: 0.0534\n",
      "[550/600] Loss: 0.0028 MAE: 0.0245 Mean Error: 0.0054 STD: 0.0526\n",
      "[560/600] Loss: 0.0027 MAE: 0.0241 Mean Error: 0.0054 STD: 0.0518\n",
      "[570/600] Loss: 0.0026 MAE: 0.0238 Mean Error: 0.0053 STD: 0.0511\n",
      "[580/600] Loss: 0.0026 MAE: 0.0235 Mean Error: 0.0052 STD: 0.0504\n",
      "[590/600] Loss: 0.0025 MAE: 0.0232 Mean Error: 0.0052 STD: 0.0497\n",
      "[599/600] Loss: 0.0024 MAE: 0.0229 Mean Error: 0.0051 STD: 0.0491\n"
     ]
    }
   ],
   "source": [
    "# Step 3\n",
    "def train(dataloader, model, num_epochs):\n",
    "    for epoch in range(num_epochs):\n",
    "        losses = []\n",
    "        ERROR_Train = [] \n",
    "        model.train() \n",
    "        for i, data in enumerate(dataloader, 0):\n",
    "            model.zero_grad()\n",
    "            real_cpu, label_cpu = data['data'], data['label']\n",
    "#             if torch.cuda.is_available():\n",
    "#                 real_cpu = real_cpu.cuda() \n",
    "#                 label_cpu = label_cpu.cuda()\n",
    "            real = real_cpu\n",
    "            label = label_cpu\n",
    "            inputv = Variable(real)\n",
    "            labelv = Variable(label)\n",
    "            output = model(inputv)\n",
    "            err = criterion(output, labelv) \n",
    "            err.backward() \n",
    "            optimizer.step() \n",
    "\n",
    "            losses.append(err.data.item())\n",
    "            error = label - output.data\n",
    "#             print(output.data)\n",
    "#             print(error)\n",
    "#             print(error.shape)\n",
    "            ERROR_Train.extend(error)\n",
    "        MAE = torch.mean(torch.abs(torch.stack(ERROR_Train)))\n",
    "        ME = torch.mean(torch.stack(ERROR_Train))\n",
    "        STD = torch.std(torch.stack(ERROR_Train)) \n",
    "        if epoch % 10 == 0 or epoch == num_epochs - 1:\n",
    "            print('[%d/%d] Loss: %.4f MAE: %.4f Mean Error: %.4f STD: %.4f' % (epoch, num_epochs, np.average(losses), MAE, ME, STD))\n",
    "            \n",
    "    return output, model\n",
    "\n",
    "# Start training        \n",
    "output, model = train(train_loader, model, num_epochs)\n",
    "# print(output.type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b9f4d3d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 256)\n"
     ]
    }
   ],
   "source": [
    "# Step 4\n",
    "# Step 4a\n",
    "# Export the image after training\n",
    "# Before executing this block, create a folder called \"output\"\n",
    "if not os.path.exists('./output'):\n",
    "    os.mkdir('./output')\n",
    "output_np = output.detach().numpy()\n",
    "print(output_np.shape)\n",
    "torch.save(model, './models/net_trained.pkl')\n",
    "output_dataset = np.zeros([10, 256])\n",
    "for i in range(10):\n",
    "    output_img = output_np[i].reshape(16, 16)*255\n",
    "    img = Image.fromarray(np.uint8(output_img))\n",
    "    img = img.convert(\"1\")\n",
    "    output_path = './output/' + str(i) + '.png'\n",
    "    img.save(output_path)\n",
    "    data = img.getdata()\n",
    "    array = np.array(data)/255\n",
    "    output_dataset[i] = array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b891b3a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4b\n",
    "# Calculate Fh\n",
    "def calculateFh(input_dataset, output_dataset):\n",
    "    x, y = input_dataset.shape\n",
    "    Fh_denominator = 0    # Fh分母\n",
    "    Fh_numerator = 0      # Fh分子\n",
    "    Fh_array = np.zeros([x])\n",
    "    for j in range(x):\n",
    "        for i in range(y):\n",
    "            if input_dataset[j][i] == 0:\n",
    "                Fh_denominator = Fh_denominator + 1\n",
    "                if output_dataset[j][i] == 0:\n",
    "                    Fh_numerator = Fh_numerator + 1\n",
    "        Fh = Fh_numerator / Fh_denominator\n",
    "        Fh_array[j] = Fh\n",
    "    return Fh_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3acfb30f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Ffa\n",
    "def calculateFfa(input_dataset, output_dataset):\n",
    "    x, y = input_dataset.shape\n",
    "    Ffa_denominator = 0    # Ffa分母\n",
    "    Ffa_numerator = 0      # Ffa分子\n",
    "    Ffa_array = np.zeros([x])\n",
    "    for j in range(x):\n",
    "        for i in range(y):\n",
    "            if input_dataset[j][i] == 1:\n",
    "                Ffa_denominator = Ffa_denominator + 1\n",
    "            if output_dataset[j][i] == 0 and input_dataset[j][i] == 1:\n",
    "                Ffa_numerator = Ffa_numerator + 1\n",
    "        Ffa = Ffa_numerator / Ffa_denominator\n",
    "        Ffa_array[j] = Ffa\n",
    "    return Ffa_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "41d276af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "[0.         0.         0.         0.0010627  0.00085106 0.00071073\n",
      " 0.0006105  0.0005322  0.00047438 0.00042753]\n"
     ]
    }
   ],
   "source": [
    "Fh_array = calculateFh(dataSet, output_dataset)\n",
    "Ffa_array = calculateFfa(dataSet, output_dataset)\n",
    "print(Fh_array)\n",
    "print(Ffa_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "097f693d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Step 4c: Graph Fh as a function of Ffa for each exemplar in the input dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "01286dec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset with noise standard deviation 0.001\n",
      "[0/600] Loss: 0.2700 MAE: 0.5024 Mean Error: 0.4180 STD: 0.3087\n",
      "[10/600] Loss: 0.0439 MAE: 0.1596 Mean Error: 0.0982 STD: 0.1852\n",
      "[20/600] Loss: 0.0305 MAE: 0.0914 Mean Error: 0.0328 STD: 0.1714\n",
      "[30/600] Loss: 0.0279 MAE: 0.0776 Mean Error: 0.0198 STD: 0.1660\n",
      "[40/600] Loss: 0.0261 MAE: 0.0732 Mean Error: 0.0168 STD: 0.1608\n",
      "[50/600] Loss: 0.0246 MAE: 0.0713 Mean Error: 0.0145 STD: 0.1563\n",
      "[60/600] Loss: 0.0233 MAE: 0.0691 Mean Error: 0.0134 STD: 0.1520\n",
      "[70/600] Loss: 0.0220 MAE: 0.0672 Mean Error: 0.0132 STD: 0.1478\n",
      "[80/600] Loss: 0.0208 MAE: 0.0657 Mean Error: 0.0128 STD: 0.1437\n",
      "[90/600] Loss: 0.0197 MAE: 0.0641 Mean Error: 0.0125 STD: 0.1398\n",
      "[100/600] Loss: 0.0186 MAE: 0.0624 Mean Error: 0.0121 STD: 0.1360\n",
      "[110/600] Loss: 0.0176 MAE: 0.0608 Mean Error: 0.0119 STD: 0.1323\n",
      "[120/600] Loss: 0.0167 MAE: 0.0592 Mean Error: 0.0116 STD: 0.1287\n",
      "[130/600] Loss: 0.0158 MAE: 0.0577 Mean Error: 0.0114 STD: 0.1253\n",
      "[140/600] Loss: 0.0150 MAE: 0.0562 Mean Error: 0.0111 STD: 0.1220\n",
      "[150/600] Loss: 0.0142 MAE: 0.0547 Mean Error: 0.0109 STD: 0.1188\n",
      "[160/600] Loss: 0.0135 MAE: 0.0533 Mean Error: 0.0106 STD: 0.1157\n",
      "[170/600] Loss: 0.0128 MAE: 0.0520 Mean Error: 0.0104 STD: 0.1127\n",
      "[180/600] Loss: 0.0122 MAE: 0.0507 Mean Error: 0.0102 STD: 0.1099\n",
      "[190/600] Loss: 0.0116 MAE: 0.0494 Mean Error: 0.0099 STD: 0.1071\n",
      "[200/600] Loss: 0.0110 MAE: 0.0482 Mean Error: 0.0097 STD: 0.1045\n",
      "[210/600] Loss: 0.0105 MAE: 0.0470 Mean Error: 0.0095 STD: 0.1019\n",
      "[220/600] Loss: 0.0100 MAE: 0.0459 Mean Error: 0.0093 STD: 0.0995\n",
      "[230/600] Loss: 0.0095 MAE: 0.0448 Mean Error: 0.0091 STD: 0.0971\n",
      "[240/600] Loss: 0.0091 MAE: 0.0438 Mean Error: 0.0089 STD: 0.0948\n",
      "[250/600] Loss: 0.0087 MAE: 0.0427 Mean Error: 0.0087 STD: 0.0927\n",
      "[260/600] Loss: 0.0083 MAE: 0.0418 Mean Error: 0.0085 STD: 0.0906\n",
      "[270/600] Loss: 0.0079 MAE: 0.0408 Mean Error: 0.0084 STD: 0.0886\n",
      "[280/600] Loss: 0.0076 MAE: 0.0400 Mean Error: 0.0082 STD: 0.0866\n",
      "[290/600] Loss: 0.0072 MAE: 0.0391 Mean Error: 0.0081 STD: 0.0848\n",
      "[300/600] Loss: 0.0069 MAE: 0.0383 Mean Error: 0.0079 STD: 0.0830\n",
      "[310/600] Loss: 0.0067 MAE: 0.0375 Mean Error: 0.0078 STD: 0.0812\n",
      "[320/600] Loss: 0.0064 MAE: 0.0367 Mean Error: 0.0076 STD: 0.0796\n",
      "[330/600] Loss: 0.0061 MAE: 0.0360 Mean Error: 0.0075 STD: 0.0780\n",
      "[340/600] Loss: 0.0059 MAE: 0.0352 Mean Error: 0.0074 STD: 0.0764\n",
      "[350/600] Loss: 0.0057 MAE: 0.0346 Mean Error: 0.0072 STD: 0.0750\n",
      "[360/600] Loss: 0.0055 MAE: 0.0339 Mean Error: 0.0071 STD: 0.0735\n",
      "[370/600] Loss: 0.0053 MAE: 0.0333 Mean Error: 0.0070 STD: 0.0721\n",
      "[380/600] Loss: 0.0051 MAE: 0.0326 Mean Error: 0.0069 STD: 0.0708\n",
      "[390/600] Loss: 0.0049 MAE: 0.0320 Mean Error: 0.0068 STD: 0.0695\n",
      "[400/600] Loss: 0.0047 MAE: 0.0315 Mean Error: 0.0067 STD: 0.0683\n",
      "[410/600] Loss: 0.0045 MAE: 0.0309 Mean Error: 0.0066 STD: 0.0671\n",
      "[420/600] Loss: 0.0044 MAE: 0.0304 Mean Error: 0.0065 STD: 0.0659\n",
      "[430/600] Loss: 0.0042 MAE: 0.0299 Mean Error: 0.0064 STD: 0.0648\n",
      "[440/600] Loss: 0.0041 MAE: 0.0294 Mean Error: 0.0063 STD: 0.0637\n",
      "[450/600] Loss: 0.0040 MAE: 0.0289 Mean Error: 0.0062 STD: 0.0626\n",
      "[460/600] Loss: 0.0038 MAE: 0.0284 Mean Error: 0.0061 STD: 0.0616\n",
      "[470/600] Loss: 0.0037 MAE: 0.0280 Mean Error: 0.0060 STD: 0.0606\n",
      "[480/600] Loss: 0.0036 MAE: 0.0275 Mean Error: 0.0059 STD: 0.0596\n",
      "[490/600] Loss: 0.0035 MAE: 0.0271 Mean Error: 0.0058 STD: 0.0587\n",
      "[500/600] Loss: 0.0034 MAE: 0.0267 Mean Error: 0.0058 STD: 0.0578\n",
      "[510/600] Loss: 0.0033 MAE: 0.0263 Mean Error: 0.0057 STD: 0.0569\n",
      "[520/600] Loss: 0.0032 MAE: 0.0259 Mean Error: 0.0056 STD: 0.0561\n",
      "[530/600] Loss: 0.0031 MAE: 0.0255 Mean Error: 0.0055 STD: 0.0552\n",
      "[540/600] Loss: 0.0030 MAE: 0.0251 Mean Error: 0.0055 STD: 0.0544\n",
      "[550/600] Loss: 0.0029 MAE: 0.0248 Mean Error: 0.0054 STD: 0.0536\n",
      "[560/600] Loss: 0.0028 MAE: 0.0244 Mean Error: 0.0053 STD: 0.0529\n",
      "[570/600] Loss: 0.0027 MAE: 0.0241 Mean Error: 0.0053 STD: 0.0521\n",
      "[580/600] Loss: 0.0027 MAE: 0.0237 Mean Error: 0.0052 STD: 0.0514\n",
      "[590/600] Loss: 0.0026 MAE: 0.0234 Mean Error: 0.0051 STD: 0.0507\n",
      "[599/600] Loss: 0.0025 MAE: 0.0231 Mean Error: 0.0051 STD: 0.0501\n",
      "------------------------------------\n",
      "Training dataset with noise standard deviation 0.002\n",
      "[0/600] Loss: 0.2549 MAE: 0.4872 Mean Error: 0.3960 STD: 0.3132\n",
      "[10/600] Loss: 0.0436 MAE: 0.1560 Mean Error: 0.0968 STD: 0.1852\n",
      "[20/600] Loss: 0.0306 MAE: 0.0904 Mean Error: 0.0334 STD: 0.1717\n",
      "[30/600] Loss: 0.0282 MAE: 0.0768 Mean Error: 0.0212 STD: 0.1665\n",
      "[40/600] Loss: 0.0264 MAE: 0.0726 Mean Error: 0.0168 STD: 0.1616\n",
      "[50/600] Loss: 0.0248 MAE: 0.0708 Mean Error: 0.0145 STD: 0.1570\n",
      "[60/600] Loss: 0.0235 MAE: 0.0692 Mean Error: 0.0132 STD: 0.1526\n",
      "[70/600] Loss: 0.0222 MAE: 0.0673 Mean Error: 0.0130 STD: 0.1483\n",
      "[80/600] Loss: 0.0209 MAE: 0.0656 Mean Error: 0.0127 STD: 0.1441\n",
      "[90/600] Loss: 0.0198 MAE: 0.0640 Mean Error: 0.0122 STD: 0.1401\n",
      "[100/600] Loss: 0.0187 MAE: 0.0623 Mean Error: 0.0119 STD: 0.1362\n",
      "[110/600] Loss: 0.0176 MAE: 0.0606 Mean Error: 0.0116 STD: 0.1324\n",
      "[120/600] Loss: 0.0167 MAE: 0.0590 Mean Error: 0.0113 STD: 0.1287\n",
      "[130/600] Loss: 0.0158 MAE: 0.0574 Mean Error: 0.0110 STD: 0.1252\n",
      "[140/600] Loss: 0.0149 MAE: 0.0559 Mean Error: 0.0108 STD: 0.1217\n",
      "[150/600] Loss: 0.0141 MAE: 0.0544 Mean Error: 0.0105 STD: 0.1185\n",
      "[160/600] Loss: 0.0134 MAE: 0.0530 Mean Error: 0.0103 STD: 0.1153\n",
      "[170/600] Loss: 0.0127 MAE: 0.0516 Mean Error: 0.0100 STD: 0.1123\n",
      "[180/600] Loss: 0.0121 MAE: 0.0502 Mean Error: 0.0098 STD: 0.1094\n",
      "[190/600] Loss: 0.0114 MAE: 0.0490 Mean Error: 0.0096 STD: 0.1066\n",
      "[200/600] Loss: 0.0109 MAE: 0.0477 Mean Error: 0.0094 STD: 0.1039\n",
      "[210/600] Loss: 0.0104 MAE: 0.0465 Mean Error: 0.0091 STD: 0.1013\n",
      "[220/600] Loss: 0.0099 MAE: 0.0454 Mean Error: 0.0089 STD: 0.0989\n",
      "[230/600] Loss: 0.0094 MAE: 0.0443 Mean Error: 0.0088 STD: 0.0965\n",
      "[240/600] Loss: 0.0090 MAE: 0.0433 Mean Error: 0.0086 STD: 0.0942\n",
      "[250/600] Loss: 0.0085 MAE: 0.0423 Mean Error: 0.0084 STD: 0.0921\n",
      "[260/600] Loss: 0.0082 MAE: 0.0413 Mean Error: 0.0082 STD: 0.0900\n",
      "[270/600] Loss: 0.0078 MAE: 0.0404 Mean Error: 0.0081 STD: 0.0880\n",
      "[280/600] Loss: 0.0075 MAE: 0.0395 Mean Error: 0.0079 STD: 0.0860\n",
      "[290/600] Loss: 0.0071 MAE: 0.0386 Mean Error: 0.0077 STD: 0.0842\n",
      "[300/600] Loss: 0.0068 MAE: 0.0378 Mean Error: 0.0076 STD: 0.0824\n",
      "[310/600] Loss: 0.0066 MAE: 0.0370 Mean Error: 0.0075 STD: 0.0807\n",
      "[320/600] Loss: 0.0063 MAE: 0.0362 Mean Error: 0.0073 STD: 0.0790\n",
      "[330/600] Loss: 0.0060 MAE: 0.0355 Mean Error: 0.0072 STD: 0.0774\n",
      "[340/600] Loss: 0.0058 MAE: 0.0348 Mean Error: 0.0071 STD: 0.0759\n",
      "[350/600] Loss: 0.0056 MAE: 0.0341 Mean Error: 0.0070 STD: 0.0744\n",
      "[360/600] Loss: 0.0054 MAE: 0.0335 Mean Error: 0.0068 STD: 0.0730\n",
      "[370/600] Loss: 0.0052 MAE: 0.0328 Mean Error: 0.0067 STD: 0.0716\n",
      "[380/600] Loss: 0.0050 MAE: 0.0322 Mean Error: 0.0066 STD: 0.0703\n",
      "[390/600] Loss: 0.0048 MAE: 0.0316 Mean Error: 0.0065 STD: 0.0690\n",
      "[400/600] Loss: 0.0046 MAE: 0.0311 Mean Error: 0.0064 STD: 0.0677\n",
      "[410/600] Loss: 0.0045 MAE: 0.0305 Mean Error: 0.0063 STD: 0.0665\n",
      "[420/600] Loss: 0.0043 MAE: 0.0300 Mean Error: 0.0062 STD: 0.0654\n",
      "[430/600] Loss: 0.0042 MAE: 0.0295 Mean Error: 0.0061 STD: 0.0643\n",
      "[440/600] Loss: 0.0040 MAE: 0.0290 Mean Error: 0.0060 STD: 0.0632\n",
      "[450/600] Loss: 0.0039 MAE: 0.0285 Mean Error: 0.0059 STD: 0.0621\n",
      "[460/600] Loss: 0.0038 MAE: 0.0280 Mean Error: 0.0059 STD: 0.0611\n",
      "[470/600] Loss: 0.0036 MAE: 0.0276 Mean Error: 0.0058 STD: 0.0601\n",
      "[480/600] Loss: 0.0035 MAE: 0.0271 Mean Error: 0.0057 STD: 0.0592\n",
      "[490/600] Loss: 0.0034 MAE: 0.0267 Mean Error: 0.0056 STD: 0.0582\n",
      "[500/600] Loss: 0.0033 MAE: 0.0263 Mean Error: 0.0055 STD: 0.0573\n",
      "[510/600] Loss: 0.0032 MAE: 0.0259 Mean Error: 0.0055 STD: 0.0565\n",
      "[520/600] Loss: 0.0031 MAE: 0.0255 Mean Error: 0.0054 STD: 0.0556\n",
      "[530/600] Loss: 0.0030 MAE: 0.0252 Mean Error: 0.0053 STD: 0.0548\n",
      "[540/600] Loss: 0.0029 MAE: 0.0248 Mean Error: 0.0053 STD: 0.0540\n",
      "[550/600] Loss: 0.0029 MAE: 0.0244 Mean Error: 0.0052 STD: 0.0532\n",
      "[560/600] Loss: 0.0028 MAE: 0.0241 Mean Error: 0.0051 STD: 0.0525\n",
      "[570/600] Loss: 0.0027 MAE: 0.0238 Mean Error: 0.0051 STD: 0.0517\n",
      "[580/600] Loss: 0.0026 MAE: 0.0234 Mean Error: 0.0050 STD: 0.0510\n",
      "[590/600] Loss: 0.0026 MAE: 0.0231 Mean Error: 0.0049 STD: 0.0503\n",
      "[599/600] Loss: 0.0025 MAE: 0.0228 Mean Error: 0.0049 STD: 0.0497\n",
      "------------------------------------\n",
      "Training dataset with noise standard deviation 0.003\n",
      "[0/600] Loss: 0.2767 MAE: 0.5089 Mean Error: 0.4254 STD: 0.3095\n",
      "[10/600] Loss: 0.0454 MAE: 0.1627 Mean Error: 0.1005 STD: 0.1878\n",
      "[20/600] Loss: 0.0307 MAE: 0.0925 Mean Error: 0.0346 STD: 0.1718\n",
      "[30/600] Loss: 0.0281 MAE: 0.0782 Mean Error: 0.0214 STD: 0.1662\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[40/600] Loss: 0.0263 MAE: 0.0734 Mean Error: 0.0166 STD: 0.1615\n",
      "[50/600] Loss: 0.0248 MAE: 0.0709 Mean Error: 0.0141 STD: 0.1570\n",
      "[60/600] Loss: 0.0235 MAE: 0.0692 Mean Error: 0.0135 STD: 0.1527\n",
      "[70/600] Loss: 0.0222 MAE: 0.0675 Mean Error: 0.0128 STD: 0.1485\n",
      "[80/600] Loss: 0.0210 MAE: 0.0659 Mean Error: 0.0126 STD: 0.1444\n",
      "[90/600] Loss: 0.0199 MAE: 0.0643 Mean Error: 0.0123 STD: 0.1404\n",
      "[100/600] Loss: 0.0188 MAE: 0.0628 Mean Error: 0.0119 STD: 0.1366\n",
      "[110/600] Loss: 0.0178 MAE: 0.0611 Mean Error: 0.0117 STD: 0.1329\n",
      "[120/600] Loss: 0.0168 MAE: 0.0595 Mean Error: 0.0115 STD: 0.1293\n",
      "[130/600] Loss: 0.0159 MAE: 0.0580 Mean Error: 0.0112 STD: 0.1258\n",
      "[140/600] Loss: 0.0151 MAE: 0.0565 Mean Error: 0.0110 STD: 0.1224\n",
      "[150/600] Loss: 0.0143 MAE: 0.0550 Mean Error: 0.0108 STD: 0.1192\n",
      "[160/600] Loss: 0.0136 MAE: 0.0536 Mean Error: 0.0106 STD: 0.1160\n",
      "[170/600] Loss: 0.0129 MAE: 0.0522 Mean Error: 0.0104 STD: 0.1130\n",
      "[180/600] Loss: 0.0122 MAE: 0.0509 Mean Error: 0.0101 STD: 0.1101\n",
      "[190/600] Loss: 0.0116 MAE: 0.0496 Mean Error: 0.0100 STD: 0.1073\n",
      "[200/600] Loss: 0.0110 MAE: 0.0484 Mean Error: 0.0098 STD: 0.1046\n",
      "[210/600] Loss: 0.0105 MAE: 0.0472 Mean Error: 0.0096 STD: 0.1020\n",
      "[220/600] Loss: 0.0100 MAE: 0.0460 Mean Error: 0.0094 STD: 0.0995\n",
      "[230/600] Loss: 0.0095 MAE: 0.0449 Mean Error: 0.0092 STD: 0.0971\n",
      "[240/600] Loss: 0.0091 MAE: 0.0439 Mean Error: 0.0090 STD: 0.0948\n",
      "[250/600] Loss: 0.0086 MAE: 0.0429 Mean Error: 0.0088 STD: 0.0926\n",
      "[260/600] Loss: 0.0083 MAE: 0.0419 Mean Error: 0.0087 STD: 0.0905\n",
      "[270/600] Loss: 0.0079 MAE: 0.0409 Mean Error: 0.0085 STD: 0.0884\n",
      "[280/600] Loss: 0.0075 MAE: 0.0400 Mean Error: 0.0083 STD: 0.0865\n",
      "[290/600] Loss: 0.0072 MAE: 0.0392 Mean Error: 0.0082 STD: 0.0846\n",
      "[300/600] Loss: 0.0069 MAE: 0.0383 Mean Error: 0.0080 STD: 0.0828\n",
      "[310/600] Loss: 0.0066 MAE: 0.0375 Mean Error: 0.0079 STD: 0.0811\n",
      "[320/600] Loss: 0.0064 MAE: 0.0367 Mean Error: 0.0078 STD: 0.0794\n",
      "[330/600] Loss: 0.0061 MAE: 0.0360 Mean Error: 0.0076 STD: 0.0778\n",
      "[340/600] Loss: 0.0059 MAE: 0.0353 Mean Error: 0.0075 STD: 0.0762\n",
      "[350/600] Loss: 0.0056 MAE: 0.0346 Mean Error: 0.0074 STD: 0.0747\n",
      "[360/600] Loss: 0.0054 MAE: 0.0339 Mean Error: 0.0072 STD: 0.0733\n",
      "[370/600] Loss: 0.0052 MAE: 0.0333 Mean Error: 0.0071 STD: 0.0719\n",
      "[380/600] Loss: 0.0050 MAE: 0.0327 Mean Error: 0.0070 STD: 0.0706\n",
      "[390/600] Loss: 0.0048 MAE: 0.0321 Mean Error: 0.0069 STD: 0.0693\n",
      "[400/600] Loss: 0.0047 MAE: 0.0315 Mean Error: 0.0068 STD: 0.0680\n",
      "[410/600] Loss: 0.0045 MAE: 0.0309 Mean Error: 0.0067 STD: 0.0668\n",
      "[420/600] Loss: 0.0044 MAE: 0.0304 Mean Error: 0.0066 STD: 0.0657\n",
      "[430/600] Loss: 0.0042 MAE: 0.0299 Mean Error: 0.0065 STD: 0.0645\n",
      "[440/600] Loss: 0.0041 MAE: 0.0294 Mean Error: 0.0064 STD: 0.0635\n",
      "[450/600] Loss: 0.0039 MAE: 0.0289 Mean Error: 0.0063 STD: 0.0624\n",
      "[460/600] Loss: 0.0038 MAE: 0.0284 Mean Error: 0.0062 STD: 0.0614\n",
      "[470/600] Loss: 0.0037 MAE: 0.0280 Mean Error: 0.0061 STD: 0.0604\n",
      "[480/600] Loss: 0.0036 MAE: 0.0275 Mean Error: 0.0060 STD: 0.0594\n",
      "[490/600] Loss: 0.0035 MAE: 0.0271 Mean Error: 0.0059 STD: 0.0585\n",
      "[500/600] Loss: 0.0033 MAE: 0.0267 Mean Error: 0.0059 STD: 0.0576\n",
      "[510/600] Loss: 0.0032 MAE: 0.0263 Mean Error: 0.0058 STD: 0.0567\n",
      "[520/600] Loss: 0.0032 MAE: 0.0259 Mean Error: 0.0057 STD: 0.0558\n",
      "[530/600] Loss: 0.0031 MAE: 0.0255 Mean Error: 0.0056 STD: 0.0550\n",
      "[540/600] Loss: 0.0030 MAE: 0.0251 Mean Error: 0.0056 STD: 0.0542\n",
      "[550/600] Loss: 0.0029 MAE: 0.0248 Mean Error: 0.0055 STD: 0.0534\n",
      "[560/600] Loss: 0.0028 MAE: 0.0244 Mean Error: 0.0054 STD: 0.0527\n",
      "[570/600] Loss: 0.0027 MAE: 0.0241 Mean Error: 0.0054 STD: 0.0519\n",
      "[580/600] Loss: 0.0026 MAE: 0.0238 Mean Error: 0.0053 STD: 0.0512\n",
      "[590/600] Loss: 0.0026 MAE: 0.0234 Mean Error: 0.0052 STD: 0.0505\n",
      "[599/600] Loss: 0.0025 MAE: 0.0231 Mean Error: 0.0052 STD: 0.0499\n",
      "------------------------------------\n",
      "Training dataset with noise standard deviation 0.005\n",
      "[0/600] Loss: 0.2488 MAE: 0.4830 Mean Error: 0.4007 STD: 0.2971\n",
      "[10/600] Loss: 0.0427 MAE: 0.1530 Mean Error: 0.0919 STD: 0.1852\n",
      "[20/600] Loss: 0.0305 MAE: 0.0908 Mean Error: 0.0326 STD: 0.1715\n",
      "[30/600] Loss: 0.0280 MAE: 0.0779 Mean Error: 0.0193 STD: 0.1663\n",
      "[40/600] Loss: 0.0263 MAE: 0.0731 Mean Error: 0.0161 STD: 0.1613\n",
      "[50/600] Loss: 0.0248 MAE: 0.0706 Mean Error: 0.0139 STD: 0.1569\n",
      "[60/600] Loss: 0.0234 MAE: 0.0685 Mean Error: 0.0127 STD: 0.1525\n",
      "[70/600] Loss: 0.0221 MAE: 0.0670 Mean Error: 0.0128 STD: 0.1481\n",
      "[80/600] Loss: 0.0209 MAE: 0.0655 Mean Error: 0.0122 STD: 0.1440\n",
      "[90/600] Loss: 0.0197 MAE: 0.0638 Mean Error: 0.0122 STD: 0.1400\n",
      "[100/600] Loss: 0.0187 MAE: 0.0621 Mean Error: 0.0118 STD: 0.1362\n",
      "[110/600] Loss: 0.0177 MAE: 0.0605 Mean Error: 0.0115 STD: 0.1325\n",
      "[120/600] Loss: 0.0167 MAE: 0.0589 Mean Error: 0.0112 STD: 0.1288\n",
      "[130/600] Loss: 0.0158 MAE: 0.0574 Mean Error: 0.0110 STD: 0.1254\n",
      "[140/600] Loss: 0.0150 MAE: 0.0559 Mean Error: 0.0108 STD: 0.1220\n",
      "[150/600] Loss: 0.0142 MAE: 0.0544 Mean Error: 0.0105 STD: 0.1187\n",
      "[160/600] Loss: 0.0135 MAE: 0.0530 Mean Error: 0.0103 STD: 0.1156\n",
      "[170/600] Loss: 0.0128 MAE: 0.0517 Mean Error: 0.0101 STD: 0.1126\n",
      "[180/600] Loss: 0.0121 MAE: 0.0503 Mean Error: 0.0099 STD: 0.1097\n",
      "[190/600] Loss: 0.0115 MAE: 0.0491 Mean Error: 0.0097 STD: 0.1069\n",
      "[200/600] Loss: 0.0109 MAE: 0.0478 Mean Error: 0.0094 STD: 0.1042\n",
      "[210/600] Loss: 0.0104 MAE: 0.0467 Mean Error: 0.0092 STD: 0.1016\n",
      "[220/600] Loss: 0.0099 MAE: 0.0455 Mean Error: 0.0090 STD: 0.0991\n",
      "[230/600] Loss: 0.0094 MAE: 0.0444 Mean Error: 0.0089 STD: 0.0967\n",
      "[240/600] Loss: 0.0090 MAE: 0.0434 Mean Error: 0.0087 STD: 0.0944\n",
      "[250/600] Loss: 0.0086 MAE: 0.0424 Mean Error: 0.0085 STD: 0.0922\n",
      "[260/600] Loss: 0.0082 MAE: 0.0414 Mean Error: 0.0083 STD: 0.0901\n",
      "[270/600] Loss: 0.0078 MAE: 0.0405 Mean Error: 0.0082 STD: 0.0881\n",
      "[280/600] Loss: 0.0075 MAE: 0.0396 Mean Error: 0.0080 STD: 0.0861\n",
      "[290/600] Loss: 0.0072 MAE: 0.0387 Mean Error: 0.0078 STD: 0.0843\n",
      "[300/600] Loss: 0.0069 MAE: 0.0379 Mean Error: 0.0077 STD: 0.0825\n",
      "[310/600] Loss: 0.0066 MAE: 0.0371 Mean Error: 0.0075 STD: 0.0807\n",
      "[320/600] Loss: 0.0063 MAE: 0.0363 Mean Error: 0.0074 STD: 0.0791\n",
      "[330/600] Loss: 0.0060 MAE: 0.0356 Mean Error: 0.0073 STD: 0.0775\n",
      "[340/600] Loss: 0.0058 MAE: 0.0349 Mean Error: 0.0072 STD: 0.0759\n",
      "[350/600] Loss: 0.0056 MAE: 0.0342 Mean Error: 0.0070 STD: 0.0744\n",
      "[360/600] Loss: 0.0054 MAE: 0.0335 Mean Error: 0.0069 STD: 0.0730\n",
      "[370/600] Loss: 0.0052 MAE: 0.0329 Mean Error: 0.0068 STD: 0.0716\n",
      "[380/600] Loss: 0.0050 MAE: 0.0323 Mean Error: 0.0067 STD: 0.0703\n",
      "[390/600] Loss: 0.0048 MAE: 0.0317 Mean Error: 0.0066 STD: 0.0690\n",
      "[400/600] Loss: 0.0046 MAE: 0.0311 Mean Error: 0.0065 STD: 0.0677\n",
      "[410/600] Loss: 0.0045 MAE: 0.0306 Mean Error: 0.0064 STD: 0.0665\n",
      "[420/600] Loss: 0.0043 MAE: 0.0300 Mean Error: 0.0063 STD: 0.0653\n",
      "[430/600] Loss: 0.0042 MAE: 0.0295 Mean Error: 0.0062 STD: 0.0642\n",
      "[440/600] Loss: 0.0040 MAE: 0.0290 Mean Error: 0.0061 STD: 0.0631\n",
      "[450/600] Loss: 0.0039 MAE: 0.0285 Mean Error: 0.0060 STD: 0.0621\n",
      "[460/600] Loss: 0.0038 MAE: 0.0281 Mean Error: 0.0059 STD: 0.0611\n",
      "[470/600] Loss: 0.0036 MAE: 0.0276 Mean Error: 0.0058 STD: 0.0601\n",
      "[480/600] Loss: 0.0035 MAE: 0.0272 Mean Error: 0.0057 STD: 0.0591\n",
      "[490/600] Loss: 0.0034 MAE: 0.0268 Mean Error: 0.0057 STD: 0.0582\n",
      "[500/600] Loss: 0.0033 MAE: 0.0264 Mean Error: 0.0056 STD: 0.0573\n",
      "[510/600] Loss: 0.0032 MAE: 0.0260 Mean Error: 0.0055 STD: 0.0564\n",
      "[520/600] Loss: 0.0031 MAE: 0.0256 Mean Error: 0.0054 STD: 0.0555\n",
      "[530/600] Loss: 0.0030 MAE: 0.0252 Mean Error: 0.0054 STD: 0.0547\n",
      "[540/600] Loss: 0.0029 MAE: 0.0248 Mean Error: 0.0053 STD: 0.0539\n",
      "[550/600] Loss: 0.0028 MAE: 0.0245 Mean Error: 0.0052 STD: 0.0531\n",
      "[560/600] Loss: 0.0028 MAE: 0.0241 Mean Error: 0.0052 STD: 0.0524\n",
      "[570/600] Loss: 0.0027 MAE: 0.0238 Mean Error: 0.0051 STD: 0.0516\n",
      "[580/600] Loss: 0.0026 MAE: 0.0235 Mean Error: 0.0050 STD: 0.0509\n",
      "[590/600] Loss: 0.0025 MAE: 0.0231 Mean Error: 0.0050 STD: 0.0502\n",
      "[599/600] Loss: 0.0025 MAE: 0.0229 Mean Error: 0.0049 STD: 0.0496\n",
      "------------------------------------\n",
      "Training dataset with noise standard deviation 0.01\n",
      "[0/600] Loss: 0.2726 MAE: 0.5076 Mean Error: 0.4228 STD: 0.3064\n",
      "[10/600] Loss: 0.0450 MAE: 0.1603 Mean Error: 0.0992 STD: 0.1877\n",
      "[20/600] Loss: 0.0312 MAE: 0.0926 Mean Error: 0.0340 STD: 0.1733\n",
      "[30/600] Loss: 0.0284 MAE: 0.0791 Mean Error: 0.0216 STD: 0.1671\n",
      "[40/600] Loss: 0.0267 MAE: 0.0747 Mean Error: 0.0162 STD: 0.1626\n",
      "[50/600] Loss: 0.0252 MAE: 0.0717 Mean Error: 0.0152 STD: 0.1580\n",
      "[60/600] Loss: 0.0238 MAE: 0.0699 Mean Error: 0.0141 STD: 0.1536\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[70/600] Loss: 0.0225 MAE: 0.0683 Mean Error: 0.0136 STD: 0.1493\n",
      "[80/600] Loss: 0.0212 MAE: 0.0666 Mean Error: 0.0133 STD: 0.1452\n",
      "[90/600] Loss: 0.0201 MAE: 0.0649 Mean Error: 0.0128 STD: 0.1412\n",
      "[100/600] Loss: 0.0190 MAE: 0.0632 Mean Error: 0.0124 STD: 0.1373\n",
      "[110/600] Loss: 0.0180 MAE: 0.0616 Mean Error: 0.0122 STD: 0.1335\n",
      "[120/600] Loss: 0.0170 MAE: 0.0600 Mean Error: 0.0118 STD: 0.1298\n",
      "[130/600] Loss: 0.0161 MAE: 0.0584 Mean Error: 0.0116 STD: 0.1263\n",
      "[140/600] Loss: 0.0152 MAE: 0.0568 Mean Error: 0.0113 STD: 0.1229\n",
      "[150/600] Loss: 0.0144 MAE: 0.0553 Mean Error: 0.0111 STD: 0.1197\n",
      "[160/600] Loss: 0.0137 MAE: 0.0539 Mean Error: 0.0108 STD: 0.1165\n",
      "[170/600] Loss: 0.0130 MAE: 0.0525 Mean Error: 0.0106 STD: 0.1135\n",
      "[180/600] Loss: 0.0123 MAE: 0.0512 Mean Error: 0.0103 STD: 0.1106\n",
      "[190/600] Loss: 0.0117 MAE: 0.0499 Mean Error: 0.0101 STD: 0.1078\n",
      "[200/600] Loss: 0.0112 MAE: 0.0486 Mean Error: 0.0099 STD: 0.1052\n",
      "[210/600] Loss: 0.0106 MAE: 0.0474 Mean Error: 0.0096 STD: 0.1026\n",
      "[220/600] Loss: 0.0101 MAE: 0.0463 Mean Error: 0.0094 STD: 0.1001\n",
      "[230/600] Loss: 0.0096 MAE: 0.0452 Mean Error: 0.0092 STD: 0.0978\n",
      "[240/600] Loss: 0.0092 MAE: 0.0441 Mean Error: 0.0090 STD: 0.0955\n",
      "[250/600] Loss: 0.0088 MAE: 0.0431 Mean Error: 0.0088 STD: 0.0933\n",
      "[260/600] Loss: 0.0084 MAE: 0.0421 Mean Error: 0.0086 STD: 0.0912\n",
      "[270/600] Loss: 0.0080 MAE: 0.0412 Mean Error: 0.0085 STD: 0.0892\n",
      "[280/600] Loss: 0.0077 MAE: 0.0403 Mean Error: 0.0083 STD: 0.0873\n",
      "[290/600] Loss: 0.0074 MAE: 0.0394 Mean Error: 0.0081 STD: 0.0854\n",
      "[300/600] Loss: 0.0070 MAE: 0.0386 Mean Error: 0.0080 STD: 0.0836\n",
      "[310/600] Loss: 0.0068 MAE: 0.0378 Mean Error: 0.0078 STD: 0.0819\n",
      "[320/600] Loss: 0.0065 MAE: 0.0370 Mean Error: 0.0077 STD: 0.0802\n",
      "[330/600] Loss: 0.0062 MAE: 0.0363 Mean Error: 0.0075 STD: 0.0786\n",
      "[340/600] Loss: 0.0060 MAE: 0.0356 Mean Error: 0.0074 STD: 0.0770\n",
      "[350/600] Loss: 0.0058 MAE: 0.0349 Mean Error: 0.0073 STD: 0.0755\n",
      "[360/600] Loss: 0.0055 MAE: 0.0342 Mean Error: 0.0071 STD: 0.0741\n",
      "[370/600] Loss: 0.0053 MAE: 0.0336 Mean Error: 0.0070 STD: 0.0727\n",
      "[380/600] Loss: 0.0051 MAE: 0.0329 Mean Error: 0.0069 STD: 0.0714\n",
      "[390/600] Loss: 0.0050 MAE: 0.0323 Mean Error: 0.0068 STD: 0.0701\n",
      "[400/600] Loss: 0.0048 MAE: 0.0318 Mean Error: 0.0067 STD: 0.0688\n",
      "[410/600] Loss: 0.0046 MAE: 0.0312 Mean Error: 0.0066 STD: 0.0676\n",
      "[420/600] Loss: 0.0045 MAE: 0.0307 Mean Error: 0.0065 STD: 0.0664\n",
      "[430/600] Loss: 0.0043 MAE: 0.0301 Mean Error: 0.0064 STD: 0.0653\n",
      "[440/600] Loss: 0.0042 MAE: 0.0296 Mean Error: 0.0063 STD: 0.0642\n",
      "[450/600] Loss: 0.0040 MAE: 0.0291 Mean Error: 0.0062 STD: 0.0631\n",
      "[460/600] Loss: 0.0039 MAE: 0.0287 Mean Error: 0.0061 STD: 0.0621\n",
      "[470/600] Loss: 0.0038 MAE: 0.0282 Mean Error: 0.0060 STD: 0.0611\n",
      "[480/600] Loss: 0.0036 MAE: 0.0278 Mean Error: 0.0059 STD: 0.0601\n",
      "[490/600] Loss: 0.0035 MAE: 0.0273 Mean Error: 0.0059 STD: 0.0592\n",
      "[500/600] Loss: 0.0034 MAE: 0.0269 Mean Error: 0.0058 STD: 0.0582\n",
      "[510/600] Loss: 0.0033 MAE: 0.0265 Mean Error: 0.0057 STD: 0.0574\n",
      "[520/600] Loss: 0.0032 MAE: 0.0261 Mean Error: 0.0056 STD: 0.0565\n",
      "[530/600] Loss: 0.0031 MAE: 0.0257 Mean Error: 0.0056 STD: 0.0557\n",
      "[540/600] Loss: 0.0030 MAE: 0.0254 Mean Error: 0.0055 STD: 0.0548\n",
      "[550/600] Loss: 0.0029 MAE: 0.0250 Mean Error: 0.0054 STD: 0.0540\n",
      "[560/600] Loss: 0.0029 MAE: 0.0246 Mean Error: 0.0054 STD: 0.0533\n",
      "[570/600] Loss: 0.0028 MAE: 0.0243 Mean Error: 0.0053 STD: 0.0525\n",
      "[580/600] Loss: 0.0027 MAE: 0.0240 Mean Error: 0.0052 STD: 0.0518\n",
      "[590/600] Loss: 0.0026 MAE: 0.0236 Mean Error: 0.0052 STD: 0.0511\n",
      "[599/600] Loss: 0.0026 MAE: 0.0234 Mean Error: 0.0051 STD: 0.0505\n",
      "------------------------------------\n",
      "Training dataset with noise standard deviation 0.02\n",
      "[0/600] Loss: 0.2558 MAE: 0.4902 Mean Error: 0.4024 STD: 0.3065\n",
      "[10/600] Loss: 0.0440 MAE: 0.1565 Mean Error: 0.0934 STD: 0.1879\n",
      "[20/600] Loss: 0.0306 MAE: 0.0919 Mean Error: 0.0343 STD: 0.1717\n",
      "[30/600] Loss: 0.0281 MAE: 0.0785 Mean Error: 0.0216 STD: 0.1664\n",
      "[40/600] Loss: 0.0264 MAE: 0.0734 Mean Error: 0.0171 STD: 0.1617\n",
      "[50/600] Loss: 0.0249 MAE: 0.0711 Mean Error: 0.0159 STD: 0.1570\n",
      "[60/600] Loss: 0.0235 MAE: 0.0692 Mean Error: 0.0145 STD: 0.1526\n",
      "[70/600] Loss: 0.0222 MAE: 0.0675 Mean Error: 0.0137 STD: 0.1483\n",
      "[80/600] Loss: 0.0209 MAE: 0.0657 Mean Error: 0.0134 STD: 0.1441\n",
      "[90/600] Loss: 0.0198 MAE: 0.0641 Mean Error: 0.0128 STD: 0.1401\n",
      "[100/600] Loss: 0.0187 MAE: 0.0625 Mean Error: 0.0124 STD: 0.1361\n",
      "[110/600] Loss: 0.0177 MAE: 0.0608 Mean Error: 0.0120 STD: 0.1324\n",
      "[120/600] Loss: 0.0167 MAE: 0.0592 Mean Error: 0.0118 STD: 0.1287\n",
      "[130/600] Loss: 0.0158 MAE: 0.0576 Mean Error: 0.0114 STD: 0.1252\n",
      "[140/600] Loss: 0.0149 MAE: 0.0561 Mean Error: 0.0111 STD: 0.1218\n",
      "[150/600] Loss: 0.0142 MAE: 0.0546 Mean Error: 0.0108 STD: 0.1185\n",
      "[160/600] Loss: 0.0134 MAE: 0.0532 Mean Error: 0.0105 STD: 0.1154\n",
      "[170/600] Loss: 0.0127 MAE: 0.0518 Mean Error: 0.0102 STD: 0.1124\n",
      "[180/600] Loss: 0.0121 MAE: 0.0505 Mean Error: 0.0100 STD: 0.1095\n",
      "[190/600] Loss: 0.0115 MAE: 0.0492 Mean Error: 0.0097 STD: 0.1067\n",
      "[200/600] Loss: 0.0109 MAE: 0.0480 Mean Error: 0.0095 STD: 0.1040\n",
      "[210/600] Loss: 0.0104 MAE: 0.0468 Mean Error: 0.0092 STD: 0.1014\n",
      "[220/600] Loss: 0.0099 MAE: 0.0456 Mean Error: 0.0090 STD: 0.0989\n",
      "[230/600] Loss: 0.0094 MAE: 0.0445 Mean Error: 0.0088 STD: 0.0965\n",
      "[240/600] Loss: 0.0090 MAE: 0.0435 Mean Error: 0.0086 STD: 0.0942\n",
      "[250/600] Loss: 0.0085 MAE: 0.0425 Mean Error: 0.0084 STD: 0.0920\n",
      "[260/600] Loss: 0.0082 MAE: 0.0415 Mean Error: 0.0082 STD: 0.0899\n",
      "[270/600] Loss: 0.0078 MAE: 0.0406 Mean Error: 0.0081 STD: 0.0879\n",
      "[280/600] Loss: 0.0074 MAE: 0.0397 Mean Error: 0.0079 STD: 0.0860\n",
      "[290/600] Loss: 0.0071 MAE: 0.0388 Mean Error: 0.0077 STD: 0.0841\n",
      "[300/600] Loss: 0.0068 MAE: 0.0380 Mean Error: 0.0076 STD: 0.0823\n",
      "[310/600] Loss: 0.0065 MAE: 0.0372 Mean Error: 0.0075 STD: 0.0805\n",
      "[320/600] Loss: 0.0063 MAE: 0.0364 Mean Error: 0.0073 STD: 0.0789\n",
      "[330/600] Loss: 0.0060 MAE: 0.0356 Mean Error: 0.0072 STD: 0.0773\n",
      "[340/600] Loss: 0.0058 MAE: 0.0349 Mean Error: 0.0071 STD: 0.0757\n",
      "[350/600] Loss: 0.0056 MAE: 0.0342 Mean Error: 0.0069 STD: 0.0742\n",
      "[360/600] Loss: 0.0053 MAE: 0.0336 Mean Error: 0.0068 STD: 0.0728\n",
      "[370/600] Loss: 0.0051 MAE: 0.0329 Mean Error: 0.0067 STD: 0.0714\n",
      "[380/600] Loss: 0.0050 MAE: 0.0323 Mean Error: 0.0066 STD: 0.0701\n",
      "[390/600] Loss: 0.0048 MAE: 0.0317 Mean Error: 0.0065 STD: 0.0688\n",
      "[400/600] Loss: 0.0046 MAE: 0.0312 Mean Error: 0.0064 STD: 0.0675\n",
      "[410/600] Loss: 0.0044 MAE: 0.0306 Mean Error: 0.0063 STD: 0.0663\n",
      "[420/600] Loss: 0.0043 MAE: 0.0301 Mean Error: 0.0062 STD: 0.0652\n",
      "[430/600] Loss: 0.0041 MAE: 0.0296 Mean Error: 0.0061 STD: 0.0640\n",
      "[440/600] Loss: 0.0040 MAE: 0.0291 Mean Error: 0.0060 STD: 0.0630\n",
      "[450/600] Loss: 0.0039 MAE: 0.0286 Mean Error: 0.0059 STD: 0.0619\n",
      "[460/600] Loss: 0.0037 MAE: 0.0281 Mean Error: 0.0058 STD: 0.0609\n",
      "[470/600] Loss: 0.0036 MAE: 0.0277 Mean Error: 0.0058 STD: 0.0599\n",
      "[480/600] Loss: 0.0035 MAE: 0.0272 Mean Error: 0.0057 STD: 0.0589\n",
      "[490/600] Loss: 0.0034 MAE: 0.0268 Mean Error: 0.0056 STD: 0.0580\n",
      "[500/600] Loss: 0.0033 MAE: 0.0264 Mean Error: 0.0055 STD: 0.0571\n",
      "[510/600] Loss: 0.0032 MAE: 0.0260 Mean Error: 0.0055 STD: 0.0562\n",
      "[520/600] Loss: 0.0031 MAE: 0.0256 Mean Error: 0.0054 STD: 0.0554\n",
      "[530/600] Loss: 0.0030 MAE: 0.0252 Mean Error: 0.0053 STD: 0.0545\n",
      "[540/600] Loss: 0.0029 MAE: 0.0248 Mean Error: 0.0053 STD: 0.0537\n",
      "[550/600] Loss: 0.0028 MAE: 0.0245 Mean Error: 0.0052 STD: 0.0530\n",
      "[560/600] Loss: 0.0028 MAE: 0.0241 Mean Error: 0.0051 STD: 0.0522\n",
      "[570/600] Loss: 0.0027 MAE: 0.0238 Mean Error: 0.0051 STD: 0.0515\n",
      "[580/600] Loss: 0.0026 MAE: 0.0235 Mean Error: 0.0050 STD: 0.0507\n",
      "[590/600] Loss: 0.0025 MAE: 0.0232 Mean Error: 0.0049 STD: 0.0501\n",
      "[599/600] Loss: 0.0025 MAE: 0.0229 Mean Error: 0.0049 STD: 0.0494\n",
      "------------------------------------\n",
      "Training dataset with noise standard deviation 0.03\n",
      "[0/600] Loss: 0.2662 MAE: 0.4999 Mean Error: 0.4150 STD: 0.3066\n",
      "[10/600] Loss: 0.0448 MAE: 0.1611 Mean Error: 0.0985 STD: 0.1873\n",
      "[20/600] Loss: 0.0307 MAE: 0.0929 Mean Error: 0.0346 STD: 0.1719\n",
      "[30/600] Loss: 0.0282 MAE: 0.0785 Mean Error: 0.0203 STD: 0.1667\n",
      "[40/600] Loss: 0.0265 MAE: 0.0736 Mean Error: 0.0174 STD: 0.1618\n",
      "[50/600] Loss: 0.0250 MAE: 0.0710 Mean Error: 0.0148 STD: 0.1574\n",
      "[60/600] Loss: 0.0236 MAE: 0.0689 Mean Error: 0.0140 STD: 0.1530\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[70/600] Loss: 0.0223 MAE: 0.0674 Mean Error: 0.0134 STD: 0.1487\n",
      "[80/600] Loss: 0.0211 MAE: 0.0659 Mean Error: 0.0130 STD: 0.1446\n",
      "[90/600] Loss: 0.0199 MAE: 0.0644 Mean Error: 0.0125 STD: 0.1406\n",
      "[100/600] Loss: 0.0188 MAE: 0.0628 Mean Error: 0.0121 STD: 0.1367\n",
      "[110/600] Loss: 0.0178 MAE: 0.0612 Mean Error: 0.0118 STD: 0.1330\n",
      "[120/600] Loss: 0.0169 MAE: 0.0596 Mean Error: 0.0116 STD: 0.1294\n",
      "[130/600] Loss: 0.0160 MAE: 0.0580 Mean Error: 0.0113 STD: 0.1258\n",
      "[140/600] Loss: 0.0151 MAE: 0.0565 Mean Error: 0.0110 STD: 0.1224\n",
      "[150/600] Loss: 0.0143 MAE: 0.0551 Mean Error: 0.0108 STD: 0.1191\n",
      "[160/600] Loss: 0.0135 MAE: 0.0536 Mean Error: 0.0105 STD: 0.1159\n",
      "[170/600] Loss: 0.0128 MAE: 0.0523 Mean Error: 0.0103 STD: 0.1129\n",
      "[180/600] Loss: 0.0122 MAE: 0.0509 Mean Error: 0.0101 STD: 0.1099\n",
      "[190/600] Loss: 0.0116 MAE: 0.0496 Mean Error: 0.0099 STD: 0.1071\n",
      "[200/600] Loss: 0.0110 MAE: 0.0484 Mean Error: 0.0097 STD: 0.1043\n",
      "[210/600] Loss: 0.0104 MAE: 0.0472 Mean Error: 0.0095 STD: 0.1017\n",
      "[220/600] Loss: 0.0099 MAE: 0.0460 Mean Error: 0.0093 STD: 0.0991\n",
      "[230/600] Loss: 0.0094 MAE: 0.0449 Mean Error: 0.0091 STD: 0.0967\n",
      "[240/600] Loss: 0.0090 MAE: 0.0438 Mean Error: 0.0089 STD: 0.0944\n",
      "[250/600] Loss: 0.0086 MAE: 0.0428 Mean Error: 0.0087 STD: 0.0921\n",
      "[260/600] Loss: 0.0082 MAE: 0.0418 Mean Error: 0.0085 STD: 0.0900\n",
      "[270/600] Loss: 0.0078 MAE: 0.0409 Mean Error: 0.0084 STD: 0.0879\n",
      "[280/600] Loss: 0.0075 MAE: 0.0399 Mean Error: 0.0082 STD: 0.0859\n",
      "[290/600] Loss: 0.0071 MAE: 0.0391 Mean Error: 0.0081 STD: 0.0840\n",
      "[300/600] Loss: 0.0068 MAE: 0.0382 Mean Error: 0.0079 STD: 0.0822\n",
      "[310/600] Loss: 0.0065 MAE: 0.0374 Mean Error: 0.0078 STD: 0.0805\n",
      "[320/600] Loss: 0.0063 MAE: 0.0366 Mean Error: 0.0076 STD: 0.0788\n",
      "[330/600] Loss: 0.0060 MAE: 0.0359 Mean Error: 0.0075 STD: 0.0771\n",
      "[340/600] Loss: 0.0058 MAE: 0.0351 Mean Error: 0.0074 STD: 0.0756\n",
      "[350/600] Loss: 0.0055 MAE: 0.0344 Mean Error: 0.0072 STD: 0.0741\n",
      "[360/600] Loss: 0.0053 MAE: 0.0338 Mean Error: 0.0071 STD: 0.0726\n",
      "[370/600] Loss: 0.0051 MAE: 0.0331 Mean Error: 0.0070 STD: 0.0712\n",
      "[380/600] Loss: 0.0049 MAE: 0.0325 Mean Error: 0.0069 STD: 0.0699\n",
      "[390/600] Loss: 0.0047 MAE: 0.0319 Mean Error: 0.0068 STD: 0.0686\n",
      "[400/600] Loss: 0.0046 MAE: 0.0313 Mean Error: 0.0067 STD: 0.0673\n",
      "[410/600] Loss: 0.0044 MAE: 0.0308 Mean Error: 0.0066 STD: 0.0661\n",
      "[420/600] Loss: 0.0043 MAE: 0.0302 Mean Error: 0.0065 STD: 0.0649\n",
      "[430/600] Loss: 0.0041 MAE: 0.0297 Mean Error: 0.0064 STD: 0.0638\n",
      "[440/600] Loss: 0.0040 MAE: 0.0292 Mean Error: 0.0063 STD: 0.0627\n",
      "[450/600] Loss: 0.0038 MAE: 0.0287 Mean Error: 0.0062 STD: 0.0616\n",
      "[460/600] Loss: 0.0037 MAE: 0.0282 Mean Error: 0.0061 STD: 0.0606\n",
      "[470/600] Loss: 0.0036 MAE: 0.0278 Mean Error: 0.0060 STD: 0.0596\n",
      "[480/600] Loss: 0.0035 MAE: 0.0273 Mean Error: 0.0059 STD: 0.0586\n",
      "[490/600] Loss: 0.0034 MAE: 0.0269 Mean Error: 0.0058 STD: 0.0577\n",
      "[500/600] Loss: 0.0033 MAE: 0.0265 Mean Error: 0.0058 STD: 0.0568\n",
      "[510/600] Loss: 0.0032 MAE: 0.0261 Mean Error: 0.0057 STD: 0.0559\n",
      "[520/600] Loss: 0.0031 MAE: 0.0257 Mean Error: 0.0056 STD: 0.0551\n",
      "[530/600] Loss: 0.0030 MAE: 0.0253 Mean Error: 0.0055 STD: 0.0542\n",
      "[540/600] Loss: 0.0029 MAE: 0.0249 Mean Error: 0.0055 STD: 0.0534\n",
      "[550/600] Loss: 0.0028 MAE: 0.0246 Mean Error: 0.0054 STD: 0.0527\n",
      "[560/600] Loss: 0.0027 MAE: 0.0242 Mean Error: 0.0053 STD: 0.0519\n",
      "[570/600] Loss: 0.0026 MAE: 0.0239 Mean Error: 0.0053 STD: 0.0512\n",
      "[580/600] Loss: 0.0026 MAE: 0.0236 Mean Error: 0.0052 STD: 0.0504\n",
      "[590/600] Loss: 0.0025 MAE: 0.0232 Mean Error: 0.0051 STD: 0.0497\n",
      "[599/600] Loss: 0.0024 MAE: 0.0230 Mean Error: 0.0051 STD: 0.0491\n",
      "------------------------------------\n",
      "Training dataset with noise standard deviation 0.05\n",
      "[0/600] Loss: 0.2633 MAE: 0.4948 Mean Error: 0.4054 STD: 0.3146\n",
      "[10/600] Loss: 0.0447 MAE: 0.1597 Mean Error: 0.0999 STD: 0.1865\n",
      "[20/600] Loss: 0.0311 MAE: 0.0917 Mean Error: 0.0346 STD: 0.1729\n",
      "[30/600] Loss: 0.0284 MAE: 0.0781 Mean Error: 0.0228 STD: 0.1669\n",
      "[40/600] Loss: 0.0266 MAE: 0.0741 Mean Error: 0.0156 STD: 0.1624\n",
      "[50/600] Loss: 0.0251 MAE: 0.0714 Mean Error: 0.0144 STD: 0.1579\n",
      "[60/600] Loss: 0.0237 MAE: 0.0696 Mean Error: 0.0145 STD: 0.1534\n",
      "[70/600] Loss: 0.0224 MAE: 0.0681 Mean Error: 0.0131 STD: 0.1492\n",
      "[80/600] Loss: 0.0212 MAE: 0.0665 Mean Error: 0.0129 STD: 0.1451\n",
      "[90/600] Loss: 0.0201 MAE: 0.0648 Mean Error: 0.0125 STD: 0.1411\n",
      "[100/600] Loss: 0.0190 MAE: 0.0631 Mean Error: 0.0121 STD: 0.1372\n",
      "[110/600] Loss: 0.0179 MAE: 0.0614 Mean Error: 0.0118 STD: 0.1334\n",
      "[120/600] Loss: 0.0169 MAE: 0.0598 Mean Error: 0.0116 STD: 0.1297\n",
      "[130/600] Loss: 0.0160 MAE: 0.0582 Mean Error: 0.0113 STD: 0.1261\n",
      "[140/600] Loss: 0.0152 MAE: 0.0567 Mean Error: 0.0110 STD: 0.1227\n",
      "[150/600] Loss: 0.0144 MAE: 0.0552 Mean Error: 0.0108 STD: 0.1194\n",
      "[160/600] Loss: 0.0136 MAE: 0.0537 Mean Error: 0.0105 STD: 0.1162\n",
      "[170/600] Loss: 0.0129 MAE: 0.0523 Mean Error: 0.0103 STD: 0.1131\n",
      "[180/600] Loss: 0.0122 MAE: 0.0509 Mean Error: 0.0101 STD: 0.1101\n",
      "[190/600] Loss: 0.0116 MAE: 0.0496 Mean Error: 0.0099 STD: 0.1072\n",
      "[200/600] Loss: 0.0110 MAE: 0.0484 Mean Error: 0.0096 STD: 0.1045\n",
      "[210/600] Loss: 0.0105 MAE: 0.0471 Mean Error: 0.0094 STD: 0.1019\n",
      "[220/600] Loss: 0.0100 MAE: 0.0460 Mean Error: 0.0092 STD: 0.0994\n",
      "[230/600] Loss: 0.0095 MAE: 0.0449 Mean Error: 0.0090 STD: 0.0969\n",
      "[240/600] Loss: 0.0090 MAE: 0.0438 Mean Error: 0.0089 STD: 0.0946\n",
      "[250/600] Loss: 0.0086 MAE: 0.0427 Mean Error: 0.0087 STD: 0.0924\n",
      "[260/600] Loss: 0.0082 MAE: 0.0418 Mean Error: 0.0085 STD: 0.0902\n",
      "[270/600] Loss: 0.0078 MAE: 0.0408 Mean Error: 0.0083 STD: 0.0882\n",
      "[280/600] Loss: 0.0075 MAE: 0.0399 Mean Error: 0.0082 STD: 0.0862\n",
      "[290/600] Loss: 0.0072 MAE: 0.0390 Mean Error: 0.0080 STD: 0.0843\n",
      "[300/600] Loss: 0.0069 MAE: 0.0382 Mean Error: 0.0079 STD: 0.0825\n",
      "[310/600] Loss: 0.0066 MAE: 0.0374 Mean Error: 0.0077 STD: 0.0808\n",
      "[320/600] Loss: 0.0063 MAE: 0.0366 Mean Error: 0.0076 STD: 0.0791\n",
      "[330/600] Loss: 0.0061 MAE: 0.0358 Mean Error: 0.0074 STD: 0.0774\n",
      "[340/600] Loss: 0.0058 MAE: 0.0351 Mean Error: 0.0073 STD: 0.0759\n",
      "[350/600] Loss: 0.0056 MAE: 0.0344 Mean Error: 0.0072 STD: 0.0744\n",
      "[360/600] Loss: 0.0054 MAE: 0.0337 Mean Error: 0.0071 STD: 0.0729\n",
      "[370/600] Loss: 0.0052 MAE: 0.0331 Mean Error: 0.0069 STD: 0.0715\n",
      "[380/600] Loss: 0.0050 MAE: 0.0325 Mean Error: 0.0068 STD: 0.0702\n",
      "[390/600] Loss: 0.0048 MAE: 0.0319 Mean Error: 0.0067 STD: 0.0689\n",
      "[400/600] Loss: 0.0046 MAE: 0.0313 Mean Error: 0.0066 STD: 0.0676\n",
      "[410/600] Loss: 0.0044 MAE: 0.0307 Mean Error: 0.0065 STD: 0.0664\n",
      "[420/600] Loss: 0.0043 MAE: 0.0302 Mean Error: 0.0064 STD: 0.0652\n",
      "[430/600] Loss: 0.0041 MAE: 0.0297 Mean Error: 0.0063 STD: 0.0641\n",
      "[440/600] Loss: 0.0040 MAE: 0.0292 Mean Error: 0.0062 STD: 0.0630\n",
      "[450/600] Loss: 0.0039 MAE: 0.0287 Mean Error: 0.0061 STD: 0.0619\n",
      "[460/600] Loss: 0.0037 MAE: 0.0282 Mean Error: 0.0060 STD: 0.0609\n",
      "[470/600] Loss: 0.0036 MAE: 0.0277 Mean Error: 0.0060 STD: 0.0599\n",
      "[480/600] Loss: 0.0035 MAE: 0.0273 Mean Error: 0.0059 STD: 0.0589\n",
      "[490/600] Loss: 0.0034 MAE: 0.0269 Mean Error: 0.0058 STD: 0.0579\n",
      "[500/600] Loss: 0.0033 MAE: 0.0264 Mean Error: 0.0057 STD: 0.0570\n",
      "[510/600] Loss: 0.0032 MAE: 0.0260 Mean Error: 0.0056 STD: 0.0561\n",
      "[520/600] Loss: 0.0031 MAE: 0.0256 Mean Error: 0.0056 STD: 0.0553\n",
      "[530/600] Loss: 0.0030 MAE: 0.0253 Mean Error: 0.0055 STD: 0.0545\n",
      "[540/600] Loss: 0.0029 MAE: 0.0249 Mean Error: 0.0054 STD: 0.0536\n",
      "[550/600] Loss: 0.0028 MAE: 0.0245 Mean Error: 0.0054 STD: 0.0529\n",
      "[560/600] Loss: 0.0027 MAE: 0.0242 Mean Error: 0.0053 STD: 0.0521\n",
      "[570/600] Loss: 0.0027 MAE: 0.0238 Mean Error: 0.0052 STD: 0.0513\n",
      "[580/600] Loss: 0.0026 MAE: 0.0235 Mean Error: 0.0052 STD: 0.0506\n",
      "[590/600] Loss: 0.0025 MAE: 0.0232 Mean Error: 0.0051 STD: 0.0499\n",
      "[599/600] Loss: 0.0025 MAE: 0.0229 Mean Error: 0.0050 STD: 0.0493\n",
      "------------------------------------\n",
      "Training dataset with noise standard deviation 0.1\n",
      "[0/600] Loss: 0.2695 MAE: 0.5037 Mean Error: 0.4179 STD: 0.3081\n",
      "[10/600] Loss: 0.0459 MAE: 0.1646 Mean Error: 0.1014 STD: 0.1888\n",
      "[20/600] Loss: 0.0313 MAE: 0.0942 Mean Error: 0.0367 STD: 0.1730\n",
      "[30/600] Loss: 0.0284 MAE: 0.0797 Mean Error: 0.0237 STD: 0.1670\n",
      "[40/600] Loss: 0.0266 MAE: 0.0749 Mean Error: 0.0178 STD: 0.1622\n",
      "[50/600] Loss: 0.0250 MAE: 0.0721 Mean Error: 0.0155 STD: 0.1574\n",
      "[60/600] Loss: 0.0236 MAE: 0.0702 Mean Error: 0.0144 STD: 0.1528\n",
      "[70/600] Loss: 0.0222 MAE: 0.0684 Mean Error: 0.0138 STD: 0.1483\n",
      "[80/600] Loss: 0.0209 MAE: 0.0666 Mean Error: 0.0134 STD: 0.1438\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[90/600] Loss: 0.0196 MAE: 0.0648 Mean Error: 0.0128 STD: 0.1395\n",
      "[100/600] Loss: 0.0184 MAE: 0.0630 Mean Error: 0.0126 STD: 0.1353\n",
      "[110/600] Loss: 0.0173 MAE: 0.0612 Mean Error: 0.0123 STD: 0.1311\n",
      "[120/600] Loss: 0.0163 MAE: 0.0595 Mean Error: 0.0120 STD: 0.1272\n",
      "[130/600] Loss: 0.0153 MAE: 0.0578 Mean Error: 0.0117 STD: 0.1233\n",
      "[140/600] Loss: 0.0144 MAE: 0.0561 Mean Error: 0.0114 STD: 0.1196\n",
      "[150/600] Loss: 0.0136 MAE: 0.0545 Mean Error: 0.0111 STD: 0.1160\n",
      "[160/600] Loss: 0.0128 MAE: 0.0530 Mean Error: 0.0109 STD: 0.1126\n",
      "[170/600] Loss: 0.0120 MAE: 0.0515 Mean Error: 0.0106 STD: 0.1093\n",
      "[180/600] Loss: 0.0114 MAE: 0.0501 Mean Error: 0.0104 STD: 0.1061\n",
      "[190/600] Loss: 0.0107 MAE: 0.0487 Mean Error: 0.0102 STD: 0.1031\n",
      "[200/600] Loss: 0.0101 MAE: 0.0473 Mean Error: 0.0099 STD: 0.1001\n",
      "[210/600] Loss: 0.0096 MAE: 0.0461 Mean Error: 0.0097 STD: 0.0974\n",
      "[220/600] Loss: 0.0091 MAE: 0.0448 Mean Error: 0.0095 STD: 0.0947\n",
      "[230/600] Loss: 0.0086 MAE: 0.0437 Mean Error: 0.0093 STD: 0.0921\n",
      "[240/600] Loss: 0.0081 MAE: 0.0426 Mean Error: 0.0091 STD: 0.0897\n",
      "[250/600] Loss: 0.0077 MAE: 0.0415 Mean Error: 0.0090 STD: 0.0874\n",
      "[260/600] Loss: 0.0073 MAE: 0.0405 Mean Error: 0.0088 STD: 0.0851\n",
      "[270/600] Loss: 0.0070 MAE: 0.0395 Mean Error: 0.0086 STD: 0.0830\n",
      "[280/600] Loss: 0.0066 MAE: 0.0385 Mean Error: 0.0084 STD: 0.0809\n",
      "[290/600] Loss: 0.0063 MAE: 0.0376 Mean Error: 0.0083 STD: 0.0790\n",
      "[300/600] Loss: 0.0060 MAE: 0.0368 Mean Error: 0.0081 STD: 0.0771\n",
      "[310/600] Loss: 0.0057 MAE: 0.0359 Mean Error: 0.0080 STD: 0.0753\n",
      "[320/600] Loss: 0.0055 MAE: 0.0351 Mean Error: 0.0078 STD: 0.0736\n",
      "[330/600] Loss: 0.0052 MAE: 0.0344 Mean Error: 0.0077 STD: 0.0720\n",
      "[340/600] Loss: 0.0050 MAE: 0.0336 Mean Error: 0.0076 STD: 0.0704\n",
      "[350/600] Loss: 0.0048 MAE: 0.0329 Mean Error: 0.0074 STD: 0.0689\n",
      "[360/600] Loss: 0.0046 MAE: 0.0323 Mean Error: 0.0073 STD: 0.0674\n",
      "[370/600] Loss: 0.0044 MAE: 0.0316 Mean Error: 0.0072 STD: 0.0660\n",
      "[380/600] Loss: 0.0042 MAE: 0.0310 Mean Error: 0.0071 STD: 0.0647\n",
      "[390/600] Loss: 0.0041 MAE: 0.0304 Mean Error: 0.0070 STD: 0.0634\n",
      "[400/600] Loss: 0.0039 MAE: 0.0298 Mean Error: 0.0068 STD: 0.0621\n",
      "[410/600] Loss: 0.0038 MAE: 0.0292 Mean Error: 0.0067 STD: 0.0609\n",
      "[420/600] Loss: 0.0036 MAE: 0.0287 Mean Error: 0.0066 STD: 0.0598\n",
      "[430/600] Loss: 0.0035 MAE: 0.0282 Mean Error: 0.0065 STD: 0.0587\n",
      "[440/600] Loss: 0.0034 MAE: 0.0277 Mean Error: 0.0064 STD: 0.0576\n",
      "[450/600] Loss: 0.0032 MAE: 0.0272 Mean Error: 0.0063 STD: 0.0566\n",
      "[460/600] Loss: 0.0031 MAE: 0.0267 Mean Error: 0.0062 STD: 0.0556\n",
      "[470/600] Loss: 0.0030 MAE: 0.0263 Mean Error: 0.0062 STD: 0.0546\n",
      "[480/600] Loss: 0.0029 MAE: 0.0259 Mean Error: 0.0061 STD: 0.0537\n",
      "[490/600] Loss: 0.0028 MAE: 0.0254 Mean Error: 0.0060 STD: 0.0528\n",
      "[500/600] Loss: 0.0027 MAE: 0.0250 Mean Error: 0.0059 STD: 0.0519\n",
      "[510/600] Loss: 0.0026 MAE: 0.0246 Mean Error: 0.0058 STD: 0.0510\n",
      "[520/600] Loss: 0.0026 MAE: 0.0242 Mean Error: 0.0058 STD: 0.0502\n",
      "[530/600] Loss: 0.0025 MAE: 0.0239 Mean Error: 0.0057 STD: 0.0494\n",
      "[540/600] Loss: 0.0024 MAE: 0.0235 Mean Error: 0.0056 STD: 0.0487\n",
      "[550/600] Loss: 0.0023 MAE: 0.0232 Mean Error: 0.0055 STD: 0.0479\n",
      "[560/600] Loss: 0.0023 MAE: 0.0228 Mean Error: 0.0055 STD: 0.0472\n",
      "[570/600] Loss: 0.0022 MAE: 0.0225 Mean Error: 0.0054 STD: 0.0465\n",
      "[580/600] Loss: 0.0021 MAE: 0.0222 Mean Error: 0.0053 STD: 0.0458\n",
      "[590/600] Loss: 0.0021 MAE: 0.0219 Mean Error: 0.0053 STD: 0.0451\n",
      "[599/600] Loss: 0.0020 MAE: 0.0216 Mean Error: 0.0052 STD: 0.0446\n",
      "------------------------------------\n",
      "------------Fh_noise_array------------\n",
      "[[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]]\n",
      "------------Ffa_noise_array------------\n",
      "[[0.004329   0.00210526 0.00141243 0.0021254  0.00170213 0.00142146\n",
      "  0.001221   0.0010644  0.00094877 0.00085507]\n",
      " [0.004329   0.00210526 0.00141243 0.0021254  0.00170213 0.00142146\n",
      "  0.001221   0.0010644  0.00094877 0.00085507]\n",
      " [0.004329   0.00210526 0.00141243 0.0021254  0.00170213 0.00142146\n",
      "  0.001221   0.0010644  0.00094877 0.00085507]\n",
      " [0.         0.         0.         0.0010627  0.00085106 0.00071073\n",
      "  0.0006105  0.0005322  0.00047438 0.00042753]\n",
      " [0.         0.         0.         0.0010627  0.00085106 0.00071073\n",
      "  0.0006105  0.0005322  0.00047438 0.00042753]\n",
      " [0.004329   0.00210526 0.00141243 0.0021254  0.00170213 0.00142146\n",
      "  0.001221   0.0010644  0.00094877 0.00085507]\n",
      " [0.004329   0.00210526 0.00141243 0.0021254  0.00170213 0.00142146\n",
      "  0.001221   0.0010644  0.00094877 0.00085507]\n",
      " [0.004329   0.00210526 0.00141243 0.0021254  0.00170213 0.00142146\n",
      "  0.001221   0.0010644  0.00094877 0.00085507]\n",
      " [0.004329   0.00421053 0.00282486 0.0031881  0.00255319 0.00284293\n",
      "  0.002442   0.00212879 0.00189753 0.00171013]]\n"
     ]
    }
   ],
   "source": [
    "# Step 5\n",
    "def gaussian_noise(img, mean, sigma):\n",
    "    # Generate gauss noise\n",
    "    noise = np.random.normal(mean, sigma, img.shape)\n",
    "    # Add the noise to image\n",
    "    gaussian_out = img + noise\n",
    "    # Make the value between 0 and 1\n",
    "    gaussian_out = np.clip(gaussian_out, 0, 1)\n",
    "    return gaussian_out\n",
    "\n",
    "gaussian_dataset = np.zeros([9, 10, 256])\n",
    "std = [0.001, 0.002, 0.003, 0.005, 0.01, 0.02, 0.03, 0.05, 0.1]\n",
    "if not os.path.exists('./input_noise/'):\n",
    "    os.mkdir('./input_noise/')\n",
    "for j in range(9):\n",
    "    if not os.path.exists('./input_noise/' + str(std[j])):\n",
    "        os.mkdir('./input_noise/' + str(std[j]))\n",
    "    for i in range(10):\n",
    "        inputImage = dataSet[i]\n",
    "        gaussian_data = gaussian_noise(inputImage, 0, std[j])\n",
    "        img = gaussian_data.reshape(16, 16)*255\n",
    "        img = Image.fromarray(np.uint8(img))\n",
    "        img.convert(\"1\")\n",
    "        inputImageDir = './input_noise/' + str(std[j]) + '/' + str(i) + '.png'\n",
    "        img.save(inputImageDir)\n",
    "        gaussian_dataset[j][i] = gaussian_data\n",
    "gaussian_dataset = np.array(gaussian_dataset)\n",
    "\n",
    "\n",
    "Fh_noise_array = np.zeros([9, 10])\n",
    "Ffa_noise_array = np.zeros([9, 10])\n",
    "\n",
    "# Train 9 datasets with noise\n",
    "if not os.path.exists('./output_noise/'):\n",
    "    os.mkdir('./output_noise/')\n",
    "for j in range(9):\n",
    "    train_noise_dataset = DigitDataset(dataset = gaussian_dataset[j], label_list = dataSet)\n",
    "    train_noise_loader = DataLoader(dataset=train_noise_dataset, batch_size=batch_size, shuffle=False)\n",
    "    print('Training dataset with noise standard deviation ' + str(std[j]))\n",
    "#     model_noise = torch.load('./models/net_untrained.pkl') #  Load the model that trained before\n",
    "    model_noise = Perceptron(input_size=input_size, num_hidden=num_hidden, num_classes=num_classes).to(device)\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model_noise.parameters(), lr=learning_rate)\n",
    "    output_noise, model_noise = train(train_noise_loader, model_noise, num_epochs)   # Train\n",
    "    torch.save(model_noise, './models/net_trained_' + str(std[j]) + '.pkl')\n",
    "    model_noise = torch.load('./models/net_trained_' + str(std[j]) + '.pkl')\n",
    "#     output_noise = model_noise(torch.from_numpy(gaussian_dataset[j]).float()) # Use the model trained before to test\n",
    "    print('------------------------------------')\n",
    "    output_noise = model_noise(torch.from_numpy(dataSet).float())\n",
    "    output_noise_np = output_noise.detach().numpy()     # Get the output\n",
    "#     print(output_noise_np)\n",
    "    output_noise_dataset = np.zeros([10, 256])\n",
    "#     Make the output only has 0 or 1\n",
    "    \n",
    "    if not os.path.exists('./output_noise/' + str(std[j])):\n",
    "        os.mkdir('./output_noise/' + str(std[j]))\n",
    "    for i in range(10):\n",
    "        output_noise_img = output_noise_np[i].reshape(16, 16)*255\n",
    "        img = Image.fromarray(np.uint8(output_noise_img))\n",
    "        img = img.convert(\"1\")\n",
    "        output_path = './output_noise/' + str(std[j]) + '/' + str(i) + '.png'\n",
    "        img.save(output_path)\n",
    "        data = img.getdata()\n",
    "        array = np.array(data)/255\n",
    "        output_noise_dataset[i] = array\n",
    "#     Calculate Fh and Ffa\n",
    "    Fh = calculateFh(dataSet, output_noise_dataset)\n",
    "    Ffa = calculateFfa(dataSet, output_noise_dataset)\n",
    "    Fh_noise_array[j] = Fh\n",
    "    Ffa_noise_array[j] = Ffa\n",
    "print('------------Fh_noise_array------------')\n",
    "print(Fh_noise_array)\n",
    "print('------------Ffa_noise_array------------')\n",
    "print(Ffa_noise_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4010e235",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Step 6: Display Data from your Tests in Step 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "43b32ebc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No handles with labels found to put in legend.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "std_plot = [[i for _ in range(10)] for i in std]\n",
    "# noiseless\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.scatter([1,2,3,4,5,6,7,8,9,10], Fh_array, c=\"green\", alpha=0.3, edgecolors='none')\n",
    "ax.scatter([1,2,3,4,5,6,7,8,9,10], Ffa_array, c=\"blue\", alpha=0.3, edgecolors='none')\n",
    "ax.legend()\n",
    "ax.grid(True)\n",
    "plt.xlabel(\"image numbers\")\n",
    "plt.ylabel(\"Fh or Ffa values\")\n",
    "plt.yscale(\"symlog\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "93470ea0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# noise\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(std_plot, Fh_noise_array, c=\"green\", label=\"Fh\", alpha=0.3, edgecolors='none')\n",
    "ax.scatter(std_plot, Ffa_noise_array, c=\"blue\", label=\"Ffa\", alpha=0.3, edgecolors='none')\n",
    "plt.xlabel(\"stdev\")\n",
    "plt.ylabel(\"Fh or Ffa values\")\n",
    "plt.xscale(\"log\")\n",
    "plt.yscale(\"log\")\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4907d085",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
