{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0bcd5cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.autograd import Variable\n",
    "from sklearn.preprocessing import normalize\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "11838ef7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 10 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Step 1\n",
    "# Get the image and change every image to an 256-dimention vector\n",
    "dataSet = np.zeros([10, 1024])\n",
    "f=lambda x: x + 60 if x > 4 else x + 48\n",
    "for i in range(0, 10):\n",
    "    # TODO Change PNG to jpg\n",
    "    inputImageDir = './dataSet132/' + chr(f(i)) + str(132) + '.PNG'\n",
    "    inputImage = Image.open(inputImageDir)\n",
    "    inputImage = inputImage.convert(\"1\")\n",
    "    plt.subplot(2,5,i+1)\n",
    "    plt.imshow(inputImage)\n",
    "    inputImage.save(inputImageDir)\n",
    "    data = inputImage.getdata()\n",
    "    array = np.array(data)/255\n",
    "    dataSet[i] = array\n",
    "dataSet = np.array(dataSet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f1478743",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2\n",
    "# define a neural network\n",
    "class Perceptron(nn.Module):\n",
    "\n",
    "    def __init__(self, input_size, d_hidden, num_classes):\n",
    "        super(Perceptron, self).__init__()\n",
    "        self.linear0 = nn.Linear(input_size, d_hidden[0])\n",
    "        self.activate0 = nn.ReLU()\n",
    "        self.linear1 = nn.Linear(d_hidden[0], d_hidden[1])\n",
    "        self.activate1 = nn.ReLU()\n",
    "        self.linear2 = nn.Linear(d_hidden[1], d_hidden[2])\n",
    "        self.activate2 = nn.ReLU()\n",
    "        self.linear3 = nn.Linear(d_hidden[2], d_hidden[3])\n",
    "        self.activate3 = nn.ReLU()\n",
    "        self.linear4 = nn.Linear(d_hidden[3],num_classes)\n",
    "        self.activate4 = nn.Sigmoid()\n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        res = self.linear0(x)\n",
    "        res = self.activate0(res)\n",
    "        res = self.linear1(res)\n",
    "        res = self.activate1(res)\n",
    "        res = self.linear2(res)\n",
    "        res = self.activate2(res)\n",
    "        res = self.linear3(res)\n",
    "        res = self.activate3(res)\n",
    "        res = self.linear4(res)\n",
    "        res = self.activate4(res)\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "634a9eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DigitDataset(Dataset):\n",
    "    def __init__(self, dataset, label_list):\n",
    "        self.dataset = dataset\n",
    "        self.label_list = label_list\n",
    "    def __len__(self):\n",
    "        return len(self.label_list)\n",
    "    def __getitem__(self, idx):\n",
    "        data = self.dataset[idx]\n",
    "        label = self.label_list[idx]\n",
    "        return {\n",
    "            'data': torch.from_numpy(data).float(),\n",
    "            'label': torch.from_numpy(label).float()\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "fc25a099",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters of training\n",
    "learning_rate = 0.001\n",
    "# Train until the error become the lowest\n",
    "# get the optimization of MAE or MSE\n",
    "num_epochs = 600\n",
    "batch_size, input_size, num_classes = 10, 1024, 1024\n",
    "d_hidden=[320, 320, 320, 320]\n",
    "\n",
    "# Load the dataset\n",
    "train_dataset = DigitDataset(dataset = dataSet, label_list = dataSet)\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=False)\n",
    "device = torch.device('cpu')\n",
    "model = Perceptron(input_size=input_size, d_hidden=d_hidden,num_classes=num_classes).to(device)\n",
    "\n",
    "# Setup for noise training\n",
    "if not os.path.exists('./models21'):\n",
    "    os.mkdir('./models21')\n",
    "torch.save(model, './models21/net_untrained.pkl')\n",
    "for i in range(5):\n",
    "    if not os.path.exists('./models21/' + str(i) + '/'):\n",
    "        os.mkdir('./models21/' + str(i) + '/')\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "452b7bfa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0/600] Loss: 0.2502 MAE: 0.5001 Mean Error: 0.0945 STD: 0.4913\n",
      "[10/600] Loss: 0.1418 MAE: 0.2048 Mean Error: 0.0190 STD: 0.3761\n",
      "[20/600] Loss: 0.1258 MAE: 0.2479 Mean Error: 0.0036 STD: 0.3547\n",
      "[30/600] Loss: 0.1153 MAE: 0.2421 Mean Error: 0.0080 STD: 0.3394\n",
      "[40/600] Loss: 0.0898 MAE: 0.1781 Mean Error: 0.0009 STD: 0.2997\n",
      "[50/600] Loss: 0.0611 MAE: 0.1349 Mean Error: 0.0002 STD: 0.2472\n",
      "[60/600] Loss: 0.0386 MAE: 0.0812 Mean Error: -0.0013 STD: 0.1964\n",
      "[70/600] Loss: 0.0246 MAE: 0.0531 Mean Error: -0.0009 STD: 0.1567\n",
      "[80/600] Loss: 0.0141 MAE: 0.0298 Mean Error: -0.0018 STD: 0.1188\n",
      "[90/600] Loss: 0.0093 MAE: 0.0169 Mean Error: -0.0010 STD: 0.0964\n",
      "[100/600] Loss: 0.0070 MAE: 0.0106 Mean Error: -0.0008 STD: 0.0839\n",
      "[110/600] Loss: 0.0066 MAE: 0.0085 Mean Error: -0.0007 STD: 0.0812\n",
      "[120/600] Loss: 0.0061 MAE: 0.0076 Mean Error: -0.0011 STD: 0.0783\n",
      "[130/600] Loss: 0.0058 MAE: 0.0069 Mean Error: -0.0011 STD: 0.0761\n",
      "[140/600] Loss: 0.0057 MAE: 0.0067 Mean Error: -0.0009 STD: 0.0753\n",
      "[150/600] Loss: 0.0055 MAE: 0.0065 Mean Error: -0.0006 STD: 0.0739\n",
      "[160/600] Loss: 0.0053 MAE: 0.0062 Mean Error: -0.0008 STD: 0.0727\n",
      "[170/600] Loss: 0.0052 MAE: 0.0060 Mean Error: -0.0007 STD: 0.0721\n",
      "[180/600] Loss: 0.0052 MAE: 0.0059 Mean Error: -0.0007 STD: 0.0720\n",
      "[190/600] Loss: 0.0051 MAE: 0.0057 Mean Error: -0.0005 STD: 0.0713\n",
      "[200/600] Loss: 0.0051 MAE: 0.0057 Mean Error: -0.0006 STD: 0.0713\n",
      "[210/600] Loss: 0.0049 MAE: 0.0055 Mean Error: -0.0004 STD: 0.0700\n",
      "[220/600] Loss: 0.0049 MAE: 0.0055 Mean Error: -0.0004 STD: 0.0698\n",
      "[230/600] Loss: 0.0046 MAE: 0.0053 Mean Error: -0.0002 STD: 0.0680\n",
      "[240/600] Loss: 0.0046 MAE: 0.0052 Mean Error: -0.0003 STD: 0.0678\n",
      "[250/600] Loss: 0.0046 MAE: 0.0051 Mean Error: -0.0003 STD: 0.0678\n",
      "[260/600] Loss: 0.0046 MAE: 0.0051 Mean Error: -0.0003 STD: 0.0678\n",
      "[270/600] Loss: 0.0046 MAE: 0.0051 Mean Error: -0.0003 STD: 0.0678\n",
      "[280/600] Loss: 0.0046 MAE: 0.0051 Mean Error: -0.0003 STD: 0.0676\n",
      "[290/600] Loss: 0.0045 MAE: 0.0050 Mean Error: -0.0002 STD: 0.0671\n",
      "[300/600] Loss: 0.0045 MAE: 0.0050 Mean Error: -0.0002 STD: 0.0670\n",
      "[310/600] Loss: 0.0045 MAE: 0.0049 Mean Error: -0.0002 STD: 0.0670\n",
      "[320/600] Loss: 0.0044 MAE: 0.0048 Mean Error: -0.0001 STD: 0.0663\n",
      "[330/600] Loss: 0.0044 MAE: 0.0048 Mean Error: -0.0001 STD: 0.0661\n",
      "[340/600] Loss: 0.0043 MAE: 0.0048 Mean Error: -0.0003 STD: 0.0654\n",
      "[350/600] Loss: 0.0041 MAE: 0.0046 Mean Error: -0.0001 STD: 0.0642\n",
      "[360/600] Loss: 0.0041 MAE: 0.0045 Mean Error: -0.0002 STD: 0.0641\n",
      "[370/600] Loss: 0.0041 MAE: 0.0045 Mean Error: -0.0002 STD: 0.0641\n",
      "[380/600] Loss: 0.0041 MAE: 0.0045 Mean Error: -0.0002 STD: 0.0641\n",
      "[390/600] Loss: 0.0041 MAE: 0.0045 Mean Error: -0.0002 STD: 0.0641\n",
      "[400/600] Loss: 0.0041 MAE: 0.0044 Mean Error: -0.0002 STD: 0.0641\n",
      "[410/600] Loss: 0.0041 MAE: 0.0044 Mean Error: -0.0002 STD: 0.0641\n",
      "[420/600] Loss: 0.0041 MAE: 0.0044 Mean Error: -0.0002 STD: 0.0641\n",
      "[430/600] Loss: 0.0041 MAE: 0.0044 Mean Error: -0.0002 STD: 0.0641\n",
      "[440/600] Loss: 0.0041 MAE: 0.0044 Mean Error: -0.0002 STD: 0.0641\n",
      "[450/600] Loss: 0.0041 MAE: 0.0044 Mean Error: -0.0002 STD: 0.0641\n",
      "[460/600] Loss: 0.0041 MAE: 0.0044 Mean Error: -0.0002 STD: 0.0641\n",
      "[470/600] Loss: 0.0041 MAE: 0.0044 Mean Error: -0.0002 STD: 0.0641\n",
      "[480/600] Loss: 0.0041 MAE: 0.0044 Mean Error: -0.0002 STD: 0.0641\n",
      "[490/600] Loss: 0.0041 MAE: 0.0044 Mean Error: -0.0002 STD: 0.0641\n",
      "[500/600] Loss: 0.0041 MAE: 0.0044 Mean Error: -0.0002 STD: 0.0640\n",
      "[510/600] Loss: 0.0040 MAE: 0.0043 Mean Error: -0.0001 STD: 0.0633\n",
      "[520/600] Loss: 0.0040 MAE: 0.0043 Mean Error: -0.0001 STD: 0.0633\n",
      "[530/600] Loss: 0.0040 MAE: 0.0043 Mean Error: -0.0001 STD: 0.0633\n",
      "[540/600] Loss: 0.0040 MAE: 0.0043 Mean Error: -0.0001 STD: 0.0633\n",
      "[550/600] Loss: 0.0040 MAE: 0.0043 Mean Error: -0.0001 STD: 0.0633\n",
      "[560/600] Loss: 0.0040 MAE: 0.0043 Mean Error: -0.0001 STD: 0.0633\n",
      "[570/600] Loss: 0.0039 MAE: 0.0042 Mean Error: -0.0000 STD: 0.0626\n",
      "[580/600] Loss: 0.0039 MAE: 0.0042 Mean Error: -0.0000 STD: 0.0625\n",
      "[590/600] Loss: 0.0039 MAE: 0.0042 Mean Error: -0.0000 STD: 0.0625\n",
      "[599/600] Loss: 0.0039 MAE: 0.0042 Mean Error: -0.0000 STD: 0.0625\n"
     ]
    }
   ],
   "source": [
    "# Step 3\n",
    "model = Perceptron(input_size=input_size, d_hidden=d_hidden, num_classes=num_classes).to(device)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "def train(dataloader, model, num_epochs):\n",
    "    # research regarding epoch to explain why we need that many iterations (num_epochs)\n",
    "    for epoch in range(num_epochs):\n",
    "        losses = []\n",
    "        ERROR_Train = []\n",
    "        model.train() \n",
    "        for i, data in enumerate(dataloader, 0):\n",
    "            model.zero_grad()\n",
    "            # data['data'] is each image data in dataset\n",
    "            real_cpu, label_cpu = data['data'], data['label']\n",
    "#             if torch.cuda.is_available():\n",
    "#                 real_cpu = real_cpu.cuda() \n",
    "#                 label_cpu = label_cpu.cuda()\n",
    "            real = real_cpu\n",
    "            label = label_cpu\n",
    "            inputv = Variable(real)\n",
    "            labelv = Variable(label)\n",
    "            output = model(inputv)\n",
    "            err = criterion(output, labelv) \n",
    "            err.backward() \n",
    "            optimizer.step() \n",
    "\n",
    "            losses.append(err.data.item())\n",
    "            error = label - output.data\n",
    "#             print(error.shape)\n",
    "            ERROR_Train.extend(error)\n",
    "#         print(ERROR_Train)\n",
    "        MAE = torch.mean(torch.abs(torch.stack(ERROR_Train)))\n",
    "        ME = torch.mean(torch.stack(ERROR_Train))\n",
    "        STD = torch.std(torch.stack(ERROR_Train)) \n",
    "        if epoch % 10 == 0 or epoch == num_epochs - 1:\n",
    "            print('[%d/%d] Loss: %.4f MAE: %.4f Mean Error: %.4f STD: %.4f' % (epoch, num_epochs, np.average(losses), MAE, ME, STD))\n",
    "    return output, model\n",
    "\n",
    "# Start training        \n",
    "output, model = train(train_loader, model, num_epochs)\n",
    "# print(output.type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b9f4d3d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 1024)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 10 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Step 4\n",
    "# Step 4a\n",
    "# TODO create new for dataset 1\n",
    "if not os.path.exists('./ass2output32'):\n",
    "    os.mkdir('./ass2output32')\n",
    "output_np = output.detach().numpy()\n",
    "print(output_np.shape)\n",
    "torch.save(model, './models21/net_trained.pkl')\n",
    "output_dataset1 = np.zeros([10, 1024])\n",
    "for i in range(10):\n",
    "    output_img = output_np[i].reshape(32, 32)*255\n",
    "    img = Image.fromarray(np.uint8(output_img))\n",
    "    img = img.convert(\"1\")\n",
    "    plt.subplot(2,5,i+1)\n",
    "    plt.imshow(img)\n",
    "    output_path = './ass2output32/' + str(i) + '.png'\n",
    "    img.save(output_path)\n",
    "    data = img.getdata()\n",
    "    array = np.array(data)/255\n",
    "    output_dataset1[i] = array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "bd6f89d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 1024)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 10 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Step 4\n",
    "# Step 4b\n",
    "# Export the image after training\n",
    "# Before executing this block, create a folder called \"output\"\n",
    "\n",
    "# read dataset2 images\n",
    "dataSet2 = np.zeros([10, 1024])\n",
    "f=lambda x: x + 60 if x > 4 else x + 48\n",
    "for i in range(0, 10):\n",
    "    # TODO Change PNG to jpg\n",
    "    inputImageDir = './dataSet232/' + chr(f(i)) + str(232) + '.jpg'\n",
    "    inputImage = Image.open(inputImageDir)\n",
    "    inputImage = inputImage.convert(\"1\")\n",
    "#     plt.subplot(6,6,i+1)\n",
    "#     plt.imshow(inputImage)\n",
    "    inputImage.save(inputImageDir)\n",
    "    data = inputImage.getdata()\n",
    "    array = np.array(data)/255\n",
    "    dataSet2[i] = array\n",
    "dataSet2 = np.array(dataSet2)\n",
    "\n",
    "if not os.path.exists('./ass2output322'):\n",
    "    os.mkdir('./ass2output322')\n",
    "output_np = output.detach().numpy()\n",
    "print(output_np.shape)\n",
    "torch.save(model, './models21/net_trained.pkl')\n",
    "output_dataset2 = np.zeros([10, 1024])\n",
    "output_dataset2_model = model(torch.from_numpy(dataSet2).float())\n",
    "output_np = output_dataset2_model.detach().numpy()\n",
    "for i in range(10):\n",
    "    output_img = output_np[i].reshape(32, 32)*255\n",
    "    img = Image.fromarray(np.uint8(output_img))\n",
    "    img = img.convert(\"1\")\n",
    "    plt.subplot(2,5,i+1)\n",
    "    plt.imshow(img)\n",
    "    output_path2 = './ass2output322/' + str(i) + '.png'\n",
    "    img.save(output_path2)\n",
    "    data = img.getdata()\n",
    "    array = np.array(data)/255\n",
    "    output_dataset2[i] = array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b891b3a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Fh\n",
    "def calculateFh(input_dataset, output_dataset):\n",
    "    x, y = input_dataset.shape\n",
    "    Fh_denominator = 0    # Fh\n",
    "    Fh_numerator = 0      # Fh\n",
    "    Fh_array = np.zeros([x])\n",
    "    for j in range(x):\n",
    "        for i in range(y):\n",
    "            if input_dataset[j][i] == 0:\n",
    "                Fh_denominator = Fh_denominator + 1\n",
    "                if output_dataset[j][i] == 0:\n",
    "                    Fh_numerator = Fh_numerator + 1\n",
    "        Fh = Fh_numerator / Fh_denominator\n",
    "        Fh_array[j] = Fh\n",
    "    return Fh_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "3acfb30f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Ffa\n",
    "def calculateFfa(input_dataset, output_dataset):\n",
    "    x, y = input_dataset.shape\n",
    "    Ffa_denominator = 0    # Ffa\n",
    "    Ffa_numerator = 0      # Ffa\n",
    "    Ffa_array = np.zeros([x])\n",
    "    for j in range(x):\n",
    "        for i in range(y):\n",
    "            if input_dataset[j][i] == 1:\n",
    "                Ffa_denominator = Ffa_denominator + 1\n",
    "            if output_dataset[j][i] == 0 and input_dataset[j][i] == 1:\n",
    "                Ffa_numerator = Ffa_numerator + 1\n",
    "        Ffa = Ffa_numerator / Ffa_denominator\n",
    "        Ffa_array[j] = Ffa\n",
    "    return Ffa_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "41d276af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.91737892 0.92906574 0.8853211  0.80842279 0.80913429 0.77100054\n",
      " 0.76334951 0.75114719 0.75865103 0.74347714]\n",
      "[0.1589896  0.12108844 0.14681818 0.14662045 0.13961128 0.14081871\n",
      " 0.14735945 0.15264042 0.1581123  0.164233  ]\n"
     ]
    }
   ],
   "source": [
    "Fh_array1 = calculateFh(dataSet, output_dataset1)\n",
    "Ffa_array1 = calculateFfa(dataSet, output_dataset1)\n",
    "Fh_array2 = calculateFh(dataSet2, output_dataset2)\n",
    "Ffa_array2 = calculateFfa(dataSet2, output_dataset2)\n",
    "print(Fh_array2)\n",
    "print(Ffa_array2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "097f693d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# TODO: Step 4c: Answer 2 questions from canvas\n",
    "# Q1 Yes there is mismatch\n",
    "# Q2 Should we compare Dataset2 output vs Dataset1 input? 50-50\n",
    "# Why or why not?  (Justify your answer with analysis in the report generated in Step 8, below, and think about test, training, and validation datasets).\n",
    "# TODO visualize Y' (dataset2 output) with X (dataset1 input) to Justify answer (think about test, training)\n",
    "\n",
    "# Step 4d Graph Fh as a function of Ffa for each exemplar in the input dataset\n",
    "# Graph for dataset1\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#std_plot = [[i for _ in range(10)] for i in std]\n",
    "# noiseless\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "Image_name = ['1','2','3','4','5','A','B','C','D','E']\n",
    "#print(len(Image_name))\n",
    "#print(len(Ffa_array))\n",
    "# ax.scatter([1,2,3,4,5,6,7,8,9,10], Fh_array, c=\"green\", label=\"Fh\", alpha=0.3, edgecolors='none')\n",
    "# ax.scatter([1,2,3,4,5,6,7,8,9,10], Ffa_array, c=\"blue\", label=\"Ffa\", alpha=0.3, edgecolors='none')\n",
    "ax.scatter(Image_name, Fh_array1, c=\"green\", label=\"Fh\", alpha=0.3, edgecolors='none')\n",
    "ax.scatter(Image_name, Ffa_array1, c=\"blue\", label=\"Ffa\", alpha=0.3, edgecolors='none')\n",
    "ax.legend()\n",
    "ax.grid(True)\n",
    "plt.xlabel(\"image numbers\")\n",
    "plt.ylabel(\"Fh or Ffa values\")\n",
    "# plt.yscale(\"log\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "ed5250e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Graph for dataset2\n",
    "#std_plot = [[i for _ in range(10)] for i in std]\n",
    "# noiseless\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "Image_name = ['1','2','3','4','5','A','B','C','D','E']\n",
    "#print(len(Image_name))\n",
    "#print(len(Ffa_array))\n",
    "# ax.scatter([1,2,3,4,5,6,7,8,9,10], Fh_array, c=\"green\", label=\"Fh\", alpha=0.3, edgecolors='none')\n",
    "# ax.scatter([1,2,3,4,5,6,7,8,9,10], Ffa_array, c=\"blue\", label=\"Ffa\", alpha=0.3, edgecolors='none')\n",
    "ax.scatter(Image_name, Fh_array2, c=\"green\", label=\"Fh\", alpha=0.3, edgecolors='none')\n",
    "ax.scatter(Image_name, Ffa_array2, c=\"blue\", label=\"Ffa\", alpha=0.3, edgecolors='none')\n",
    "ax.legend()\n",
    "ax.grid(True)\n",
    "plt.xlabel(\"image numbers\")\n",
    "plt.ylabel(\"Fh or Ffa values\")\n",
    "# plt.yscale(\"log\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "01286dec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "Training dataset with noise standard deviation 0.001\n",
      "[0/600] Loss: 0.2499 MAE: 0.4998 Mean Error: 0.0943 STD: 0.4909\n",
      "[10/600] Loss: 0.1405 MAE: 0.2087 Mean Error: 0.0138 STD: 0.3746\n",
      "[20/600] Loss: 0.1260 MAE: 0.2491 Mean Error: 0.0059 STD: 0.3550\n",
      "[30/600] Loss: 0.1172 MAE: 0.2451 Mean Error: 0.0054 STD: 0.3423\n",
      "[40/600] Loss: 0.0922 MAE: 0.1838 Mean Error: -0.0031 STD: 0.3036\n",
      "[50/600] Loss: 0.0734 MAE: 0.1582 Mean Error: -0.0025 STD: 0.2708\n",
      "[60/600] Loss: 0.0416 MAE: 0.1002 Mean Error: 0.0001 STD: 0.2039\n",
      "[70/600] Loss: 0.0163 MAE: 0.0412 Mean Error: -0.0018 STD: 0.1276\n",
      "[80/600] Loss: 0.0080 MAE: 0.0170 Mean Error: 0.0002 STD: 0.0897\n",
      "[90/600] Loss: 0.0061 MAE: 0.0094 Mean Error: 0.0004 STD: 0.0779\n",
      "[100/600] Loss: 0.0054 MAE: 0.0072 Mean Error: -0.0000 STD: 0.0737\n",
      "[110/600] Loss: 0.0053 MAE: 0.0065 Mean Error: 0.0002 STD: 0.0728\n",
      "[120/600] Loss: 0.0052 MAE: 0.0062 Mean Error: 0.0001 STD: 0.0721\n",
      "[130/600] Loss: 0.0052 MAE: 0.0060 Mean Error: 0.0001 STD: 0.0720\n",
      "[140/600] Loss: 0.0052 MAE: 0.0059 Mean Error: 0.0001 STD: 0.0720\n",
      "[150/600] Loss: 0.0052 MAE: 0.0058 Mean Error: 0.0001 STD: 0.0720\n",
      "[160/600] Loss: 0.0052 MAE: 0.0058 Mean Error: 0.0001 STD: 0.0720\n",
      "[170/600] Loss: 0.0052 MAE: 0.0058 Mean Error: 0.0001 STD: 0.0720\n",
      "[180/600] Loss: 0.0052 MAE: 0.0057 Mean Error: 0.0001 STD: 0.0720\n",
      "[190/600] Loss: 0.0052 MAE: 0.0057 Mean Error: 0.0001 STD: 0.0720\n",
      "[200/600] Loss: 0.0052 MAE: 0.0057 Mean Error: 0.0001 STD: 0.0720\n",
      "[210/600] Loss: 0.0052 MAE: 0.0057 Mean Error: 0.0001 STD: 0.0720\n",
      "[220/600] Loss: 0.0052 MAE: 0.0057 Mean Error: 0.0001 STD: 0.0720\n",
      "[230/600] Loss: 0.0052 MAE: 0.0057 Mean Error: 0.0001 STD: 0.0720\n",
      "[240/600] Loss: 0.0052 MAE: 0.0056 Mean Error: 0.0001 STD: 0.0720\n",
      "[250/600] Loss: 0.0052 MAE: 0.0056 Mean Error: 0.0001 STD: 0.0720\n",
      "[260/600] Loss: 0.0052 MAE: 0.0056 Mean Error: 0.0001 STD: 0.0720\n",
      "[270/600] Loss: 0.0052 MAE: 0.0056 Mean Error: 0.0001 STD: 0.0720\n",
      "[280/600] Loss: 0.0052 MAE: 0.0056 Mean Error: 0.0001 STD: 0.0720\n",
      "[290/600] Loss: 0.0051 MAE: 0.0055 Mean Error: 0.0002 STD: 0.0713\n",
      "[300/600] Loss: 0.0051 MAE: 0.0055 Mean Error: 0.0002 STD: 0.0713\n",
      "[310/600] Loss: 0.0051 MAE: 0.0055 Mean Error: 0.0002 STD: 0.0713\n",
      "[320/600] Loss: 0.0051 MAE: 0.0055 Mean Error: 0.0002 STD: 0.0713\n",
      "[330/600] Loss: 0.0051 MAE: 0.0055 Mean Error: 0.0002 STD: 0.0713\n",
      "[340/600] Loss: 0.0051 MAE: 0.0055 Mean Error: 0.0002 STD: 0.0713\n",
      "[350/600] Loss: 0.0051 MAE: 0.0055 Mean Error: 0.0002 STD: 0.0713\n",
      "[360/600] Loss: 0.0051 MAE: 0.0054 Mean Error: 0.0002 STD: 0.0713\n",
      "[370/600] Loss: 0.0051 MAE: 0.0054 Mean Error: 0.0002 STD: 0.0713\n",
      "[380/600] Loss: 0.0051 MAE: 0.0054 Mean Error: 0.0002 STD: 0.0713\n",
      "[390/600] Loss: 0.0051 MAE: 0.0054 Mean Error: 0.0002 STD: 0.0713\n",
      "[400/600] Loss: 0.0051 MAE: 0.0054 Mean Error: 0.0002 STD: 0.0713\n",
      "[410/600] Loss: 0.0051 MAE: 0.0054 Mean Error: 0.0002 STD: 0.0713\n",
      "[420/600] Loss: 0.0051 MAE: 0.0054 Mean Error: 0.0002 STD: 0.0713\n",
      "[430/600] Loss: 0.0050 MAE: 0.0055 Mean Error: 0.0000 STD: 0.0706\n",
      "[440/600] Loss: 0.0050 MAE: 0.0053 Mean Error: 0.0001 STD: 0.0706\n",
      "[450/600] Loss: 0.0050 MAE: 0.0053 Mean Error: 0.0001 STD: 0.0706\n",
      "[460/600] Loss: 0.0050 MAE: 0.0053 Mean Error: 0.0001 STD: 0.0706\n",
      "[470/600] Loss: 0.0050 MAE: 0.0053 Mean Error: 0.0001 STD: 0.0706\n",
      "[480/600] Loss: 0.0050 MAE: 0.0053 Mean Error: 0.0001 STD: 0.0706\n",
      "[490/600] Loss: 0.0050 MAE: 0.0053 Mean Error: 0.0001 STD: 0.0706\n",
      "[500/600] Loss: 0.0050 MAE: 0.0053 Mean Error: 0.0001 STD: 0.0706\n",
      "[510/600] Loss: 0.0050 MAE: 0.0053 Mean Error: 0.0001 STD: 0.0706\n",
      "[520/600] Loss: 0.0050 MAE: 0.0053 Mean Error: 0.0001 STD: 0.0706\n",
      "[530/600] Loss: 0.0050 MAE: 0.0053 Mean Error: 0.0001 STD: 0.0706\n",
      "[540/600] Loss: 0.0050 MAE: 0.0053 Mean Error: 0.0001 STD: 0.0706\n",
      "[550/600] Loss: 0.0050 MAE: 0.0052 Mean Error: 0.0001 STD: 0.0706\n",
      "[560/600] Loss: 0.0050 MAE: 0.0052 Mean Error: 0.0001 STD: 0.0706\n",
      "[570/600] Loss: 0.0050 MAE: 0.0052 Mean Error: 0.0001 STD: 0.0706\n",
      "[580/600] Loss: 0.0050 MAE: 0.0052 Mean Error: 0.0001 STD: 0.0706\n",
      "[590/600] Loss: 0.0050 MAE: 0.0052 Mean Error: 0.0001 STD: 0.0706\n",
      "[599/600] Loss: 0.0050 MAE: 0.0052 Mean Error: 0.0001 STD: 0.0706\n",
      "------------------------------------\n",
      "Training dataset with noise standard deviation 0.002\n",
      "[0/600] Loss: 0.2500 MAE: 0.4999 Mean Error: 0.0946 STD: 0.4910\n",
      "[10/600] Loss: 0.1411 MAE: 0.2075 Mean Error: 0.0117 STD: 0.3755\n",
      "[20/600] Loss: 0.1248 MAE: 0.2504 Mean Error: 0.0056 STD: 0.3532\n",
      "[30/600] Loss: 0.1066 MAE: 0.2246 Mean Error: 0.0043 STD: 0.3265\n",
      "[40/600] Loss: 0.0894 MAE: 0.1843 Mean Error: -0.0009 STD: 0.2990\n",
      "[50/600] Loss: 0.0753 MAE: 0.1572 Mean Error: -0.0022 STD: 0.2744\n",
      "[60/600] Loss: 0.0538 MAE: 0.1245 Mean Error: -0.0015 STD: 0.2320\n",
      "[70/600] Loss: 0.0236 MAE: 0.0605 Mean Error: 0.0009 STD: 0.1537\n",
      "[80/600] Loss: 0.0086 MAE: 0.0207 Mean Error: 0.0014 STD: 0.0925\n",
      "[90/600] Loss: 0.0056 MAE: 0.0097 Mean Error: 0.0012 STD: 0.0747\n",
      "[100/600] Loss: 0.0051 MAE: 0.0067 Mean Error: 0.0016 STD: 0.0711\n",
      "[110/600] Loss: 0.0048 MAE: 0.0059 Mean Error: 0.0018 STD: 0.0694\n",
      "[120/600] Loss: 0.0046 MAE: 0.0055 Mean Error: 0.0016 STD: 0.0680\n",
      "[130/600] Loss: 0.0046 MAE: 0.0053 Mean Error: 0.0016 STD: 0.0678\n",
      "[140/600] Loss: 0.0046 MAE: 0.0052 Mean Error: 0.0016 STD: 0.0678\n",
      "[150/600] Loss: 0.0046 MAE: 0.0051 Mean Error: 0.0016 STD: 0.0678\n",
      "[160/600] Loss: 0.0046 MAE: 0.0051 Mean Error: 0.0016 STD: 0.0678\n",
      "[170/600] Loss: 0.0046 MAE: 0.0051 Mean Error: 0.0016 STD: 0.0678\n",
      "[180/600] Loss: 0.0046 MAE: 0.0051 Mean Error: 0.0016 STD: 0.0678\n",
      "[190/600] Loss: 0.0046 MAE: 0.0050 Mean Error: 0.0016 STD: 0.0678\n",
      "[200/600] Loss: 0.0046 MAE: 0.0050 Mean Error: 0.0016 STD: 0.0678\n",
      "[210/600] Loss: 0.0046 MAE: 0.0050 Mean Error: 0.0016 STD: 0.0677\n",
      "[220/600] Loss: 0.0046 MAE: 0.0050 Mean Error: 0.0016 STD: 0.0677\n",
      "[230/600] Loss: 0.0045 MAE: 0.0050 Mean Error: 0.0016 STD: 0.0671\n",
      "[240/600] Loss: 0.0045 MAE: 0.0049 Mean Error: 0.0015 STD: 0.0670\n",
      "[250/600] Loss: 0.0045 MAE: 0.0049 Mean Error: 0.0015 STD: 0.0670\n",
      "[260/600] Loss: 0.0045 MAE: 0.0049 Mean Error: 0.0016 STD: 0.0670\n",
      "[270/600] Loss: 0.0045 MAE: 0.0049 Mean Error: 0.0015 STD: 0.0670\n",
      "[280/600] Loss: 0.0045 MAE: 0.0049 Mean Error: 0.0015 STD: 0.0670\n",
      "[290/600] Loss: 0.0045 MAE: 0.0049 Mean Error: 0.0015 STD: 0.0669\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[300/600] Loss: 0.0044 MAE: 0.0048 Mean Error: 0.0015 STD: 0.0663\n",
      "[310/600] Loss: 0.0044 MAE: 0.0048 Mean Error: 0.0014 STD: 0.0663\n",
      "[320/600] Loss: 0.0044 MAE: 0.0047 Mean Error: 0.0014 STD: 0.0663\n",
      "[330/600] Loss: 0.0044 MAE: 0.0047 Mean Error: 0.0014 STD: 0.0663\n",
      "[340/600] Loss: 0.0044 MAE: 0.0047 Mean Error: 0.0014 STD: 0.0663\n",
      "[350/600] Loss: 0.0044 MAE: 0.0047 Mean Error: 0.0014 STD: 0.0663\n",
      "[360/600] Loss: 0.0044 MAE: 0.0047 Mean Error: 0.0014 STD: 0.0663\n",
      "[370/600] Loss: 0.0044 MAE: 0.0047 Mean Error: 0.0014 STD: 0.0663\n",
      "[380/600] Loss: 0.0043 MAE: 0.0047 Mean Error: 0.0013 STD: 0.0656\n",
      "[390/600] Loss: 0.0043 MAE: 0.0047 Mean Error: 0.0013 STD: 0.0656\n",
      "[400/600] Loss: 0.0043 MAE: 0.0046 Mean Error: 0.0014 STD: 0.0656\n",
      "[410/600] Loss: 0.0042 MAE: 0.0046 Mean Error: 0.0013 STD: 0.0649\n",
      "[420/600] Loss: 0.0042 MAE: 0.0046 Mean Error: 0.0012 STD: 0.0648\n",
      "[430/600] Loss: 0.0042 MAE: 0.0045 Mean Error: 0.0012 STD: 0.0648\n",
      "[440/600] Loss: 0.0040 MAE: 0.0044 Mean Error: 0.0010 STD: 0.0633\n",
      "[450/600] Loss: 0.0040 MAE: 0.0044 Mean Error: 0.0011 STD: 0.0633\n",
      "[460/600] Loss: 0.0040 MAE: 0.0043 Mean Error: 0.0011 STD: 0.0633\n",
      "[470/600] Loss: 0.0039 MAE: 0.0043 Mean Error: 0.0009 STD: 0.0626\n",
      "[480/600] Loss: 0.0039 MAE: 0.0042 Mean Error: 0.0010 STD: 0.0625\n",
      "[490/600] Loss: 0.0038 MAE: 0.0042 Mean Error: 0.0011 STD: 0.0618\n",
      "[500/600] Loss: 0.0038 MAE: 0.0041 Mean Error: 0.0011 STD: 0.0617\n",
      "[510/600] Loss: 0.0038 MAE: 0.0041 Mean Error: 0.0011 STD: 0.0617\n",
      "[520/600] Loss: 0.0038 MAE: 0.0041 Mean Error: 0.0011 STD: 0.0617\n",
      "[530/600] Loss: 0.0038 MAE: 0.0041 Mean Error: 0.0011 STD: 0.0617\n",
      "[540/600] Loss: 0.0038 MAE: 0.0040 Mean Error: 0.0011 STD: 0.0617\n",
      "[550/600] Loss: 0.0038 MAE: 0.0040 Mean Error: 0.0011 STD: 0.0617\n",
      "[560/600] Loss: 0.0038 MAE: 0.0040 Mean Error: 0.0011 STD: 0.0617\n",
      "[570/600] Loss: 0.0038 MAE: 0.0040 Mean Error: 0.0011 STD: 0.0617\n",
      "[580/600] Loss: 0.0038 MAE: 0.0040 Mean Error: 0.0011 STD: 0.0617\n",
      "[590/600] Loss: 0.0038 MAE: 0.0040 Mean Error: 0.0011 STD: 0.0617\n",
      "[599/600] Loss: 0.0038 MAE: 0.0040 Mean Error: 0.0011 STD: 0.0617\n",
      "------------------------------------\n",
      "Training dataset with noise standard deviation 0.003\n",
      "[0/600] Loss: 0.2502 MAE: 0.5001 Mean Error: 0.0941 STD: 0.4913\n",
      "[10/600] Loss: 0.1387 MAE: 0.2126 Mean Error: 0.0043 STD: 0.3725\n",
      "[20/600] Loss: 0.1221 MAE: 0.2555 Mean Error: 0.0047 STD: 0.3495\n",
      "[30/600] Loss: 0.0997 MAE: 0.2038 Mean Error: 0.0007 STD: 0.3157\n",
      "[40/600] Loss: 0.0814 MAE: 0.1707 Mean Error: -0.0017 STD: 0.2854\n",
      "[50/600] Loss: 0.0577 MAE: 0.1300 Mean Error: -0.0047 STD: 0.2402\n",
      "[60/600] Loss: 0.0307 MAE: 0.0718 Mean Error: -0.0006 STD: 0.1752\n",
      "[70/600] Loss: 0.0126 MAE: 0.0318 Mean Error: 0.0010 STD: 0.1121\n",
      "[80/600] Loss: 0.0063 MAE: 0.0132 Mean Error: 0.0013 STD: 0.0794\n",
      "[90/600] Loss: 0.0049 MAE: 0.0075 Mean Error: 0.0011 STD: 0.0701\n",
      "[100/600] Loss: 0.0047 MAE: 0.0061 Mean Error: 0.0011 STD: 0.0687\n",
      "[110/600] Loss: 0.0046 MAE: 0.0056 Mean Error: 0.0011 STD: 0.0681\n",
      "[120/600] Loss: 0.0045 MAE: 0.0053 Mean Error: 0.0011 STD: 0.0671\n",
      "[130/600] Loss: 0.0045 MAE: 0.0052 Mean Error: 0.0012 STD: 0.0670\n",
      "[140/600] Loss: 0.0042 MAE: 0.0050 Mean Error: 0.0008 STD: 0.0648\n",
      "[150/600] Loss: 0.0041 MAE: 0.0048 Mean Error: 0.0009 STD: 0.0641\n",
      "[160/600] Loss: 0.0041 MAE: 0.0047 Mean Error: 0.0010 STD: 0.0641\n",
      "[170/600] Loss: 0.0040 MAE: 0.0046 Mean Error: 0.0009 STD: 0.0633\n",
      "[180/600] Loss: 0.0040 MAE: 0.0045 Mean Error: 0.0009 STD: 0.0633\n",
      "[190/600] Loss: 0.0040 MAE: 0.0045 Mean Error: 0.0009 STD: 0.0633\n",
      "[200/600] Loss: 0.0040 MAE: 0.0045 Mean Error: 0.0009 STD: 0.0633\n",
      "[210/600] Loss: 0.0040 MAE: 0.0044 Mean Error: 0.0009 STD: 0.0633\n",
      "[220/600] Loss: 0.0039 MAE: 0.0044 Mean Error: 0.0008 STD: 0.0625\n",
      "[230/600] Loss: 0.0039 MAE: 0.0044 Mean Error: 0.0008 STD: 0.0625\n",
      "[240/600] Loss: 0.0039 MAE: 0.0043 Mean Error: 0.0008 STD: 0.0625\n",
      "[250/600] Loss: 0.0039 MAE: 0.0043 Mean Error: 0.0008 STD: 0.0624\n",
      "[260/600] Loss: 0.0038 MAE: 0.0043 Mean Error: 0.0007 STD: 0.0617\n",
      "[270/600] Loss: 0.0038 MAE: 0.0042 Mean Error: 0.0007 STD: 0.0617\n",
      "[280/600] Loss: 0.0038 MAE: 0.0042 Mean Error: 0.0007 STD: 0.0617\n",
      "[290/600] Loss: 0.0038 MAE: 0.0042 Mean Error: 0.0007 STD: 0.0617\n",
      "[300/600] Loss: 0.0038 MAE: 0.0042 Mean Error: 0.0007 STD: 0.0617\n",
      "[310/600] Loss: 0.0037 MAE: 0.0042 Mean Error: 0.0008 STD: 0.0611\n",
      "[320/600] Loss: 0.0037 MAE: 0.0042 Mean Error: 0.0008 STD: 0.0609\n",
      "[330/600] Loss: 0.0037 MAE: 0.0041 Mean Error: 0.0008 STD: 0.0609\n",
      "[340/600] Loss: 0.0037 MAE: 0.0041 Mean Error: 0.0008 STD: 0.0609\n",
      "[350/600] Loss: 0.0037 MAE: 0.0040 Mean Error: 0.0008 STD: 0.0609\n",
      "[360/600] Loss: 0.0037 MAE: 0.0040 Mean Error: 0.0008 STD: 0.0609\n",
      "[370/600] Loss: 0.0037 MAE: 0.0040 Mean Error: 0.0008 STD: 0.0609\n",
      "[380/600] Loss: 0.0037 MAE: 0.0040 Mean Error: 0.0008 STD: 0.0609\n",
      "[390/600] Loss: 0.0037 MAE: 0.0040 Mean Error: 0.0008 STD: 0.0609\n",
      "[400/600] Loss: 0.0037 MAE: 0.0040 Mean Error: 0.0008 STD: 0.0609\n",
      "[410/600] Loss: 0.0037 MAE: 0.0040 Mean Error: 0.0008 STD: 0.0609\n",
      "[420/600] Loss: 0.0037 MAE: 0.0040 Mean Error: 0.0008 STD: 0.0609\n",
      "[430/600] Loss: 0.0037 MAE: 0.0040 Mean Error: 0.0008 STD: 0.0609\n",
      "[440/600] Loss: 0.0037 MAE: 0.0040 Mean Error: 0.0008 STD: 0.0609\n",
      "[450/600] Loss: 0.0037 MAE: 0.0040 Mean Error: 0.0008 STD: 0.0609\n",
      "[460/600] Loss: 0.0037 MAE: 0.0039 Mean Error: 0.0008 STD: 0.0609\n",
      "[470/600] Loss: 0.0037 MAE: 0.0039 Mean Error: 0.0008 STD: 0.0609\n",
      "[480/600] Loss: 0.0037 MAE: 0.0039 Mean Error: 0.0008 STD: 0.0609\n",
      "[490/600] Loss: 0.0037 MAE: 0.0039 Mean Error: 0.0008 STD: 0.0609\n",
      "[500/600] Loss: 0.0037 MAE: 0.0039 Mean Error: 0.0008 STD: 0.0609\n",
      "[510/600] Loss: 0.0037 MAE: 0.0039 Mean Error: 0.0008 STD: 0.0609\n",
      "[520/600] Loss: 0.0037 MAE: 0.0039 Mean Error: 0.0008 STD: 0.0609\n",
      "[530/600] Loss: 0.0037 MAE: 0.0039 Mean Error: 0.0008 STD: 0.0609\n",
      "[540/600] Loss: 0.0037 MAE: 0.0039 Mean Error: 0.0008 STD: 0.0609\n",
      "[550/600] Loss: 0.0037 MAE: 0.0039 Mean Error: 0.0008 STD: 0.0609\n",
      "[560/600] Loss: 0.0037 MAE: 0.0039 Mean Error: 0.0008 STD: 0.0609\n",
      "[570/600] Loss: 0.0037 MAE: 0.0039 Mean Error: 0.0008 STD: 0.0609\n",
      "[580/600] Loss: 0.0037 MAE: 0.0039 Mean Error: 0.0008 STD: 0.0609\n",
      "[590/600] Loss: 0.0037 MAE: 0.0039 Mean Error: 0.0008 STD: 0.0609\n",
      "[599/600] Loss: 0.0037 MAE: 0.0039 Mean Error: 0.0008 STD: 0.0609\n",
      "------------------------------------\n",
      "Training dataset with noise standard deviation 0.005\n",
      "[0/600] Loss: 0.2502 MAE: 0.5001 Mean Error: 0.0939 STD: 0.4913\n",
      "[10/600] Loss: 0.1410 MAE: 0.2075 Mean Error: 0.0140 STD: 0.3753\n",
      "[20/600] Loss: 0.1259 MAE: 0.2562 Mean Error: 0.0059 STD: 0.3548\n",
      "[30/600] Loss: 0.1159 MAE: 0.2467 Mean Error: 0.0054 STD: 0.3404\n",
      "[40/600] Loss: 0.0939 MAE: 0.1901 Mean Error: -0.0053 STD: 0.3063\n",
      "[50/600] Loss: 0.0786 MAE: 0.1650 Mean Error: -0.0019 STD: 0.2803\n",
      "[60/600] Loss: 0.0546 MAE: 0.1220 Mean Error: 0.0011 STD: 0.2337\n",
      "[70/600] Loss: 0.0285 MAE: 0.0651 Mean Error: -0.0028 STD: 0.1687\n",
      "[80/600] Loss: 0.0141 MAE: 0.0305 Mean Error: -0.0016 STD: 0.1186\n",
      "[90/600] Loss: 0.0092 MAE: 0.0161 Mean Error: -0.0012 STD: 0.0958\n",
      "[100/600] Loss: 0.0077 MAE: 0.0109 Mean Error: -0.0010 STD: 0.0878\n",
      "[110/600] Loss: 0.0072 MAE: 0.0090 Mean Error: -0.0009 STD: 0.0850\n",
      "[120/600] Loss: 0.0071 MAE: 0.0083 Mean Error: -0.0010 STD: 0.0840\n",
      "[130/600] Loss: 0.0070 MAE: 0.0081 Mean Error: -0.0009 STD: 0.0840\n",
      "[140/600] Loss: 0.0070 MAE: 0.0079 Mean Error: -0.0010 STD: 0.0839\n",
      "[150/600] Loss: 0.0070 MAE: 0.0078 Mean Error: -0.0010 STD: 0.0839\n",
      "[160/600] Loss: 0.0070 MAE: 0.0077 Mean Error: -0.0010 STD: 0.0839\n",
      "[170/600] Loss: 0.0070 MAE: 0.0077 Mean Error: -0.0010 STD: 0.0839\n",
      "[180/600] Loss: 0.0070 MAE: 0.0077 Mean Error: -0.0010 STD: 0.0839\n",
      "[190/600] Loss: 0.0070 MAE: 0.0076 Mean Error: -0.0010 STD: 0.0839\n",
      "[200/600] Loss: 0.0070 MAE: 0.0076 Mean Error: -0.0010 STD: 0.0839\n",
      "[210/600] Loss: 0.0070 MAE: 0.0076 Mean Error: -0.0010 STD: 0.0839\n",
      "[220/600] Loss: 0.0070 MAE: 0.0076 Mean Error: -0.0010 STD: 0.0839\n",
      "[230/600] Loss: 0.0069 MAE: 0.0076 Mean Error: -0.0007 STD: 0.0829\n",
      "[240/600] Loss: 0.0068 MAE: 0.0074 Mean Error: -0.0008 STD: 0.0822\n",
      "[250/600] Loss: 0.0067 MAE: 0.0074 Mean Error: -0.0009 STD: 0.0821\n",
      "[260/600] Loss: 0.0067 MAE: 0.0073 Mean Error: -0.0009 STD: 0.0821\n",
      "[270/600] Loss: 0.0067 MAE: 0.0073 Mean Error: -0.0009 STD: 0.0821\n",
      "[280/600] Loss: 0.0067 MAE: 0.0072 Mean Error: -0.0009 STD: 0.0821\n",
      "[290/600] Loss: 0.0067 MAE: 0.0072 Mean Error: -0.0009 STD: 0.0821\n",
      "[300/600] Loss: 0.0067 MAE: 0.0072 Mean Error: -0.0009 STD: 0.0821\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[310/600] Loss: 0.0067 MAE: 0.0072 Mean Error: -0.0009 STD: 0.0821\n",
      "[320/600] Loss: 0.0067 MAE: 0.0071 Mean Error: -0.0009 STD: 0.0821\n",
      "[330/600] Loss: 0.0067 MAE: 0.0071 Mean Error: -0.0009 STD: 0.0821\n",
      "[340/600] Loss: 0.0067 MAE: 0.0071 Mean Error: -0.0009 STD: 0.0821\n",
      "[350/600] Loss: 0.0067 MAE: 0.0071 Mean Error: -0.0009 STD: 0.0821\n",
      "[360/600] Loss: 0.0067 MAE: 0.0071 Mean Error: -0.0009 STD: 0.0821\n",
      "[370/600] Loss: 0.0067 MAE: 0.0071 Mean Error: -0.0009 STD: 0.0820\n",
      "[380/600] Loss: 0.0066 MAE: 0.0071 Mean Error: -0.0007 STD: 0.0815\n",
      "[390/600] Loss: 0.0066 MAE: 0.0071 Mean Error: -0.0008 STD: 0.0815\n",
      "[400/600] Loss: 0.0066 MAE: 0.0070 Mean Error: -0.0007 STD: 0.0809\n",
      "[410/600] Loss: 0.0065 MAE: 0.0070 Mean Error: -0.0007 STD: 0.0808\n",
      "[420/600] Loss: 0.0064 MAE: 0.0069 Mean Error: -0.0007 STD: 0.0802\n",
      "[430/600] Loss: 0.0064 MAE: 0.0069 Mean Error: -0.0007 STD: 0.0797\n",
      "[440/600] Loss: 0.0064 MAE: 0.0068 Mean Error: -0.0007 STD: 0.0797\n",
      "[450/600] Loss: 0.0063 MAE: 0.0067 Mean Error: -0.0007 STD: 0.0797\n",
      "[460/600] Loss: 0.0063 MAE: 0.0067 Mean Error: -0.0007 STD: 0.0797\n",
      "[470/600] Loss: 0.0063 MAE: 0.0067 Mean Error: -0.0007 STD: 0.0797\n",
      "[480/600] Loss: 0.0063 MAE: 0.0067 Mean Error: -0.0007 STD: 0.0797\n",
      "[490/600] Loss: 0.0063 MAE: 0.0066 Mean Error: -0.0007 STD: 0.0797\n",
      "[500/600] Loss: 0.0063 MAE: 0.0066 Mean Error: -0.0007 STD: 0.0797\n",
      "[510/600] Loss: 0.0063 MAE: 0.0066 Mean Error: -0.0007 STD: 0.0797\n",
      "[520/600] Loss: 0.0063 MAE: 0.0066 Mean Error: -0.0007 STD: 0.0797\n",
      "[530/600] Loss: 0.0063 MAE: 0.0066 Mean Error: -0.0007 STD: 0.0797\n",
      "[540/600] Loss: 0.0063 MAE: 0.0066 Mean Error: -0.0007 STD: 0.0797\n",
      "[550/600] Loss: 0.0063 MAE: 0.0066 Mean Error: -0.0007 STD: 0.0797\n",
      "[560/600] Loss: 0.0063 MAE: 0.0066 Mean Error: -0.0007 STD: 0.0797\n",
      "[570/600] Loss: 0.0063 MAE: 0.0066 Mean Error: -0.0007 STD: 0.0797\n",
      "[580/600] Loss: 0.0063 MAE: 0.0066 Mean Error: -0.0007 STD: 0.0797\n",
      "[590/600] Loss: 0.0063 MAE: 0.0066 Mean Error: -0.0007 STD: 0.0797\n",
      "[599/600] Loss: 0.0063 MAE: 0.0066 Mean Error: -0.0006 STD: 0.0796\n",
      "------------------------------------\n",
      "Training dataset with noise standard deviation 0.01\n",
      "[0/600] Loss: 0.2498 MAE: 0.4997 Mean Error: 0.0939 STD: 0.4909\n",
      "[10/600] Loss: 0.1398 MAE: 0.2112 Mean Error: 0.0103 STD: 0.3737\n",
      "[20/600] Loss: 0.1217 MAE: 0.2542 Mean Error: 0.0062 STD: 0.3488\n",
      "[30/600] Loss: 0.0997 MAE: 0.2039 Mean Error: 0.0039 STD: 0.3158\n",
      "[40/600] Loss: 0.0851 MAE: 0.1728 Mean Error: -0.0024 STD: 0.2917\n",
      "[50/600] Loss: 0.0695 MAE: 0.1488 Mean Error: 0.0005 STD: 0.2636\n",
      "[60/600] Loss: 0.0415 MAE: 0.0984 Mean Error: -0.0022 STD: 0.2037\n",
      "[70/600] Loss: 0.0188 MAE: 0.0461 Mean Error: -0.0001 STD: 0.1373\n",
      "[80/600] Loss: 0.0090 MAE: 0.0196 Mean Error: -0.0001 STD: 0.0951\n",
      "[90/600] Loss: 0.0065 MAE: 0.0109 Mean Error: 0.0008 STD: 0.0809\n",
      "[100/600] Loss: 0.0060 MAE: 0.0081 Mean Error: 0.0009 STD: 0.0772\n",
      "[110/600] Loss: 0.0059 MAE: 0.0072 Mean Error: 0.0008 STD: 0.0768\n",
      "[120/600] Loss: 0.0059 MAE: 0.0069 Mean Error: 0.0008 STD: 0.0766\n",
      "[130/600] Loss: 0.0059 MAE: 0.0067 Mean Error: 0.0008 STD: 0.0766\n",
      "[140/600] Loss: 0.0059 MAE: 0.0066 Mean Error: 0.0008 STD: 0.0766\n",
      "[150/600] Loss: 0.0059 MAE: 0.0066 Mean Error: 0.0008 STD: 0.0766\n",
      "[160/600] Loss: 0.0059 MAE: 0.0066 Mean Error: 0.0008 STD: 0.0766\n",
      "[170/600] Loss: 0.0059 MAE: 0.0065 Mean Error: 0.0008 STD: 0.0766\n",
      "[180/600] Loss: 0.0059 MAE: 0.0065 Mean Error: 0.0008 STD: 0.0766\n",
      "[190/600] Loss: 0.0059 MAE: 0.0065 Mean Error: 0.0008 STD: 0.0766\n",
      "[200/600] Loss: 0.0059 MAE: 0.0065 Mean Error: 0.0008 STD: 0.0766\n",
      "[210/600] Loss: 0.0059 MAE: 0.0065 Mean Error: 0.0008 STD: 0.0765\n",
      "[220/600] Loss: 0.0058 MAE: 0.0064 Mean Error: 0.0008 STD: 0.0760\n",
      "[230/600] Loss: 0.0056 MAE: 0.0062 Mean Error: 0.0007 STD: 0.0748\n",
      "[240/600] Loss: 0.0056 MAE: 0.0062 Mean Error: 0.0007 STD: 0.0747\n",
      "[250/600] Loss: 0.0056 MAE: 0.0061 Mean Error: 0.0007 STD: 0.0746\n",
      "[260/600] Loss: 0.0056 MAE: 0.0061 Mean Error: 0.0007 STD: 0.0746\n",
      "[270/600] Loss: 0.0056 MAE: 0.0061 Mean Error: 0.0007 STD: 0.0746\n",
      "[280/600] Loss: 0.0056 MAE: 0.0060 Mean Error: 0.0007 STD: 0.0746\n",
      "[290/600] Loss: 0.0056 MAE: 0.0060 Mean Error: 0.0007 STD: 0.0746\n",
      "[300/600] Loss: 0.0056 MAE: 0.0060 Mean Error: 0.0007 STD: 0.0746\n",
      "[310/600] Loss: 0.0056 MAE: 0.0060 Mean Error: 0.0007 STD: 0.0746\n",
      "[320/600] Loss: 0.0056 MAE: 0.0060 Mean Error: 0.0007 STD: 0.0746\n",
      "[330/600] Loss: 0.0056 MAE: 0.0060 Mean Error: 0.0007 STD: 0.0746\n",
      "[340/600] Loss: 0.0055 MAE: 0.0059 Mean Error: 0.0006 STD: 0.0740\n",
      "[350/600] Loss: 0.0055 MAE: 0.0058 Mean Error: 0.0006 STD: 0.0740\n",
      "[360/600] Loss: 0.0055 MAE: 0.0058 Mean Error: 0.0006 STD: 0.0740\n",
      "[370/600] Loss: 0.0055 MAE: 0.0058 Mean Error: 0.0006 STD: 0.0740\n",
      "[380/600] Loss: 0.0055 MAE: 0.0058 Mean Error: 0.0006 STD: 0.0740\n",
      "[390/600] Loss: 0.0055 MAE: 0.0058 Mean Error: 0.0006 STD: 0.0740\n",
      "[400/600] Loss: 0.0055 MAE: 0.0058 Mean Error: 0.0006 STD: 0.0740\n",
      "[410/600] Loss: 0.0055 MAE: 0.0058 Mean Error: 0.0006 STD: 0.0740\n",
      "[420/600] Loss: 0.0055 MAE: 0.0058 Mean Error: 0.0006 STD: 0.0740\n",
      "[430/600] Loss: 0.0055 MAE: 0.0058 Mean Error: 0.0006 STD: 0.0740\n",
      "[440/600] Loss: 0.0055 MAE: 0.0058 Mean Error: 0.0006 STD: 0.0740\n",
      "[450/600] Loss: 0.0055 MAE: 0.0058 Mean Error: 0.0006 STD: 0.0740\n",
      "[460/600] Loss: 0.0054 MAE: 0.0058 Mean Error: 0.0006 STD: 0.0735\n",
      "[470/600] Loss: 0.0054 MAE: 0.0057 Mean Error: 0.0007 STD: 0.0733\n",
      "[480/600] Loss: 0.0054 MAE: 0.0057 Mean Error: 0.0007 STD: 0.0733\n",
      "[490/600] Loss: 0.0054 MAE: 0.0057 Mean Error: 0.0007 STD: 0.0733\n",
      "[500/600] Loss: 0.0054 MAE: 0.0057 Mean Error: 0.0007 STD: 0.0733\n",
      "[510/600] Loss: 0.0053 MAE: 0.0056 Mean Error: 0.0008 STD: 0.0727\n",
      "[520/600] Loss: 0.0053 MAE: 0.0056 Mean Error: 0.0008 STD: 0.0726\n",
      "[530/600] Loss: 0.0053 MAE: 0.0056 Mean Error: 0.0008 STD: 0.0726\n",
      "[540/600] Loss: 0.0053 MAE: 0.0056 Mean Error: 0.0008 STD: 0.0726\n",
      "[550/600] Loss: 0.0053 MAE: 0.0056 Mean Error: 0.0008 STD: 0.0726\n",
      "[560/600] Loss: 0.0052 MAE: 0.0056 Mean Error: 0.0008 STD: 0.0719\n",
      "[570/600] Loss: 0.0050 MAE: 0.0054 Mean Error: 0.0006 STD: 0.0706\n",
      "[580/600] Loss: 0.0050 MAE: 0.0054 Mean Error: 0.0007 STD: 0.0706\n",
      "[590/600] Loss: 0.0050 MAE: 0.0053 Mean Error: 0.0007 STD: 0.0706\n",
      "[599/600] Loss: 0.0050 MAE: 0.0053 Mean Error: 0.0007 STD: 0.0706\n",
      "------------------------------------\n",
      "Training dataset with noise standard deviation 0.02\n",
      "[0/600] Loss: 0.2503 MAE: 0.5002 Mean Error: 0.0941 STD: 0.4914\n",
      "[10/600] Loss: 0.1420 MAE: 0.2065 Mean Error: 0.0117 STD: 0.3767\n",
      "[20/600] Loss: 0.1228 MAE: 0.2498 Mean Error: 0.0059 STD: 0.3504\n",
      "[30/600] Loss: 0.0995 MAE: 0.2013 Mean Error: 0.0008 STD: 0.3155\n",
      "[40/600] Loss: 0.0821 MAE: 0.1684 Mean Error: -0.0038 STD: 0.2865\n",
      "[50/600] Loss: 0.0554 MAE: 0.1258 Mean Error: -0.0075 STD: 0.2352\n",
      "[60/600] Loss: 0.0240 MAE: 0.0574 Mean Error: -0.0036 STD: 0.1550\n",
      "[70/600] Loss: 0.0118 MAE: 0.0246 Mean Error: -0.0012 STD: 0.1085\n",
      "[80/600] Loss: 0.0080 MAE: 0.0133 Mean Error: -0.0010 STD: 0.0894\n",
      "[90/600] Loss: 0.0072 MAE: 0.0095 Mean Error: -0.0009 STD: 0.0851\n",
      "[100/600] Loss: 0.0069 MAE: 0.0082 Mean Error: -0.0007 STD: 0.0831\n",
      "[110/600] Loss: 0.0067 MAE: 0.0077 Mean Error: -0.0011 STD: 0.0818\n",
      "[120/600] Loss: 0.0064 MAE: 0.0074 Mean Error: -0.0009 STD: 0.0802\n",
      "[130/600] Loss: 0.0062 MAE: 0.0071 Mean Error: -0.0007 STD: 0.0787\n",
      "[140/600] Loss: 0.0061 MAE: 0.0069 Mean Error: -0.0006 STD: 0.0784\n",
      "[150/600] Loss: 0.0060 MAE: 0.0068 Mean Error: -0.0006 STD: 0.0778\n",
      "[160/600] Loss: 0.0060 MAE: 0.0066 Mean Error: -0.0005 STD: 0.0772\n",
      "[170/600] Loss: 0.0060 MAE: 0.0066 Mean Error: -0.0005 STD: 0.0772\n",
      "[180/600] Loss: 0.0059 MAE: 0.0065 Mean Error: -0.0004 STD: 0.0767\n",
      "[190/600] Loss: 0.0059 MAE: 0.0064 Mean Error: -0.0004 STD: 0.0766\n",
      "[200/600] Loss: 0.0059 MAE: 0.0064 Mean Error: -0.0004 STD: 0.0766\n",
      "[210/600] Loss: 0.0059 MAE: 0.0063 Mean Error: -0.0004 STD: 0.0766\n",
      "[220/600] Loss: 0.0059 MAE: 0.0063 Mean Error: -0.0004 STD: 0.0766\n",
      "[230/600] Loss: 0.0059 MAE: 0.0063 Mean Error: -0.0004 STD: 0.0766\n",
      "[240/600] Loss: 0.0059 MAE: 0.0063 Mean Error: -0.0004 STD: 0.0765\n",
      "[250/600] Loss: 0.0058 MAE: 0.0063 Mean Error: -0.0003 STD: 0.0760\n",
      "[260/600] Loss: 0.0058 MAE: 0.0062 Mean Error: -0.0003 STD: 0.0759\n",
      "[270/600] Loss: 0.0058 MAE: 0.0062 Mean Error: -0.0003 STD: 0.0759\n",
      "[280/600] Loss: 0.0057 MAE: 0.0062 Mean Error: -0.0004 STD: 0.0753\n",
      "[290/600] Loss: 0.0057 MAE: 0.0061 Mean Error: -0.0004 STD: 0.0752\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[300/600] Loss: 0.0056 MAE: 0.0061 Mean Error: -0.0005 STD: 0.0747\n",
      "[310/600] Loss: 0.0056 MAE: 0.0060 Mean Error: -0.0005 STD: 0.0746\n",
      "[320/600] Loss: 0.0056 MAE: 0.0060 Mean Error: -0.0005 STD: 0.0746\n",
      "[330/600] Loss: 0.0055 MAE: 0.0060 Mean Error: -0.0003 STD: 0.0740\n",
      "[340/600] Loss: 0.0055 MAE: 0.0059 Mean Error: -0.0004 STD: 0.0740\n",
      "[350/600] Loss: 0.0055 MAE: 0.0058 Mean Error: -0.0004 STD: 0.0740\n",
      "[360/600] Loss: 0.0055 MAE: 0.0058 Mean Error: -0.0004 STD: 0.0740\n",
      "[370/600] Loss: 0.0055 MAE: 0.0058 Mean Error: -0.0004 STD: 0.0740\n",
      "[380/600] Loss: 0.0055 MAE: 0.0058 Mean Error: -0.0004 STD: 0.0740\n",
      "[390/600] Loss: 0.0055 MAE: 0.0058 Mean Error: -0.0004 STD: 0.0740\n",
      "[400/600] Loss: 0.0055 MAE: 0.0058 Mean Error: -0.0004 STD: 0.0740\n",
      "[410/600] Loss: 0.0055 MAE: 0.0057 Mean Error: -0.0004 STD: 0.0740\n",
      "[420/600] Loss: 0.0055 MAE: 0.0057 Mean Error: -0.0004 STD: 0.0740\n",
      "[430/600] Loss: 0.0055 MAE: 0.0057 Mean Error: -0.0004 STD: 0.0740\n",
      "[440/600] Loss: 0.0055 MAE: 0.0057 Mean Error: -0.0004 STD: 0.0740\n",
      "[450/600] Loss: 0.0055 MAE: 0.0057 Mean Error: -0.0004 STD: 0.0740\n",
      "[460/600] Loss: 0.0055 MAE: 0.0057 Mean Error: -0.0004 STD: 0.0740\n",
      "[470/600] Loss: 0.0055 MAE: 0.0057 Mean Error: -0.0004 STD: 0.0740\n",
      "[480/600] Loss: 0.0055 MAE: 0.0057 Mean Error: -0.0004 STD: 0.0740\n",
      "[490/600] Loss: 0.0055 MAE: 0.0057 Mean Error: -0.0004 STD: 0.0740\n",
      "[500/600] Loss: 0.0055 MAE: 0.0057 Mean Error: -0.0004 STD: 0.0740\n",
      "[510/600] Loss: 0.0055 MAE: 0.0058 Mean Error: -0.0004 STD: 0.0740\n",
      "[520/600] Loss: 0.0054 MAE: 0.0057 Mean Error: -0.0003 STD: 0.0733\n",
      "[530/600] Loss: 0.0054 MAE: 0.0057 Mean Error: -0.0003 STD: 0.0733\n",
      "[540/600] Loss: 0.0054 MAE: 0.0057 Mean Error: -0.0003 STD: 0.0733\n",
      "[550/600] Loss: 0.0054 MAE: 0.0056 Mean Error: -0.0003 STD: 0.0733\n",
      "[560/600] Loss: 0.0054 MAE: 0.0056 Mean Error: -0.0003 STD: 0.0733\n",
      "[570/600] Loss: 0.0054 MAE: 0.0056 Mean Error: -0.0003 STD: 0.0733\n",
      "[580/600] Loss: 0.0054 MAE: 0.0056 Mean Error: -0.0003 STD: 0.0733\n",
      "[590/600] Loss: 0.0054 MAE: 0.0056 Mean Error: -0.0003 STD: 0.0733\n",
      "[599/600] Loss: 0.0054 MAE: 0.0056 Mean Error: -0.0003 STD: 0.0733\n",
      "------------------------------------\n",
      "Training dataset with noise standard deviation 0.03\n",
      "[0/600] Loss: 0.2495 MAE: 0.4994 Mean Error: 0.0935 STD: 0.4907\n",
      "[10/600] Loss: 0.1399 MAE: 0.2090 Mean Error: 0.0077 STD: 0.3740\n",
      "[20/600] Loss: 0.1251 MAE: 0.2534 Mean Error: 0.0051 STD: 0.3537\n",
      "[30/600] Loss: 0.1085 MAE: 0.2296 Mean Error: 0.0013 STD: 0.3295\n",
      "[40/600] Loss: 0.0901 MAE: 0.1830 Mean Error: 0.0001 STD: 0.3003\n",
      "[50/600] Loss: 0.0741 MAE: 0.1569 Mean Error: -0.0005 STD: 0.2723\n",
      "[60/600] Loss: 0.0486 MAE: 0.1106 Mean Error: -0.0035 STD: 0.2204\n",
      "[70/600] Loss: 0.0250 MAE: 0.0605 Mean Error: -0.0023 STD: 0.1582\n",
      "[80/600] Loss: 0.0110 MAE: 0.0268 Mean Error: 0.0011 STD: 0.1051\n",
      "[90/600] Loss: 0.0065 MAE: 0.0131 Mean Error: 0.0007 STD: 0.0803\n",
      "[100/600] Loss: 0.0054 MAE: 0.0083 Mean Error: 0.0006 STD: 0.0737\n",
      "[110/600] Loss: 0.0051 MAE: 0.0068 Mean Error: 0.0005 STD: 0.0714\n",
      "[120/600] Loss: 0.0050 MAE: 0.0062 Mean Error: 0.0004 STD: 0.0705\n",
      "[130/600] Loss: 0.0049 MAE: 0.0058 Mean Error: 0.0004 STD: 0.0700\n",
      "[140/600] Loss: 0.0048 MAE: 0.0056 Mean Error: 0.0003 STD: 0.0693\n",
      "[150/600] Loss: 0.0048 MAE: 0.0055 Mean Error: 0.0003 STD: 0.0692\n",
      "[160/600] Loss: 0.0048 MAE: 0.0054 Mean Error: 0.0003 STD: 0.0692\n",
      "[170/600] Loss: 0.0048 MAE: 0.0054 Mean Error: 0.0003 STD: 0.0692\n",
      "[180/600] Loss: 0.0047 MAE: 0.0053 Mean Error: 0.0004 STD: 0.0685\n",
      "[190/600] Loss: 0.0047 MAE: 0.0053 Mean Error: 0.0004 STD: 0.0685\n",
      "[200/600] Loss: 0.0047 MAE: 0.0052 Mean Error: 0.0004 STD: 0.0685\n",
      "[210/600] Loss: 0.0047 MAE: 0.0052 Mean Error: 0.0004 STD: 0.0685\n",
      "[220/600] Loss: 0.0047 MAE: 0.0052 Mean Error: 0.0004 STD: 0.0685\n",
      "[230/600] Loss: 0.0046 MAE: 0.0051 Mean Error: 0.0003 STD: 0.0678\n",
      "[240/600] Loss: 0.0046 MAE: 0.0051 Mean Error: 0.0003 STD: 0.0678\n",
      "[250/600] Loss: 0.0046 MAE: 0.0051 Mean Error: 0.0003 STD: 0.0678\n",
      "[260/600] Loss: 0.0046 MAE: 0.0050 Mean Error: 0.0003 STD: 0.0678\n",
      "[270/600] Loss: 0.0046 MAE: 0.0050 Mean Error: 0.0003 STD: 0.0678\n",
      "[280/600] Loss: 0.0046 MAE: 0.0050 Mean Error: 0.0003 STD: 0.0678\n",
      "[290/600] Loss: 0.0046 MAE: 0.0050 Mean Error: 0.0003 STD: 0.0678\n",
      "[300/600] Loss: 0.0046 MAE: 0.0050 Mean Error: 0.0003 STD: 0.0678\n",
      "[310/600] Loss: 0.0046 MAE: 0.0050 Mean Error: 0.0003 STD: 0.0678\n",
      "[320/600] Loss: 0.0046 MAE: 0.0050 Mean Error: 0.0003 STD: 0.0678\n",
      "[330/600] Loss: 0.0046 MAE: 0.0049 Mean Error: 0.0003 STD: 0.0678\n",
      "[340/600] Loss: 0.0046 MAE: 0.0049 Mean Error: 0.0003 STD: 0.0678\n",
      "[350/600] Loss: 0.0046 MAE: 0.0049 Mean Error: 0.0003 STD: 0.0678\n",
      "[360/600] Loss: 0.0046 MAE: 0.0049 Mean Error: 0.0003 STD: 0.0678\n",
      "[370/600] Loss: 0.0046 MAE: 0.0049 Mean Error: 0.0003 STD: 0.0678\n",
      "[380/600] Loss: 0.0046 MAE: 0.0049 Mean Error: 0.0003 STD: 0.0678\n",
      "[390/600] Loss: 0.0046 MAE: 0.0049 Mean Error: 0.0003 STD: 0.0678\n",
      "[400/600] Loss: 0.0046 MAE: 0.0049 Mean Error: 0.0003 STD: 0.0678\n",
      "[410/600] Loss: 0.0045 MAE: 0.0048 Mean Error: 0.0004 STD: 0.0671\n",
      "[420/600] Loss: 0.0045 MAE: 0.0049 Mean Error: 0.0004 STD: 0.0670\n",
      "[430/600] Loss: 0.0045 MAE: 0.0049 Mean Error: 0.0004 STD: 0.0670\n",
      "[440/600] Loss: 0.0045 MAE: 0.0048 Mean Error: 0.0004 STD: 0.0670\n",
      "[450/600] Loss: 0.0044 MAE: 0.0048 Mean Error: 0.0004 STD: 0.0665\n",
      "[460/600] Loss: 0.0044 MAE: 0.0048 Mean Error: 0.0005 STD: 0.0663\n",
      "[470/600] Loss: 0.0044 MAE: 0.0048 Mean Error: 0.0005 STD: 0.0663\n",
      "[480/600] Loss: 0.0044 MAE: 0.0047 Mean Error: 0.0005 STD: 0.0663\n",
      "[490/600] Loss: 0.0044 MAE: 0.0047 Mean Error: 0.0005 STD: 0.0663\n",
      "[500/600] Loss: 0.0044 MAE: 0.0047 Mean Error: 0.0005 STD: 0.0663\n",
      "[510/600] Loss: 0.0044 MAE: 0.0047 Mean Error: 0.0005 STD: 0.0663\n",
      "[520/600] Loss: 0.0044 MAE: 0.0047 Mean Error: 0.0005 STD: 0.0663\n",
      "[530/600] Loss: 0.0044 MAE: 0.0047 Mean Error: 0.0005 STD: 0.0663\n",
      "[540/600] Loss: 0.0044 MAE: 0.0047 Mean Error: 0.0005 STD: 0.0663\n",
      "[550/600] Loss: 0.0044 MAE: 0.0046 Mean Error: 0.0005 STD: 0.0663\n",
      "[560/600] Loss: 0.0044 MAE: 0.0046 Mean Error: 0.0005 STD: 0.0663\n",
      "[570/600] Loss: 0.0044 MAE: 0.0046 Mean Error: 0.0005 STD: 0.0663\n",
      "[580/600] Loss: 0.0044 MAE: 0.0046 Mean Error: 0.0005 STD: 0.0663\n",
      "[590/600] Loss: 0.0044 MAE: 0.0046 Mean Error: 0.0005 STD: 0.0663\n",
      "[599/600] Loss: 0.0044 MAE: 0.0046 Mean Error: 0.0005 STD: 0.0663\n",
      "------------------------------------\n",
      "Training dataset with noise standard deviation 0.05\n",
      "[0/600] Loss: 0.2500 MAE: 0.4999 Mean Error: 0.0936 STD: 0.4912\n",
      "[10/600] Loss: 0.1398 MAE: 0.2105 Mean Error: 0.0031 STD: 0.3739\n",
      "[20/600] Loss: 0.1215 MAE: 0.2409 Mean Error: 0.0031 STD: 0.3486\n",
      "[30/600] Loss: 0.0981 MAE: 0.1926 Mean Error: -0.0000 STD: 0.3133\n",
      "[40/600] Loss: 0.0820 MAE: 0.1714 Mean Error: 0.0001 STD: 0.2864\n",
      "[50/600] Loss: 0.0553 MAE: 0.1235 Mean Error: -0.0061 STD: 0.2351\n",
      "[60/600] Loss: 0.0304 MAE: 0.0686 Mean Error: -0.0027 STD: 0.1744\n",
      "[70/600] Loss: 0.0137 MAE: 0.0311 Mean Error: 0.0007 STD: 0.1170\n",
      "[80/600] Loss: 0.0085 MAE: 0.0157 Mean Error: 0.0008 STD: 0.0922\n",
      "[90/600] Loss: 0.0069 MAE: 0.0101 Mean Error: 0.0008 STD: 0.0829\n",
      "[100/600] Loss: 0.0064 MAE: 0.0082 Mean Error: 0.0009 STD: 0.0802\n",
      "[110/600] Loss: 0.0062 MAE: 0.0074 Mean Error: 0.0008 STD: 0.0788\n",
      "[120/600] Loss: 0.0061 MAE: 0.0070 Mean Error: 0.0010 STD: 0.0780\n",
      "[130/600] Loss: 0.0060 MAE: 0.0068 Mean Error: 0.0009 STD: 0.0773\n",
      "[140/600] Loss: 0.0059 MAE: 0.0066 Mean Error: 0.0008 STD: 0.0767\n",
      "[150/600] Loss: 0.0059 MAE: 0.0065 Mean Error: 0.0008 STD: 0.0766\n",
      "[160/600] Loss: 0.0059 MAE: 0.0065 Mean Error: 0.0008 STD: 0.0766\n",
      "[170/600] Loss: 0.0059 MAE: 0.0064 Mean Error: 0.0008 STD: 0.0766\n",
      "[180/600] Loss: 0.0059 MAE: 0.0064 Mean Error: 0.0008 STD: 0.0766\n",
      "[190/600] Loss: 0.0059 MAE: 0.0064 Mean Error: 0.0008 STD: 0.0766\n",
      "[200/600] Loss: 0.0059 MAE: 0.0064 Mean Error: 0.0008 STD: 0.0766\n",
      "[210/600] Loss: 0.0059 MAE: 0.0063 Mean Error: 0.0008 STD: 0.0766\n",
      "[220/600] Loss: 0.0059 MAE: 0.0063 Mean Error: 0.0008 STD: 0.0766\n",
      "[230/600] Loss: 0.0059 MAE: 0.0063 Mean Error: 0.0008 STD: 0.0766\n",
      "[240/600] Loss: 0.0059 MAE: 0.0063 Mean Error: 0.0008 STD: 0.0766\n",
      "[250/600] Loss: 0.0059 MAE: 0.0063 Mean Error: 0.0008 STD: 0.0766\n",
      "[260/600] Loss: 0.0059 MAE: 0.0063 Mean Error: 0.0008 STD: 0.0766\n",
      "[270/600] Loss: 0.0059 MAE: 0.0063 Mean Error: 0.0008 STD: 0.0766\n",
      "[280/600] Loss: 0.0059 MAE: 0.0063 Mean Error: 0.0008 STD: 0.0766\n",
      "[290/600] Loss: 0.0059 MAE: 0.0063 Mean Error: 0.0008 STD: 0.0766\n",
      "[300/600] Loss: 0.0059 MAE: 0.0062 Mean Error: 0.0008 STD: 0.0766\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[310/600] Loss: 0.0059 MAE: 0.0062 Mean Error: 0.0008 STD: 0.0766\n",
      "[320/600] Loss: 0.0059 MAE: 0.0062 Mean Error: 0.0008 STD: 0.0766\n",
      "[330/600] Loss: 0.0059 MAE: 0.0062 Mean Error: 0.0008 STD: 0.0766\n",
      "[340/600] Loss: 0.0058 MAE: 0.0062 Mean Error: 0.0007 STD: 0.0763\n",
      "[350/600] Loss: 0.0058 MAE: 0.0062 Mean Error: 0.0007 STD: 0.0759\n",
      "[360/600] Loss: 0.0058 MAE: 0.0062 Mean Error: 0.0007 STD: 0.0759\n",
      "[370/600] Loss: 0.0058 MAE: 0.0061 Mean Error: 0.0007 STD: 0.0759\n",
      "[380/600] Loss: 0.0058 MAE: 0.0061 Mean Error: 0.0007 STD: 0.0759\n",
      "[390/600] Loss: 0.0058 MAE: 0.0061 Mean Error: 0.0007 STD: 0.0759\n",
      "[400/600] Loss: 0.0058 MAE: 0.0061 Mean Error: 0.0007 STD: 0.0759\n",
      "[410/600] Loss: 0.0058 MAE: 0.0061 Mean Error: 0.0007 STD: 0.0759\n",
      "[420/600] Loss: 0.0058 MAE: 0.0061 Mean Error: 0.0007 STD: 0.0759\n",
      "[430/600] Loss: 0.0058 MAE: 0.0061 Mean Error: 0.0007 STD: 0.0759\n",
      "[440/600] Loss: 0.0058 MAE: 0.0061 Mean Error: 0.0007 STD: 0.0759\n",
      "[450/600] Loss: 0.0058 MAE: 0.0061 Mean Error: 0.0007 STD: 0.0759\n",
      "[460/600] Loss: 0.0058 MAE: 0.0060 Mean Error: 0.0007 STD: 0.0759\n",
      "[470/600] Loss: 0.0057 MAE: 0.0061 Mean Error: 0.0007 STD: 0.0758\n",
      "[480/600] Loss: 0.0057 MAE: 0.0061 Mean Error: 0.0008 STD: 0.0754\n",
      "[490/600] Loss: 0.0057 MAE: 0.0061 Mean Error: 0.0007 STD: 0.0753\n",
      "[500/600] Loss: 0.0057 MAE: 0.0060 Mean Error: 0.0008 STD: 0.0753\n",
      "[510/600] Loss: 0.0057 MAE: 0.0060 Mean Error: 0.0008 STD: 0.0753\n",
      "[520/600] Loss: 0.0057 MAE: 0.0059 Mean Error: 0.0008 STD: 0.0753\n",
      "[530/600] Loss: 0.0057 MAE: 0.0059 Mean Error: 0.0008 STD: 0.0753\n",
      "[540/600] Loss: 0.0057 MAE: 0.0059 Mean Error: 0.0008 STD: 0.0753\n",
      "[550/600] Loss: 0.0057 MAE: 0.0059 Mean Error: 0.0008 STD: 0.0753\n",
      "[560/600] Loss: 0.0057 MAE: 0.0059 Mean Error: 0.0008 STD: 0.0753\n",
      "[570/600] Loss: 0.0057 MAE: 0.0059 Mean Error: 0.0008 STD: 0.0753\n",
      "[580/600] Loss: 0.0057 MAE: 0.0059 Mean Error: 0.0008 STD: 0.0753\n",
      "[590/600] Loss: 0.0057 MAE: 0.0059 Mean Error: 0.0008 STD: 0.0753\n",
      "[599/600] Loss: 0.0056 MAE: 0.0059 Mean Error: 0.0010 STD: 0.0748\n",
      "------------------------------------\n",
      "Training dataset with noise standard deviation 0.1\n",
      "[0/600] Loss: 0.2500 MAE: 0.4999 Mean Error: 0.0944 STD: 0.4910\n",
      "[10/600] Loss: 0.1388 MAE: 0.2116 Mean Error: 0.0039 STD: 0.3726\n",
      "[20/600] Loss: 0.1226 MAE: 0.2529 Mean Error: 0.0050 STD: 0.3502\n",
      "[30/600] Loss: 0.1003 MAE: 0.2032 Mean Error: -0.0005 STD: 0.3167\n",
      "[40/600] Loss: 0.0824 MAE: 0.1695 Mean Error: -0.0008 STD: 0.2870\n",
      "[50/600] Loss: 0.0554 MAE: 0.1261 Mean Error: -0.0066 STD: 0.2352\n",
      "[60/600] Loss: 0.0248 MAE: 0.0609 Mean Error: -0.0040 STD: 0.1575\n",
      "[70/600] Loss: 0.0105 MAE: 0.0225 Mean Error: -0.0004 STD: 0.1027\n",
      "[80/600] Loss: 0.0067 MAE: 0.0113 Mean Error: -0.0001 STD: 0.0818\n",
      "[90/600] Loss: 0.0055 MAE: 0.0077 Mean Error: 0.0007 STD: 0.0744\n",
      "[100/600] Loss: 0.0053 MAE: 0.0065 Mean Error: 0.0008 STD: 0.0729\n",
      "[110/600] Loss: 0.0053 MAE: 0.0061 Mean Error: 0.0007 STD: 0.0726\n",
      "[120/600] Loss: 0.0050 MAE: 0.0057 Mean Error: 0.0011 STD: 0.0706\n",
      "[130/600] Loss: 0.0050 MAE: 0.0056 Mean Error: 0.0011 STD: 0.0706\n",
      "[140/600] Loss: 0.0049 MAE: 0.0055 Mean Error: 0.0012 STD: 0.0699\n",
      "[150/600] Loss: 0.0048 MAE: 0.0054 Mean Error: 0.0012 STD: 0.0692\n",
      "[160/600] Loss: 0.0048 MAE: 0.0053 Mean Error: 0.0012 STD: 0.0692\n",
      "[170/600] Loss: 0.0048 MAE: 0.0053 Mean Error: 0.0013 STD: 0.0692\n",
      "[180/600] Loss: 0.0046 MAE: 0.0051 Mean Error: 0.0014 STD: 0.0678\n",
      "[190/600] Loss: 0.0044 MAE: 0.0050 Mean Error: 0.0014 STD: 0.0664\n",
      "[200/600] Loss: 0.0044 MAE: 0.0050 Mean Error: 0.0014 STD: 0.0663\n",
      "[210/600] Loss: 0.0044 MAE: 0.0049 Mean Error: 0.0014 STD: 0.0663\n",
      "[220/600] Loss: 0.0043 MAE: 0.0048 Mean Error: 0.0014 STD: 0.0656\n",
      "[230/600] Loss: 0.0043 MAE: 0.0048 Mean Error: 0.0013 STD: 0.0656\n",
      "[240/600] Loss: 0.0042 MAE: 0.0047 Mean Error: 0.0015 STD: 0.0649\n",
      "[250/600] Loss: 0.0042 MAE: 0.0046 Mean Error: 0.0014 STD: 0.0648\n",
      "[260/600] Loss: 0.0042 MAE: 0.0046 Mean Error: 0.0014 STD: 0.0648\n",
      "[270/600] Loss: 0.0042 MAE: 0.0046 Mean Error: 0.0015 STD: 0.0648\n",
      "[280/600] Loss: 0.0042 MAE: 0.0045 Mean Error: 0.0015 STD: 0.0648\n",
      "[290/600] Loss: 0.0042 MAE: 0.0046 Mean Error: 0.0013 STD: 0.0644\n",
      "[300/600] Loss: 0.0041 MAE: 0.0045 Mean Error: 0.0014 STD: 0.0641\n",
      "[310/600] Loss: 0.0041 MAE: 0.0044 Mean Error: 0.0013 STD: 0.0640\n",
      "[320/600] Loss: 0.0040 MAE: 0.0044 Mean Error: 0.0012 STD: 0.0633\n",
      "[330/600] Loss: 0.0039 MAE: 0.0042 Mean Error: 0.0012 STD: 0.0625\n",
      "[340/600] Loss: 0.0039 MAE: 0.0042 Mean Error: 0.0011 STD: 0.0625\n",
      "[350/600] Loss: 0.0039 MAE: 0.0042 Mean Error: 0.0012 STD: 0.0625\n",
      "[360/600] Loss: 0.0039 MAE: 0.0042 Mean Error: 0.0012 STD: 0.0625\n",
      "[370/600] Loss: 0.0039 MAE: 0.0042 Mean Error: 0.0012 STD: 0.0625\n",
      "[380/600] Loss: 0.0039 MAE: 0.0042 Mean Error: 0.0012 STD: 0.0625\n",
      "[390/600] Loss: 0.0039 MAE: 0.0042 Mean Error: 0.0012 STD: 0.0625\n",
      "[400/600] Loss: 0.0038 MAE: 0.0041 Mean Error: 0.0011 STD: 0.0619\n",
      "[410/600] Loss: 0.0038 MAE: 0.0041 Mean Error: 0.0011 STD: 0.0617\n",
      "[420/600] Loss: 0.0038 MAE: 0.0041 Mean Error: 0.0011 STD: 0.0617\n",
      "[430/600] Loss: 0.0038 MAE: 0.0041 Mean Error: 0.0011 STD: 0.0617\n",
      "[440/600] Loss: 0.0038 MAE: 0.0041 Mean Error: 0.0011 STD: 0.0617\n",
      "[450/600] Loss: 0.0038 MAE: 0.0041 Mean Error: 0.0011 STD: 0.0617\n",
      "[460/600] Loss: 0.0038 MAE: 0.0041 Mean Error: 0.0011 STD: 0.0617\n",
      "[470/600] Loss: 0.0037 MAE: 0.0040 Mean Error: 0.0010 STD: 0.0609\n",
      "[480/600] Loss: 0.0037 MAE: 0.0040 Mean Error: 0.0010 STD: 0.0609\n",
      "[490/600] Loss: 0.0037 MAE: 0.0040 Mean Error: 0.0010 STD: 0.0609\n",
      "[500/600] Loss: 0.0036 MAE: 0.0039 Mean Error: 0.0010 STD: 0.0602\n",
      "[510/600] Loss: 0.0036 MAE: 0.0039 Mean Error: 0.0010 STD: 0.0601\n",
      "[520/600] Loss: 0.0036 MAE: 0.0039 Mean Error: 0.0011 STD: 0.0601\n",
      "[530/600] Loss: 0.0036 MAE: 0.0038 Mean Error: 0.0011 STD: 0.0601\n",
      "[540/600] Loss: 0.0036 MAE: 0.0038 Mean Error: 0.0011 STD: 0.0601\n",
      "[550/600] Loss: 0.0036 MAE: 0.0038 Mean Error: 0.0011 STD: 0.0601\n",
      "[560/600] Loss: 0.0036 MAE: 0.0038 Mean Error: 0.0011 STD: 0.0601\n",
      "[570/600] Loss: 0.0036 MAE: 0.0038 Mean Error: 0.0011 STD: 0.0601\n",
      "[580/600] Loss: 0.0036 MAE: 0.0038 Mean Error: 0.0011 STD: 0.0601\n",
      "[590/600] Loss: 0.0036 MAE: 0.0040 Mean Error: 0.0011 STD: 0.0601\n",
      "[599/600] Loss: 0.0036 MAE: 0.0039 Mean Error: 0.0011 STD: 0.0601\n",
      "------------------------------------\n",
      "Training dataset with noise standard deviation 0.001\n",
      "[0/600] Loss: 0.2499 MAE: 0.4999 Mean Error: 0.0935 STD: 0.4912\n",
      "[10/600] Loss: 0.1413 MAE: 0.2083 Mean Error: 0.0101 STD: 0.3757\n",
      "[20/600] Loss: 0.1240 MAE: 0.2583 Mean Error: 0.0051 STD: 0.3521\n",
      "[30/600] Loss: 0.1026 MAE: 0.2147 Mean Error: 0.0030 STD: 0.3203\n",
      "[40/600] Loss: 0.0857 MAE: 0.1765 Mean Error: -0.0029 STD: 0.2928\n",
      "[50/600] Loss: 0.0697 MAE: 0.1500 Mean Error: -0.0023 STD: 0.2640\n",
      "[60/600] Loss: 0.0461 MAE: 0.1016 Mean Error: 0.0015 STD: 0.2148\n",
      "[70/600] Loss: 0.0259 MAE: 0.0590 Mean Error: -0.0014 STD: 0.1609\n",
      "[80/600] Loss: 0.0131 MAE: 0.0295 Mean Error: -0.0022 STD: 0.1145\n",
      "[90/600] Loss: 0.0087 MAE: 0.0153 Mean Error: -0.0015 STD: 0.0934\n",
      "[100/600] Loss: 0.0075 MAE: 0.0105 Mean Error: -0.0009 STD: 0.0864\n",
      "[110/600] Loss: 0.0070 MAE: 0.0088 Mean Error: -0.0007 STD: 0.0836\n",
      "[120/600] Loss: 0.0068 MAE: 0.0080 Mean Error: -0.0006 STD: 0.0823\n",
      "[130/600] Loss: 0.0068 MAE: 0.0077 Mean Error: -0.0007 STD: 0.0822\n",
      "[140/600] Loss: 0.0067 MAE: 0.0075 Mean Error: -0.0008 STD: 0.0816\n",
      "[150/600] Loss: 0.0066 MAE: 0.0075 Mean Error: -0.0008 STD: 0.0815\n",
      "[160/600] Loss: 0.0066 MAE: 0.0074 Mean Error: -0.0008 STD: 0.0815\n",
      "[170/600] Loss: 0.0066 MAE: 0.0073 Mean Error: -0.0008 STD: 0.0815\n",
      "[180/600] Loss: 0.0066 MAE: 0.0073 Mean Error: -0.0008 STD: 0.0815\n",
      "[190/600] Loss: 0.0066 MAE: 0.0072 Mean Error: -0.0008 STD: 0.0815\n",
      "[200/600] Loss: 0.0066 MAE: 0.0072 Mean Error: -0.0008 STD: 0.0815\n",
      "[210/600] Loss: 0.0066 MAE: 0.0072 Mean Error: -0.0008 STD: 0.0815\n",
      "[220/600] Loss: 0.0066 MAE: 0.0071 Mean Error: -0.0008 STD: 0.0815\n",
      "[230/600] Loss: 0.0066 MAE: 0.0071 Mean Error: -0.0008 STD: 0.0815\n",
      "[240/600] Loss: 0.0066 MAE: 0.0071 Mean Error: -0.0008 STD: 0.0815\n",
      "[250/600] Loss: 0.0066 MAE: 0.0071 Mean Error: -0.0009 STD: 0.0812\n",
      "[260/600] Loss: 0.0065 MAE: 0.0070 Mean Error: -0.0009 STD: 0.0809\n",
      "[270/600] Loss: 0.0065 MAE: 0.0070 Mean Error: -0.0010 STD: 0.0805\n",
      "[280/600] Loss: 0.0064 MAE: 0.0069 Mean Error: -0.0010 STD: 0.0803\n",
      "[290/600] Loss: 0.0064 MAE: 0.0070 Mean Error: -0.0009 STD: 0.0802\n",
      "[300/600] Loss: 0.0064 MAE: 0.0070 Mean Error: -0.0009 STD: 0.0803\n",
      "[310/600] Loss: 0.0064 MAE: 0.0070 Mean Error: -0.0010 STD: 0.0803\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[320/600] Loss: 0.0064 MAE: 0.0068 Mean Error: -0.0009 STD: 0.0797\n",
      "[330/600] Loss: 0.0064 MAE: 0.0068 Mean Error: -0.0009 STD: 0.0797\n",
      "[340/600] Loss: 0.0063 MAE: 0.0068 Mean Error: -0.0009 STD: 0.0797\n",
      "[350/600] Loss: 0.0063 MAE: 0.0067 Mean Error: -0.0009 STD: 0.0797\n",
      "[360/600] Loss: 0.0063 MAE: 0.0067 Mean Error: -0.0009 STD: 0.0797\n",
      "[370/600] Loss: 0.0063 MAE: 0.0067 Mean Error: -0.0009 STD: 0.0797\n",
      "[380/600] Loss: 0.0063 MAE: 0.0067 Mean Error: -0.0009 STD: 0.0797\n",
      "[390/600] Loss: 0.0063 MAE: 0.0067 Mean Error: -0.0009 STD: 0.0797\n",
      "[400/600] Loss: 0.0063 MAE: 0.0067 Mean Error: -0.0009 STD: 0.0797\n",
      "[410/600] Loss: 0.0063 MAE: 0.0067 Mean Error: -0.0008 STD: 0.0796\n",
      "[420/600] Loss: 0.0063 MAE: 0.0066 Mean Error: -0.0008 STD: 0.0791\n",
      "[430/600] Loss: 0.0063 MAE: 0.0066 Mean Error: -0.0008 STD: 0.0791\n",
      "[440/600] Loss: 0.0063 MAE: 0.0066 Mean Error: -0.0008 STD: 0.0791\n",
      "[450/600] Loss: 0.0063 MAE: 0.0066 Mean Error: -0.0008 STD: 0.0791\n",
      "[460/600] Loss: 0.0063 MAE: 0.0066 Mean Error: -0.0008 STD: 0.0791\n",
      "[470/600] Loss: 0.0063 MAE: 0.0065 Mean Error: -0.0008 STD: 0.0791\n",
      "[480/600] Loss: 0.0063 MAE: 0.0065 Mean Error: -0.0008 STD: 0.0791\n",
      "[490/600] Loss: 0.0063 MAE: 0.0065 Mean Error: -0.0008 STD: 0.0791\n",
      "[500/600] Loss: 0.0063 MAE: 0.0065 Mean Error: -0.0008 STD: 0.0791\n",
      "[510/600] Loss: 0.0062 MAE: 0.0065 Mean Error: -0.0007 STD: 0.0784\n",
      "[520/600] Loss: 0.0062 MAE: 0.0066 Mean Error: -0.0007 STD: 0.0785\n",
      "[530/600] Loss: 0.0061 MAE: 0.0065 Mean Error: -0.0006 STD: 0.0779\n",
      "[540/600] Loss: 0.0061 MAE: 0.0064 Mean Error: -0.0005 STD: 0.0778\n",
      "[550/600] Loss: 0.0061 MAE: 0.0064 Mean Error: -0.0006 STD: 0.0778\n",
      "[560/600] Loss: 0.0061 MAE: 0.0063 Mean Error: -0.0006 STD: 0.0778\n",
      "[570/600] Loss: 0.0061 MAE: 0.0063 Mean Error: -0.0006 STD: 0.0778\n",
      "[580/600] Loss: 0.0060 MAE: 0.0063 Mean Error: -0.0005 STD: 0.0773\n",
      "[590/600] Loss: 0.0060 MAE: 0.0064 Mean Error: -0.0005 STD: 0.0772\n",
      "[599/600] Loss: 0.0060 MAE: 0.0063 Mean Error: -0.0005 STD: 0.0772\n",
      "------------------------------------\n",
      "Training dataset with noise standard deviation 0.002\n",
      "[0/600] Loss: 0.2503 MAE: 0.5002 Mean Error: 0.0943 STD: 0.4913\n",
      "[10/600] Loss: 0.1411 MAE: 0.2068 Mean Error: 0.0159 STD: 0.3753\n",
      "[20/600] Loss: 0.1212 MAE: 0.2527 Mean Error: 0.0067 STD: 0.3481\n",
      "[30/600] Loss: 0.0987 MAE: 0.1973 Mean Error: -0.0012 STD: 0.3141\n",
      "[40/600] Loss: 0.0824 MAE: 0.1716 Mean Error: -0.0025 STD: 0.2870\n",
      "[50/600] Loss: 0.0598 MAE: 0.1302 Mean Error: -0.0050 STD: 0.2445\n",
      "[60/600] Loss: 0.0383 MAE: 0.0838 Mean Error: -0.0005 STD: 0.1957\n",
      "[70/600] Loss: 0.0234 MAE: 0.0518 Mean Error: -0.0012 STD: 0.1529\n",
      "[80/600] Loss: 0.0113 MAE: 0.0261 Mean Error: 0.0003 STD: 0.1062\n",
      "[90/600] Loss: 0.0068 MAE: 0.0111 Mean Error: 0.0003 STD: 0.0826\n",
      "[100/600] Loss: 0.0060 MAE: 0.0080 Mean Error: 0.0003 STD: 0.0777\n",
      "[110/600] Loss: 0.0056 MAE: 0.0068 Mean Error: 0.0003 STD: 0.0748\n",
      "[120/600] Loss: 0.0055 MAE: 0.0063 Mean Error: 0.0004 STD: 0.0740\n",
      "[130/600] Loss: 0.0055 MAE: 0.0062 Mean Error: 0.0004 STD: 0.0740\n",
      "[140/600] Loss: 0.0054 MAE: 0.0060 Mean Error: 0.0005 STD: 0.0733\n",
      "[150/600] Loss: 0.0054 MAE: 0.0059 Mean Error: 0.0005 STD: 0.0733\n",
      "[160/600] Loss: 0.0053 MAE: 0.0058 Mean Error: 0.0003 STD: 0.0727\n",
      "[170/600] Loss: 0.0053 MAE: 0.0058 Mean Error: 0.0004 STD: 0.0726\n",
      "[180/600] Loss: 0.0053 MAE: 0.0058 Mean Error: 0.0004 STD: 0.0726\n",
      "[190/600] Loss: 0.0053 MAE: 0.0057 Mean Error: 0.0004 STD: 0.0726\n",
      "[200/600] Loss: 0.0053 MAE: 0.0057 Mean Error: 0.0004 STD: 0.0726\n",
      "[210/600] Loss: 0.0053 MAE: 0.0057 Mean Error: 0.0004 STD: 0.0726\n",
      "[220/600] Loss: 0.0053 MAE: 0.0057 Mean Error: 0.0004 STD: 0.0726\n",
      "[230/600] Loss: 0.0053 MAE: 0.0057 Mean Error: 0.0004 STD: 0.0726\n",
      "[240/600] Loss: 0.0053 MAE: 0.0056 Mean Error: 0.0004 STD: 0.0726\n",
      "[250/600] Loss: 0.0053 MAE: 0.0056 Mean Error: 0.0004 STD: 0.0726\n",
      "[260/600] Loss: 0.0053 MAE: 0.0056 Mean Error: 0.0004 STD: 0.0726\n",
      "[270/600] Loss: 0.0052 MAE: 0.0056 Mean Error: 0.0003 STD: 0.0724\n",
      "[280/600] Loss: 0.0052 MAE: 0.0056 Mean Error: 0.0003 STD: 0.0720\n",
      "[290/600] Loss: 0.0052 MAE: 0.0056 Mean Error: 0.0003 STD: 0.0720\n",
      "[300/600] Loss: 0.0052 MAE: 0.0055 Mean Error: 0.0003 STD: 0.0720\n",
      "[310/600] Loss: 0.0052 MAE: 0.0055 Mean Error: 0.0003 STD: 0.0720\n",
      "[320/600] Loss: 0.0052 MAE: 0.0055 Mean Error: 0.0003 STD: 0.0720\n",
      "[330/600] Loss: 0.0052 MAE: 0.0055 Mean Error: 0.0003 STD: 0.0718\n",
      "[340/600] Loss: 0.0050 MAE: 0.0055 Mean Error: 0.0004 STD: 0.0709\n",
      "[350/600] Loss: 0.0049 MAE: 0.0054 Mean Error: 0.0004 STD: 0.0699\n",
      "[360/600] Loss: 0.0048 MAE: 0.0053 Mean Error: 0.0005 STD: 0.0692\n",
      "[370/600] Loss: 0.0048 MAE: 0.0052 Mean Error: 0.0005 STD: 0.0692\n",
      "[380/600] Loss: 0.0048 MAE: 0.0051 Mean Error: 0.0005 STD: 0.0692\n",
      "[390/600] Loss: 0.0048 MAE: 0.0051 Mean Error: 0.0005 STD: 0.0692\n",
      "[400/600] Loss: 0.0048 MAE: 0.0051 Mean Error: 0.0005 STD: 0.0692\n",
      "[410/600] Loss: 0.0048 MAE: 0.0051 Mean Error: 0.0005 STD: 0.0692\n",
      "[420/600] Loss: 0.0048 MAE: 0.0051 Mean Error: 0.0005 STD: 0.0692\n",
      "[430/600] Loss: 0.0047 MAE: 0.0050 Mean Error: 0.0006 STD: 0.0685\n",
      "[440/600] Loss: 0.0047 MAE: 0.0050 Mean Error: 0.0006 STD: 0.0685\n",
      "[450/600] Loss: 0.0047 MAE: 0.0050 Mean Error: 0.0006 STD: 0.0685\n",
      "[460/600] Loss: 0.0047 MAE: 0.0050 Mean Error: 0.0006 STD: 0.0685\n",
      "[470/600] Loss: 0.0047 MAE: 0.0049 Mean Error: 0.0006 STD: 0.0685\n",
      "[480/600] Loss: 0.0047 MAE: 0.0049 Mean Error: 0.0006 STD: 0.0685\n",
      "[490/600] Loss: 0.0047 MAE: 0.0049 Mean Error: 0.0006 STD: 0.0685\n",
      "[500/600] Loss: 0.0047 MAE: 0.0049 Mean Error: 0.0006 STD: 0.0685\n",
      "[510/600] Loss: 0.0046 MAE: 0.0049 Mean Error: 0.0004 STD: 0.0678\n",
      "[520/600] Loss: 0.0046 MAE: 0.0049 Mean Error: 0.0004 STD: 0.0678\n",
      "[530/600] Loss: 0.0046 MAE: 0.0049 Mean Error: 0.0005 STD: 0.0678\n",
      "[540/600] Loss: 0.0046 MAE: 0.0048 Mean Error: 0.0005 STD: 0.0678\n",
      "[550/600] Loss: 0.0046 MAE: 0.0048 Mean Error: 0.0005 STD: 0.0678\n",
      "[560/600] Loss: 0.0046 MAE: 0.0048 Mean Error: 0.0005 STD: 0.0678\n",
      "[570/600] Loss: 0.0045 MAE: 0.0047 Mean Error: 0.0004 STD: 0.0670\n",
      "[580/600] Loss: 0.0045 MAE: 0.0047 Mean Error: 0.0004 STD: 0.0670\n",
      "[590/600] Loss: 0.0046 MAE: 0.0049 Mean Error: 0.0007 STD: 0.0678\n",
      "[599/600] Loss: 0.0045 MAE: 0.0049 Mean Error: 0.0006 STD: 0.0673\n",
      "------------------------------------\n",
      "Training dataset with noise standard deviation 0.003\n",
      "[0/600] Loss: 0.2500 MAE: 0.4999 Mean Error: 0.0941 STD: 0.4911\n",
      "[10/600] Loss: 0.1389 MAE: 0.2117 Mean Error: 0.0072 STD: 0.3727\n",
      "[20/600] Loss: 0.1250 MAE: 0.2557 Mean Error: 0.0066 STD: 0.3535\n",
      "[30/600] Loss: 0.1082 MAE: 0.2289 Mean Error: -0.0001 STD: 0.3290\n",
      "[40/600] Loss: 0.0885 MAE: 0.1824 Mean Error: -0.0020 STD: 0.2975\n",
      "[50/600] Loss: 0.0689 MAE: 0.1506 Mean Error: -0.0023 STD: 0.2626\n",
      "[60/600] Loss: 0.0401 MAE: 0.0897 Mean Error: -0.0023 STD: 0.2002\n",
      "[70/600] Loss: 0.0195 MAE: 0.0449 Mean Error: -0.0009 STD: 0.1397\n",
      "[80/600] Loss: 0.0107 MAE: 0.0219 Mean Error: -0.0005 STD: 0.1034\n",
      "[90/600] Loss: 0.0076 MAE: 0.0126 Mean Error: -0.0001 STD: 0.0872\n",
      "[100/600] Loss: 0.0068 MAE: 0.0092 Mean Error: -0.0002 STD: 0.0824\n",
      "[110/600] Loss: 0.0065 MAE: 0.0081 Mean Error: -0.0000 STD: 0.0807\n",
      "[120/600] Loss: 0.0065 MAE: 0.0076 Mean Error: -0.0001 STD: 0.0804\n",
      "[130/600] Loss: 0.0063 MAE: 0.0075 Mean Error: -0.0001 STD: 0.0797\n",
      "[140/600] Loss: 0.0063 MAE: 0.0072 Mean Error: -0.0001 STD: 0.0791\n",
      "[150/600] Loss: 0.0063 MAE: 0.0071 Mean Error: -0.0001 STD: 0.0791\n",
      "[160/600] Loss: 0.0061 MAE: 0.0069 Mean Error: -0.0000 STD: 0.0779\n",
      "[170/600] Loss: 0.0061 MAE: 0.0068 Mean Error: -0.0000 STD: 0.0779\n",
      "[180/600] Loss: 0.0060 MAE: 0.0067 Mean Error: -0.0002 STD: 0.0772\n",
      "[190/600] Loss: 0.0059 MAE: 0.0067 Mean Error: -0.0002 STD: 0.0767\n",
      "[200/600] Loss: 0.0058 MAE: 0.0066 Mean Error: -0.0001 STD: 0.0761\n",
      "[210/600] Loss: 0.0058 MAE: 0.0064 Mean Error: -0.0002 STD: 0.0760\n",
      "[220/600] Loss: 0.0058 MAE: 0.0064 Mean Error: -0.0001 STD: 0.0759\n",
      "[230/600] Loss: 0.0058 MAE: 0.0063 Mean Error: -0.0001 STD: 0.0759\n",
      "[240/600] Loss: 0.0058 MAE: 0.0063 Mean Error: -0.0001 STD: 0.0759\n",
      "[250/600] Loss: 0.0058 MAE: 0.0063 Mean Error: -0.0001 STD: 0.0759\n",
      "[260/600] Loss: 0.0058 MAE: 0.0063 Mean Error: -0.0001 STD: 0.0759\n",
      "[270/600] Loss: 0.0058 MAE: 0.0062 Mean Error: -0.0001 STD: 0.0759\n",
      "[280/600] Loss: 0.0058 MAE: 0.0062 Mean Error: -0.0001 STD: 0.0759\n",
      "[290/600] Loss: 0.0058 MAE: 0.0062 Mean Error: -0.0001 STD: 0.0759\n",
      "[300/600] Loss: 0.0058 MAE: 0.0062 Mean Error: -0.0001 STD: 0.0759\n",
      "[310/600] Loss: 0.0058 MAE: 0.0062 Mean Error: -0.0001 STD: 0.0759\n",
      "[320/600] Loss: 0.0058 MAE: 0.0062 Mean Error: -0.0001 STD: 0.0759\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[330/600] Loss: 0.0058 MAE: 0.0062 Mean Error: -0.0001 STD: 0.0759\n",
      "[340/600] Loss: 0.0058 MAE: 0.0062 Mean Error: -0.0001 STD: 0.0759\n",
      "[350/600] Loss: 0.0058 MAE: 0.0062 Mean Error: -0.0001 STD: 0.0759\n",
      "[360/600] Loss: 0.0058 MAE: 0.0061 Mean Error: -0.0001 STD: 0.0759\n",
      "[370/600] Loss: 0.0058 MAE: 0.0061 Mean Error: -0.0001 STD: 0.0759\n",
      "[380/600] Loss: 0.0058 MAE: 0.0061 Mean Error: -0.0001 STD: 0.0759\n",
      "[390/600] Loss: 0.0058 MAE: 0.0061 Mean Error: -0.0001 STD: 0.0759\n",
      "[400/600] Loss: 0.0058 MAE: 0.0061 Mean Error: -0.0001 STD: 0.0759\n",
      "[410/600] Loss: 0.0058 MAE: 0.0061 Mean Error: -0.0001 STD: 0.0759\n",
      "[420/600] Loss: 0.0058 MAE: 0.0061 Mean Error: -0.0001 STD: 0.0759\n",
      "[430/600] Loss: 0.0058 MAE: 0.0061 Mean Error: -0.0001 STD: 0.0759\n",
      "[440/600] Loss: 0.0058 MAE: 0.0061 Mean Error: -0.0001 STD: 0.0759\n",
      "[450/600] Loss: 0.0058 MAE: 0.0061 Mean Error: -0.0001 STD: 0.0759\n",
      "[460/600] Loss: 0.0058 MAE: 0.0061 Mean Error: -0.0001 STD: 0.0759\n",
      "[470/600] Loss: 0.0058 MAE: 0.0061 Mean Error: -0.0001 STD: 0.0759\n",
      "[480/600] Loss: 0.0058 MAE: 0.0061 Mean Error: -0.0001 STD: 0.0759\n",
      "[490/600] Loss: 0.0058 MAE: 0.0061 Mean Error: -0.0001 STD: 0.0759\n",
      "[500/600] Loss: 0.0058 MAE: 0.0061 Mean Error: -0.0001 STD: 0.0759\n",
      "[510/600] Loss: 0.0058 MAE: 0.0061 Mean Error: -0.0001 STD: 0.0759\n",
      "[520/600] Loss: 0.0058 MAE: 0.0061 Mean Error: -0.0001 STD: 0.0759\n",
      "[530/600] Loss: 0.0058 MAE: 0.0060 Mean Error: -0.0001 STD: 0.0759\n",
      "[540/600] Loss: 0.0058 MAE: 0.0060 Mean Error: -0.0001 STD: 0.0759\n",
      "[550/600] Loss: 0.0058 MAE: 0.0060 Mean Error: -0.0001 STD: 0.0759\n",
      "[560/600] Loss: 0.0058 MAE: 0.0060 Mean Error: -0.0001 STD: 0.0759\n",
      "[570/600] Loss: 0.0058 MAE: 0.0060 Mean Error: -0.0001 STD: 0.0759\n",
      "[580/600] Loss: 0.0058 MAE: 0.0060 Mean Error: -0.0001 STD: 0.0759\n",
      "[590/600] Loss: 0.0058 MAE: 0.0060 Mean Error: -0.0001 STD: 0.0759\n",
      "[599/600] Loss: 0.0058 MAE: 0.0060 Mean Error: -0.0001 STD: 0.0759\n",
      "------------------------------------\n",
      "Training dataset with noise standard deviation 0.005\n",
      "[0/600] Loss: 0.2500 MAE: 0.4999 Mean Error: 0.0939 STD: 0.4911\n",
      "[10/600] Loss: 0.1421 MAE: 0.2053 Mean Error: 0.0123 STD: 0.3767\n",
      "[20/600] Loss: 0.1264 MAE: 0.2429 Mean Error: 0.0018 STD: 0.3556\n",
      "[30/600] Loss: 0.1158 MAE: 0.2395 Mean Error: 0.0042 STD: 0.3403\n",
      "[40/600] Loss: 0.0938 MAE: 0.1830 Mean Error: -0.0030 STD: 0.3063\n",
      "[50/600] Loss: 0.0790 MAE: 0.1658 Mean Error: -0.0023 STD: 0.2810\n",
      "[60/600] Loss: 0.0572 MAE: 0.1299 Mean Error: 0.0008 STD: 0.2393\n",
      "[70/600] Loss: 0.0295 MAE: 0.0718 Mean Error: 0.0001 STD: 0.1716\n",
      "[80/600] Loss: 0.0108 MAE: 0.0287 Mean Error: 0.0001 STD: 0.1039\n",
      "[90/600] Loss: 0.0052 MAE: 0.0116 Mean Error: 0.0003 STD: 0.0723\n",
      "[100/600] Loss: 0.0041 MAE: 0.0068 Mean Error: 0.0007 STD: 0.0641\n",
      "[110/600] Loss: 0.0039 MAE: 0.0053 Mean Error: 0.0008 STD: 0.0627\n",
      "[120/600] Loss: 0.0038 MAE: 0.0048 Mean Error: 0.0009 STD: 0.0618\n",
      "[130/600] Loss: 0.0037 MAE: 0.0045 Mean Error: 0.0008 STD: 0.0610\n",
      "[140/600] Loss: 0.0037 MAE: 0.0044 Mean Error: 0.0008 STD: 0.0606\n",
      "[150/600] Loss: 0.0035 MAE: 0.0043 Mean Error: 0.0008 STD: 0.0594\n",
      "[160/600] Loss: 0.0035 MAE: 0.0042 Mean Error: 0.0008 STD: 0.0593\n",
      "[170/600] Loss: 0.0035 MAE: 0.0041 Mean Error: 0.0008 STD: 0.0593\n",
      "[180/600] Loss: 0.0035 MAE: 0.0041 Mean Error: 0.0008 STD: 0.0593\n",
      "[190/600] Loss: 0.0035 MAE: 0.0041 Mean Error: 0.0008 STD: 0.0593\n",
      "[200/600] Loss: 0.0035 MAE: 0.0041 Mean Error: 0.0008 STD: 0.0593\n",
      "[210/600] Loss: 0.0035 MAE: 0.0040 Mean Error: 0.0008 STD: 0.0593\n",
      "[220/600] Loss: 0.0035 MAE: 0.0040 Mean Error: 0.0008 STD: 0.0593\n",
      "[230/600] Loss: 0.0035 MAE: 0.0040 Mean Error: 0.0008 STD: 0.0593\n",
      "[240/600] Loss: 0.0035 MAE: 0.0040 Mean Error: 0.0008 STD: 0.0593\n",
      "[250/600] Loss: 0.0035 MAE: 0.0040 Mean Error: 0.0008 STD: 0.0593\n",
      "[260/600] Loss: 0.0035 MAE: 0.0040 Mean Error: 0.0008 STD: 0.0593\n",
      "[270/600] Loss: 0.0035 MAE: 0.0040 Mean Error: 0.0008 STD: 0.0593\n",
      "[280/600] Loss: 0.0034 MAE: 0.0039 Mean Error: 0.0008 STD: 0.0586\n",
      "[290/600] Loss: 0.0034 MAE: 0.0039 Mean Error: 0.0009 STD: 0.0585\n",
      "[300/600] Loss: 0.0034 MAE: 0.0039 Mean Error: 0.0009 STD: 0.0585\n",
      "[310/600] Loss: 0.0034 MAE: 0.0038 Mean Error: 0.0009 STD: 0.0585\n",
      "[320/600] Loss: 0.0034 MAE: 0.0038 Mean Error: 0.0009 STD: 0.0585\n",
      "[330/600] Loss: 0.0034 MAE: 0.0038 Mean Error: 0.0009 STD: 0.0585\n",
      "[340/600] Loss: 0.0034 MAE: 0.0038 Mean Error: 0.0009 STD: 0.0585\n",
      "[350/600] Loss: 0.0034 MAE: 0.0038 Mean Error: 0.0009 STD: 0.0585\n",
      "[360/600] Loss: 0.0034 MAE: 0.0038 Mean Error: 0.0009 STD: 0.0585\n",
      "[370/600] Loss: 0.0034 MAE: 0.0038 Mean Error: 0.0009 STD: 0.0585\n",
      "[380/600] Loss: 0.0034 MAE: 0.0038 Mean Error: 0.0009 STD: 0.0585\n",
      "[390/600] Loss: 0.0034 MAE: 0.0038 Mean Error: 0.0009 STD: 0.0585\n",
      "[400/600] Loss: 0.0034 MAE: 0.0037 Mean Error: 0.0009 STD: 0.0585\n",
      "[410/600] Loss: 0.0034 MAE: 0.0037 Mean Error: 0.0009 STD: 0.0585\n",
      "[420/600] Loss: 0.0034 MAE: 0.0037 Mean Error: 0.0009 STD: 0.0585\n",
      "[430/600] Loss: 0.0034 MAE: 0.0037 Mean Error: 0.0009 STD: 0.0585\n",
      "[440/600] Loss: 0.0034 MAE: 0.0037 Mean Error: 0.0009 STD: 0.0585\n",
      "[450/600] Loss: 0.0034 MAE: 0.0037 Mean Error: 0.0009 STD: 0.0585\n",
      "[460/600] Loss: 0.0034 MAE: 0.0037 Mean Error: 0.0009 STD: 0.0585\n",
      "[470/600] Loss: 0.0034 MAE: 0.0037 Mean Error: 0.0009 STD: 0.0585\n",
      "[480/600] Loss: 0.0034 MAE: 0.0037 Mean Error: 0.0009 STD: 0.0585\n",
      "[490/600] Loss: 0.0034 MAE: 0.0037 Mean Error: 0.0009 STD: 0.0585\n",
      "[500/600] Loss: 0.0034 MAE: 0.0037 Mean Error: 0.0009 STD: 0.0585\n",
      "[510/600] Loss: 0.0034 MAE: 0.0037 Mean Error: 0.0009 STD: 0.0585\n",
      "[520/600] Loss: 0.0034 MAE: 0.0037 Mean Error: 0.0009 STD: 0.0585\n",
      "[530/600] Loss: 0.0034 MAE: 0.0037 Mean Error: 0.0009 STD: 0.0585\n",
      "[540/600] Loss: 0.0034 MAE: 0.0037 Mean Error: 0.0009 STD: 0.0585\n",
      "[550/600] Loss: 0.0034 MAE: 0.0037 Mean Error: 0.0009 STD: 0.0585\n",
      "[560/600] Loss: 0.0034 MAE: 0.0037 Mean Error: 0.0009 STD: 0.0585\n",
      "[570/600] Loss: 0.0034 MAE: 0.0037 Mean Error: 0.0009 STD: 0.0585\n",
      "[580/600] Loss: 0.0034 MAE: 0.0037 Mean Error: 0.0009 STD: 0.0585\n",
      "[590/600] Loss: 0.0034 MAE: 0.0037 Mean Error: 0.0009 STD: 0.0585\n",
      "[599/600] Loss: 0.0034 MAE: 0.0037 Mean Error: 0.0009 STD: 0.0585\n",
      "------------------------------------\n",
      "Training dataset with noise standard deviation 0.01\n",
      "[0/600] Loss: 0.2501 MAE: 0.5000 Mean Error: 0.0942 STD: 0.4912\n",
      "[10/600] Loss: 0.1438 MAE: 0.2028 Mean Error: 0.0184 STD: 0.3788\n",
      "[20/600] Loss: 0.1265 MAE: 0.2357 Mean Error: 0.0052 STD: 0.3557\n",
      "[30/600] Loss: 0.1102 MAE: 0.2266 Mean Error: 0.0007 STD: 0.3321\n",
      "[40/600] Loss: 0.0911 MAE: 0.1818 Mean Error: -0.0007 STD: 0.3019\n",
      "[50/600] Loss: 0.0771 MAE: 0.1614 Mean Error: 0.0007 STD: 0.2778\n",
      "[60/600] Loss: 0.0571 MAE: 0.1283 Mean Error: -0.0004 STD: 0.2389\n",
      "[70/600] Loss: 0.0325 MAE: 0.0748 Mean Error: -0.0001 STD: 0.1803\n",
      "[80/600] Loss: 0.0158 MAE: 0.0394 Mean Error: -0.0013 STD: 0.1255\n",
      "[90/600] Loss: 0.0069 MAE: 0.0162 Mean Error: -0.0004 STD: 0.0830\n",
      "[100/600] Loss: 0.0049 MAE: 0.0084 Mean Error: -0.0001 STD: 0.0699\n",
      "[110/600] Loss: 0.0045 MAE: 0.0062 Mean Error: -0.0001 STD: 0.0671\n",
      "[120/600] Loss: 0.0042 MAE: 0.0054 Mean Error: -0.0001 STD: 0.0650\n",
      "[130/600] Loss: 0.0041 MAE: 0.0050 Mean Error: -0.0002 STD: 0.0642\n",
      "[140/600] Loss: 0.0041 MAE: 0.0049 Mean Error: -0.0002 STD: 0.0641\n",
      "[150/600] Loss: 0.0041 MAE: 0.0048 Mean Error: -0.0002 STD: 0.0641\n",
      "[160/600] Loss: 0.0041 MAE: 0.0047 Mean Error: -0.0002 STD: 0.0641\n",
      "[170/600] Loss: 0.0041 MAE: 0.0047 Mean Error: -0.0002 STD: 0.0641\n",
      "[180/600] Loss: 0.0041 MAE: 0.0047 Mean Error: -0.0002 STD: 0.0641\n",
      "[190/600] Loss: 0.0041 MAE: 0.0047 Mean Error: -0.0002 STD: 0.0641\n",
      "[200/600] Loss: 0.0041 MAE: 0.0046 Mean Error: -0.0002 STD: 0.0641\n",
      "[210/600] Loss: 0.0041 MAE: 0.0046 Mean Error: -0.0002 STD: 0.0641\n",
      "[220/600] Loss: 0.0041 MAE: 0.0046 Mean Error: -0.0002 STD: 0.0641\n",
      "[230/600] Loss: 0.0041 MAE: 0.0046 Mean Error: -0.0002 STD: 0.0641\n",
      "[240/600] Loss: 0.0041 MAE: 0.0046 Mean Error: -0.0002 STD: 0.0641\n",
      "[250/600] Loss: 0.0041 MAE: 0.0046 Mean Error: -0.0002 STD: 0.0641\n",
      "[260/600] Loss: 0.0041 MAE: 0.0046 Mean Error: -0.0002 STD: 0.0641\n",
      "[270/600] Loss: 0.0041 MAE: 0.0045 Mean Error: -0.0002 STD: 0.0641\n",
      "[280/600] Loss: 0.0041 MAE: 0.0045 Mean Error: -0.0002 STD: 0.0641\n",
      "[290/600] Loss: 0.0041 MAE: 0.0045 Mean Error: -0.0002 STD: 0.0641\n",
      "[300/600] Loss: 0.0041 MAE: 0.0045 Mean Error: -0.0002 STD: 0.0641\n",
      "[310/600] Loss: 0.0041 MAE: 0.0045 Mean Error: -0.0002 STD: 0.0641\n",
      "[320/600] Loss: 0.0041 MAE: 0.0045 Mean Error: -0.0002 STD: 0.0641\n",
      "[330/600] Loss: 0.0041 MAE: 0.0045 Mean Error: -0.0002 STD: 0.0641\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[340/600] Loss: 0.0041 MAE: 0.0045 Mean Error: -0.0002 STD: 0.0641\n",
      "[350/600] Loss: 0.0041 MAE: 0.0045 Mean Error: -0.0002 STD: 0.0641\n",
      "[360/600] Loss: 0.0041 MAE: 0.0045 Mean Error: -0.0002 STD: 0.0641\n",
      "[370/600] Loss: 0.0041 MAE: 0.0045 Mean Error: -0.0002 STD: 0.0641\n",
      "[380/600] Loss: 0.0041 MAE: 0.0045 Mean Error: -0.0002 STD: 0.0641\n",
      "[390/600] Loss: 0.0041 MAE: 0.0045 Mean Error: -0.0002 STD: 0.0641\n",
      "[400/600] Loss: 0.0041 MAE: 0.0044 Mean Error: -0.0002 STD: 0.0641\n",
      "[410/600] Loss: 0.0041 MAE: 0.0044 Mean Error: -0.0002 STD: 0.0641\n",
      "[420/600] Loss: 0.0041 MAE: 0.0044 Mean Error: -0.0002 STD: 0.0641\n",
      "[430/600] Loss: 0.0041 MAE: 0.0044 Mean Error: -0.0002 STD: 0.0641\n",
      "[440/600] Loss: 0.0041 MAE: 0.0044 Mean Error: -0.0002 STD: 0.0641\n",
      "[450/600] Loss: 0.0041 MAE: 0.0044 Mean Error: -0.0002 STD: 0.0641\n",
      "[460/600] Loss: 0.0041 MAE: 0.0044 Mean Error: -0.0002 STD: 0.0641\n",
      "[470/600] Loss: 0.0041 MAE: 0.0044 Mean Error: -0.0002 STD: 0.0641\n",
      "[480/600] Loss: 0.0041 MAE: 0.0044 Mean Error: -0.0002 STD: 0.0641\n",
      "[490/600] Loss: 0.0041 MAE: 0.0044 Mean Error: -0.0002 STD: 0.0641\n",
      "[500/600] Loss: 0.0041 MAE: 0.0044 Mean Error: -0.0002 STD: 0.0641\n",
      "[510/600] Loss: 0.0041 MAE: 0.0044 Mean Error: -0.0002 STD: 0.0641\n",
      "[520/600] Loss: 0.0041 MAE: 0.0044 Mean Error: -0.0002 STD: 0.0641\n",
      "[530/600] Loss: 0.0041 MAE: 0.0044 Mean Error: -0.0002 STD: 0.0641\n",
      "[540/600] Loss: 0.0041 MAE: 0.0044 Mean Error: -0.0002 STD: 0.0641\n",
      "[550/600] Loss: 0.0041 MAE: 0.0044 Mean Error: -0.0002 STD: 0.0641\n",
      "[560/600] Loss: 0.0041 MAE: 0.0044 Mean Error: -0.0002 STD: 0.0641\n",
      "[570/600] Loss: 0.0041 MAE: 0.0044 Mean Error: -0.0002 STD: 0.0641\n",
      "[580/600] Loss: 0.0041 MAE: 0.0044 Mean Error: -0.0002 STD: 0.0641\n",
      "[590/600] Loss: 0.0041 MAE: 0.0044 Mean Error: -0.0002 STD: 0.0641\n",
      "[599/600] Loss: 0.0041 MAE: 0.0044 Mean Error: -0.0002 STD: 0.0641\n",
      "------------------------------------\n",
      "Training dataset with noise standard deviation 0.02\n",
      "[0/600] Loss: 0.2501 MAE: 0.5000 Mean Error: 0.0945 STD: 0.4911\n",
      "[10/600] Loss: 0.1395 MAE: 0.2111 Mean Error: 0.0065 STD: 0.3735\n",
      "[20/600] Loss: 0.1219 MAE: 0.2488 Mean Error: 0.0031 STD: 0.3492\n",
      "[30/600] Loss: 0.1010 MAE: 0.2029 Mean Error: -0.0002 STD: 0.3178\n",
      "[40/600] Loss: 0.0848 MAE: 0.1768 Mean Error: -0.0001 STD: 0.2912\n",
      "[50/600] Loss: 0.0617 MAE: 0.1399 Mean Error: -0.0034 STD: 0.2484\n",
      "[60/600] Loss: 0.0311 MAE: 0.0754 Mean Error: -0.0041 STD: 0.1764\n",
      "[70/600] Loss: 0.0122 MAE: 0.0304 Mean Error: -0.0009 STD: 0.1107\n",
      "[80/600] Loss: 0.0061 MAE: 0.0132 Mean Error: -0.0010 STD: 0.0783\n",
      "[90/600] Loss: 0.0044 MAE: 0.0075 Mean Error: -0.0009 STD: 0.0664\n",
      "[100/600] Loss: 0.0040 MAE: 0.0056 Mean Error: -0.0007 STD: 0.0629\n",
      "[110/600] Loss: 0.0036 MAE: 0.0048 Mean Error: -0.0004 STD: 0.0602\n",
      "[120/600] Loss: 0.0035 MAE: 0.0045 Mean Error: -0.0004 STD: 0.0594\n",
      "[130/600] Loss: 0.0035 MAE: 0.0043 Mean Error: -0.0004 STD: 0.0594\n",
      "[140/600] Loss: 0.0033 MAE: 0.0042 Mean Error: -0.0004 STD: 0.0577\n",
      "[150/600] Loss: 0.0031 MAE: 0.0038 Mean Error: -0.0006 STD: 0.0560\n",
      "[160/600] Loss: 0.0031 MAE: 0.0038 Mean Error: -0.0006 STD: 0.0560\n",
      "[170/600] Loss: 0.0030 MAE: 0.0037 Mean Error: -0.0005 STD: 0.0551\n",
      "[180/600] Loss: 0.0030 MAE: 0.0036 Mean Error: -0.0005 STD: 0.0551\n",
      "[190/600] Loss: 0.0030 MAE: 0.0036 Mean Error: -0.0005 STD: 0.0551\n",
      "[200/600] Loss: 0.0030 MAE: 0.0035 Mean Error: -0.0005 STD: 0.0550\n",
      "[210/600] Loss: 0.0030 MAE: 0.0035 Mean Error: -0.0005 STD: 0.0550\n",
      "[220/600] Loss: 0.0028 MAE: 0.0034 Mean Error: -0.0007 STD: 0.0534\n",
      "[230/600] Loss: 0.0026 MAE: 0.0033 Mean Error: -0.0006 STD: 0.0515\n",
      "[240/600] Loss: 0.0026 MAE: 0.0032 Mean Error: -0.0005 STD: 0.0514\n",
      "[250/600] Loss: 0.0026 MAE: 0.0031 Mean Error: -0.0005 STD: 0.0514\n",
      "[260/600] Loss: 0.0026 MAE: 0.0031 Mean Error: -0.0005 STD: 0.0514\n",
      "[270/600] Loss: 0.0026 MAE: 0.0030 Mean Error: -0.0005 STD: 0.0514\n",
      "[280/600] Loss: 0.0026 MAE: 0.0030 Mean Error: -0.0005 STD: 0.0514\n",
      "[290/600] Loss: 0.0026 MAE: 0.0030 Mean Error: -0.0005 STD: 0.0514\n",
      "[300/600] Loss: 0.0026 MAE: 0.0030 Mean Error: -0.0005 STD: 0.0514\n",
      "[310/600] Loss: 0.0026 MAE: 0.0030 Mean Error: -0.0005 STD: 0.0514\n",
      "[320/600] Loss: 0.0026 MAE: 0.0030 Mean Error: -0.0005 STD: 0.0514\n",
      "[330/600] Loss: 0.0026 MAE: 0.0030 Mean Error: -0.0005 STD: 0.0514\n",
      "[340/600] Loss: 0.0026 MAE: 0.0030 Mean Error: -0.0005 STD: 0.0514\n",
      "[350/600] Loss: 0.0026 MAE: 0.0030 Mean Error: -0.0005 STD: 0.0514\n",
      "[360/600] Loss: 0.0026 MAE: 0.0030 Mean Error: -0.0005 STD: 0.0514\n",
      "[370/600] Loss: 0.0026 MAE: 0.0029 Mean Error: -0.0005 STD: 0.0509\n",
      "[380/600] Loss: 0.0025 MAE: 0.0029 Mean Error: -0.0004 STD: 0.0504\n",
      "[390/600] Loss: 0.0025 MAE: 0.0029 Mean Error: -0.0004 STD: 0.0504\n",
      "[400/600] Loss: 0.0025 MAE: 0.0029 Mean Error: -0.0004 STD: 0.0504\n",
      "[410/600] Loss: 0.0025 MAE: 0.0029 Mean Error: -0.0004 STD: 0.0504\n",
      "[420/600] Loss: 0.0025 MAE: 0.0028 Mean Error: -0.0004 STD: 0.0504\n",
      "[430/600] Loss: 0.0025 MAE: 0.0028 Mean Error: -0.0004 STD: 0.0504\n",
      "[440/600] Loss: 0.0025 MAE: 0.0028 Mean Error: -0.0004 STD: 0.0504\n",
      "[450/600] Loss: 0.0025 MAE: 0.0028 Mean Error: -0.0004 STD: 0.0504\n",
      "[460/600] Loss: 0.0025 MAE: 0.0028 Mean Error: -0.0004 STD: 0.0504\n",
      "[470/600] Loss: 0.0025 MAE: 0.0028 Mean Error: -0.0004 STD: 0.0504\n",
      "[480/600] Loss: 0.0025 MAE: 0.0028 Mean Error: -0.0004 STD: 0.0504\n",
      "[490/600] Loss: 0.0025 MAE: 0.0028 Mean Error: -0.0004 STD: 0.0504\n",
      "[500/600] Loss: 0.0025 MAE: 0.0028 Mean Error: -0.0004 STD: 0.0504\n",
      "[510/600] Loss: 0.0025 MAE: 0.0028 Mean Error: -0.0004 STD: 0.0504\n",
      "[520/600] Loss: 0.0025 MAE: 0.0028 Mean Error: -0.0004 STD: 0.0504\n",
      "[530/600] Loss: 0.0025 MAE: 0.0028 Mean Error: -0.0004 STD: 0.0504\n",
      "[540/600] Loss: 0.0025 MAE: 0.0028 Mean Error: -0.0004 STD: 0.0504\n",
      "[550/600] Loss: 0.0025 MAE: 0.0028 Mean Error: -0.0004 STD: 0.0504\n",
      "[560/600] Loss: 0.0025 MAE: 0.0028 Mean Error: -0.0004 STD: 0.0504\n",
      "[570/600] Loss: 0.0025 MAE: 0.0028 Mean Error: -0.0004 STD: 0.0504\n",
      "[580/600] Loss: 0.0025 MAE: 0.0028 Mean Error: -0.0004 STD: 0.0504\n",
      "[590/600] Loss: 0.0025 MAE: 0.0028 Mean Error: -0.0004 STD: 0.0504\n",
      "[599/600] Loss: 0.0025 MAE: 0.0028 Mean Error: -0.0004 STD: 0.0504\n",
      "------------------------------------\n",
      "Training dataset with noise standard deviation 0.03\n",
      "[0/600] Loss: 0.2499 MAE: 0.4998 Mean Error: 0.0944 STD: 0.4909\n",
      "[10/600] Loss: 0.1402 MAE: 0.2093 Mean Error: 0.0133 STD: 0.3743\n",
      "[20/600] Loss: 0.1249 MAE: 0.2534 Mean Error: 0.0033 STD: 0.3534\n",
      "[30/600] Loss: 0.1064 MAE: 0.2243 Mean Error: 0.0025 STD: 0.3263\n",
      "[40/600] Loss: 0.0869 MAE: 0.1814 Mean Error: -0.0024 STD: 0.2947\n",
      "[50/600] Loss: 0.0632 MAE: 0.1434 Mean Error: -0.0031 STD: 0.2514\n",
      "[60/600] Loss: 0.0316 MAE: 0.0753 Mean Error: -0.0042 STD: 0.1777\n",
      "[70/600] Loss: 0.0132 MAE: 0.0313 Mean Error: -0.0016 STD: 0.1151\n",
      "[80/600] Loss: 0.0070 MAE: 0.0148 Mean Error: 0.0001 STD: 0.0836\n",
      "[90/600] Loss: 0.0051 MAE: 0.0087 Mean Error: 0.0001 STD: 0.0717\n",
      "[100/600] Loss: 0.0047 MAE: 0.0066 Mean Error: -0.0001 STD: 0.0685\n",
      "[110/600] Loss: 0.0044 MAE: 0.0058 Mean Error: -0.0002 STD: 0.0663\n",
      "[120/600] Loss: 0.0043 MAE: 0.0053 Mean Error: 0.0000 STD: 0.0657\n",
      "[130/600] Loss: 0.0042 MAE: 0.0050 Mean Error: -0.0001 STD: 0.0649\n",
      "[140/600] Loss: 0.0040 MAE: 0.0048 Mean Error: -0.0001 STD: 0.0634\n",
      "[150/600] Loss: 0.0039 MAE: 0.0047 Mean Error: -0.0001 STD: 0.0626\n",
      "[160/600] Loss: 0.0039 MAE: 0.0046 Mean Error: -0.0000 STD: 0.0626\n",
      "[170/600] Loss: 0.0038 MAE: 0.0045 Mean Error: 0.0001 STD: 0.0619\n",
      "[180/600] Loss: 0.0038 MAE: 0.0044 Mean Error: 0.0001 STD: 0.0618\n",
      "[190/600] Loss: 0.0038 MAE: 0.0044 Mean Error: 0.0001 STD: 0.0617\n",
      "[200/600] Loss: 0.0037 MAE: 0.0043 Mean Error: 0.0002 STD: 0.0610\n",
      "[210/600] Loss: 0.0037 MAE: 0.0043 Mean Error: 0.0002 STD: 0.0610\n",
      "[220/600] Loss: 0.0037 MAE: 0.0043 Mean Error: 0.0002 STD: 0.0610\n",
      "[230/600] Loss: 0.0037 MAE: 0.0042 Mean Error: 0.0002 STD: 0.0609\n",
      "[240/600] Loss: 0.0036 MAE: 0.0042 Mean Error: 0.0001 STD: 0.0602\n",
      "[250/600] Loss: 0.0036 MAE: 0.0041 Mean Error: 0.0001 STD: 0.0602\n",
      "[260/600] Loss: 0.0036 MAE: 0.0041 Mean Error: 0.0001 STD: 0.0601\n",
      "[270/600] Loss: 0.0036 MAE: 0.0041 Mean Error: 0.0001 STD: 0.0601\n",
      "[280/600] Loss: 0.0036 MAE: 0.0041 Mean Error: 0.0001 STD: 0.0601\n",
      "[290/600] Loss: 0.0036 MAE: 0.0040 Mean Error: 0.0001 STD: 0.0601\n",
      "[300/600] Loss: 0.0036 MAE: 0.0040 Mean Error: 0.0001 STD: 0.0601\n",
      "[310/600] Loss: 0.0036 MAE: 0.0040 Mean Error: 0.0001 STD: 0.0601\n",
      "[320/600] Loss: 0.0036 MAE: 0.0040 Mean Error: 0.0001 STD: 0.0601\n",
      "[330/600] Loss: 0.0035 MAE: 0.0039 Mean Error: 0.0000 STD: 0.0593\n",
      "[340/600] Loss: 0.0035 MAE: 0.0040 Mean Error: 0.0000 STD: 0.0593\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[350/600] Loss: 0.0035 MAE: 0.0039 Mean Error: -0.0000 STD: 0.0593\n",
      "[360/600] Loss: 0.0035 MAE: 0.0039 Mean Error: -0.0000 STD: 0.0592\n",
      "[370/600] Loss: 0.0034 MAE: 0.0039 Mean Error: 0.0001 STD: 0.0585\n",
      "[380/600] Loss: 0.0034 MAE: 0.0038 Mean Error: 0.0001 STD: 0.0585\n",
      "[390/600] Loss: 0.0034 MAE: 0.0038 Mean Error: 0.0001 STD: 0.0585\n",
      "[400/600] Loss: 0.0034 MAE: 0.0038 Mean Error: 0.0001 STD: 0.0585\n",
      "[410/600] Loss: 0.0034 MAE: 0.0038 Mean Error: 0.0001 STD: 0.0585\n",
      "[420/600] Loss: 0.0034 MAE: 0.0038 Mean Error: 0.0001 STD: 0.0585\n",
      "[430/600] Loss: 0.0034 MAE: 0.0038 Mean Error: 0.0001 STD: 0.0585\n",
      "[440/600] Loss: 0.0034 MAE: 0.0037 Mean Error: 0.0001 STD: 0.0585\n",
      "[450/600] Loss: 0.0034 MAE: 0.0037 Mean Error: 0.0001 STD: 0.0585\n",
      "[460/600] Loss: 0.0034 MAE: 0.0037 Mean Error: 0.0001 STD: 0.0585\n",
      "[470/600] Loss: 0.0034 MAE: 0.0037 Mean Error: 0.0001 STD: 0.0585\n",
      "[480/600] Loss: 0.0034 MAE: 0.0037 Mean Error: 0.0001 STD: 0.0585\n",
      "[490/600] Loss: 0.0034 MAE: 0.0038 Mean Error: 0.0001 STD: 0.0585\n",
      "[500/600] Loss: 0.0034 MAE: 0.0037 Mean Error: 0.0001 STD: 0.0585\n",
      "[510/600] Loss: 0.0034 MAE: 0.0037 Mean Error: 0.0001 STD: 0.0585\n",
      "[520/600] Loss: 0.0034 MAE: 0.0037 Mean Error: 0.0001 STD: 0.0585\n",
      "[530/600] Loss: 0.0034 MAE: 0.0037 Mean Error: 0.0001 STD: 0.0585\n",
      "[540/600] Loss: 0.0034 MAE: 0.0037 Mean Error: 0.0001 STD: 0.0584\n",
      "[550/600] Loss: 0.0033 MAE: 0.0037 Mean Error: 0.0002 STD: 0.0576\n",
      "[560/600] Loss: 0.0033 MAE: 0.0036 Mean Error: 0.0002 STD: 0.0576\n",
      "[570/600] Loss: 0.0033 MAE: 0.0036 Mean Error: 0.0002 STD: 0.0576\n",
      "[580/600] Loss: 0.0033 MAE: 0.0036 Mean Error: 0.0002 STD: 0.0576\n",
      "[590/600] Loss: 0.0033 MAE: 0.0036 Mean Error: 0.0002 STD: 0.0576\n",
      "[599/600] Loss: 0.0033 MAE: 0.0036 Mean Error: 0.0002 STD: 0.0576\n",
      "------------------------------------\n",
      "Training dataset with noise standard deviation 0.05\n",
      "[0/600] Loss: 0.2501 MAE: 0.5000 Mean Error: 0.0944 STD: 0.4911\n",
      "[10/600] Loss: 0.1407 MAE: 0.2083 Mean Error: 0.0095 STD: 0.3750\n",
      "[20/600] Loss: 0.1227 MAE: 0.2544 Mean Error: 0.0067 STD: 0.3503\n",
      "[30/600] Loss: 0.1010 MAE: 0.2070 Mean Error: -0.0003 STD: 0.3179\n",
      "[40/600] Loss: 0.0851 MAE: 0.1757 Mean Error: -0.0018 STD: 0.2917\n",
      "[50/600] Loss: 0.0672 MAE: 0.1465 Mean Error: 0.0002 STD: 0.2593\n",
      "[60/600] Loss: 0.0425 MAE: 0.0946 Mean Error: -0.0027 STD: 0.2061\n",
      "[70/600] Loss: 0.0218 MAE: 0.0526 Mean Error: 0.0012 STD: 0.1476\n",
      "[80/600] Loss: 0.0074 MAE: 0.0187 Mean Error: -0.0000 STD: 0.0862\n",
      "[90/600] Loss: 0.0046 MAE: 0.0083 Mean Error: -0.0003 STD: 0.0677\n",
      "[100/600] Loss: 0.0042 MAE: 0.0057 Mean Error: -0.0001 STD: 0.0644\n",
      "[110/600] Loss: 0.0041 MAE: 0.0050 Mean Error: -0.0000 STD: 0.0641\n",
      "[120/600] Loss: 0.0040 MAE: 0.0047 Mean Error: 0.0001 STD: 0.0633\n",
      "[130/600] Loss: 0.0040 MAE: 0.0046 Mean Error: 0.0001 STD: 0.0633\n",
      "[140/600] Loss: 0.0039 MAE: 0.0045 Mean Error: -0.0001 STD: 0.0626\n",
      "[150/600] Loss: 0.0038 MAE: 0.0044 Mean Error: -0.0002 STD: 0.0619\n",
      "[160/600] Loss: 0.0038 MAE: 0.0043 Mean Error: -0.0001 STD: 0.0618\n",
      "[170/600] Loss: 0.0038 MAE: 0.0043 Mean Error: -0.0001 STD: 0.0617\n",
      "[180/600] Loss: 0.0038 MAE: 0.0042 Mean Error: -0.0001 STD: 0.0617\n",
      "[190/600] Loss: 0.0038 MAE: 0.0042 Mean Error: -0.0001 STD: 0.0617\n",
      "[200/600] Loss: 0.0037 MAE: 0.0041 Mean Error: -0.0002 STD: 0.0609\n",
      "[210/600] Loss: 0.0037 MAE: 0.0041 Mean Error: -0.0002 STD: 0.0609\n",
      "[220/600] Loss: 0.0037 MAE: 0.0041 Mean Error: -0.0002 STD: 0.0609\n",
      "[230/600] Loss: 0.0037 MAE: 0.0041 Mean Error: -0.0002 STD: 0.0609\n",
      "[240/600] Loss: 0.0036 MAE: 0.0041 Mean Error: -0.0002 STD: 0.0604\n",
      "[250/600] Loss: 0.0036 MAE: 0.0040 Mean Error: -0.0001 STD: 0.0601\n",
      "[260/600] Loss: 0.0036 MAE: 0.0041 Mean Error: -0.0003 STD: 0.0601\n",
      "[270/600] Loss: 0.0035 MAE: 0.0039 Mean Error: -0.0002 STD: 0.0593\n",
      "[280/600] Loss: 0.0035 MAE: 0.0039 Mean Error: -0.0002 STD: 0.0593\n",
      "[290/600] Loss: 0.0035 MAE: 0.0039 Mean Error: -0.0002 STD: 0.0593\n",
      "[300/600] Loss: 0.0035 MAE: 0.0038 Mean Error: -0.0002 STD: 0.0593\n",
      "[310/600] Loss: 0.0035 MAE: 0.0038 Mean Error: -0.0002 STD: 0.0593\n",
      "[320/600] Loss: 0.0034 MAE: 0.0038 Mean Error: -0.0001 STD: 0.0587\n",
      "[330/600] Loss: 0.0034 MAE: 0.0038 Mean Error: -0.0001 STD: 0.0585\n",
      "[340/600] Loss: 0.0034 MAE: 0.0038 Mean Error: -0.0001 STD: 0.0585\n",
      "[350/600] Loss: 0.0034 MAE: 0.0037 Mean Error: -0.0001 STD: 0.0585\n",
      "[360/600] Loss: 0.0034 MAE: 0.0037 Mean Error: -0.0001 STD: 0.0585\n",
      "[370/600] Loss: 0.0034 MAE: 0.0037 Mean Error: -0.0001 STD: 0.0585\n",
      "[380/600] Loss: 0.0034 MAE: 0.0037 Mean Error: -0.0001 STD: 0.0585\n",
      "[390/600] Loss: 0.0034 MAE: 0.0037 Mean Error: -0.0001 STD: 0.0585\n",
      "[400/600] Loss: 0.0034 MAE: 0.0037 Mean Error: -0.0001 STD: 0.0585\n",
      "[410/600] Loss: 0.0034 MAE: 0.0037 Mean Error: -0.0001 STD: 0.0585\n",
      "[420/600] Loss: 0.0034 MAE: 0.0037 Mean Error: -0.0001 STD: 0.0585\n",
      "[430/600] Loss: 0.0034 MAE: 0.0037 Mean Error: -0.0001 STD: 0.0585\n",
      "[440/600] Loss: 0.0034 MAE: 0.0037 Mean Error: -0.0001 STD: 0.0585\n",
      "[450/600] Loss: 0.0034 MAE: 0.0036 Mean Error: -0.0001 STD: 0.0585\n",
      "[460/600] Loss: 0.0034 MAE: 0.0036 Mean Error: -0.0001 STD: 0.0585\n",
      "[470/600] Loss: 0.0034 MAE: 0.0036 Mean Error: -0.0001 STD: 0.0585\n",
      "[480/600] Loss: 0.0034 MAE: 0.0036 Mean Error: -0.0001 STD: 0.0585\n",
      "[490/600] Loss: 0.0034 MAE: 0.0037 Mean Error: 0.0001 STD: 0.0583\n",
      "[500/600] Loss: 0.0033 MAE: 0.0036 Mean Error: -0.0000 STD: 0.0576\n",
      "[510/600] Loss: 0.0033 MAE: 0.0036 Mean Error: -0.0000 STD: 0.0576\n",
      "[520/600] Loss: 0.0033 MAE: 0.0036 Mean Error: -0.0000 STD: 0.0576\n",
      "[530/600] Loss: 0.0033 MAE: 0.0036 Mean Error: -0.0000 STD: 0.0576\n",
      "[540/600] Loss: 0.0033 MAE: 0.0036 Mean Error: -0.0000 STD: 0.0576\n",
      "[550/600] Loss: 0.0033 MAE: 0.0035 Mean Error: -0.0000 STD: 0.0576\n",
      "[560/600] Loss: 0.0033 MAE: 0.0035 Mean Error: -0.0000 STD: 0.0576\n",
      "[570/600] Loss: 0.0033 MAE: 0.0035 Mean Error: -0.0000 STD: 0.0576\n",
      "[580/600] Loss: 0.0033 MAE: 0.0035 Mean Error: -0.0000 STD: 0.0576\n",
      "[590/600] Loss: 0.0033 MAE: 0.0035 Mean Error: -0.0000 STD: 0.0576\n",
      "[599/600] Loss: 0.0033 MAE: 0.0035 Mean Error: -0.0000 STD: 0.0576\n",
      "------------------------------------\n",
      "Training dataset with noise standard deviation 0.1\n",
      "[0/600] Loss: 0.2499 MAE: 0.4999 Mean Error: 0.0939 STD: 0.4911\n",
      "[10/600] Loss: 0.1377 MAE: 0.2141 Mean Error: 0.0048 STD: 0.3711\n",
      "[20/600] Loss: 0.1204 MAE: 0.2525 Mean Error: 0.0001 STD: 0.3470\n",
      "[30/600] Loss: 0.0976 MAE: 0.1954 Mean Error: -0.0030 STD: 0.3124\n",
      "[40/600] Loss: 0.0816 MAE: 0.1690 Mean Error: -0.0022 STD: 0.2857\n",
      "[50/600] Loss: 0.0602 MAE: 0.1345 Mean Error: -0.0018 STD: 0.2454\n",
      "[60/600] Loss: 0.0316 MAE: 0.0788 Mean Error: -0.0037 STD: 0.1778\n",
      "[70/600] Loss: 0.0130 MAE: 0.0351 Mean Error: -0.0008 STD: 0.1142\n",
      "[80/600] Loss: 0.0061 MAE: 0.0151 Mean Error: -0.0003 STD: 0.0783\n",
      "[90/600] Loss: 0.0044 MAE: 0.0084 Mean Error: -0.0004 STD: 0.0660\n",
      "[100/600] Loss: 0.0040 MAE: 0.0062 Mean Error: -0.0003 STD: 0.0629\n",
      "[110/600] Loss: 0.0038 MAE: 0.0053 Mean Error: -0.0004 STD: 0.0614\n",
      "[120/600] Loss: 0.0036 MAE: 0.0049 Mean Error: -0.0003 STD: 0.0604\n",
      "[130/600] Loss: 0.0036 MAE: 0.0047 Mean Error: -0.0005 STD: 0.0599\n",
      "[140/600] Loss: 0.0035 MAE: 0.0045 Mean Error: -0.0004 STD: 0.0589\n",
      "[150/600] Loss: 0.0034 MAE: 0.0043 Mean Error: -0.0005 STD: 0.0586\n",
      "[160/600] Loss: 0.0034 MAE: 0.0043 Mean Error: -0.0005 STD: 0.0585\n",
      "[170/600] Loss: 0.0033 MAE: 0.0041 Mean Error: -0.0004 STD: 0.0577\n",
      "[180/600] Loss: 0.0032 MAE: 0.0040 Mean Error: -0.0003 STD: 0.0569\n",
      "[190/600] Loss: 0.0031 MAE: 0.0038 Mean Error: -0.0002 STD: 0.0560\n",
      "[200/600] Loss: 0.0031 MAE: 0.0038 Mean Error: -0.0002 STD: 0.0560\n",
      "[210/600] Loss: 0.0031 MAE: 0.0038 Mean Error: -0.0002 STD: 0.0559\n",
      "[220/600] Loss: 0.0031 MAE: 0.0037 Mean Error: -0.0002 STD: 0.0559\n",
      "[230/600] Loss: 0.0031 MAE: 0.0037 Mean Error: -0.0001 STD: 0.0553\n",
      "[240/600] Loss: 0.0030 MAE: 0.0036 Mean Error: -0.0001 STD: 0.0551\n",
      "[250/600] Loss: 0.0030 MAE: 0.0036 Mean Error: -0.0001 STD: 0.0551\n",
      "[260/600] Loss: 0.0030 MAE: 0.0036 Mean Error: -0.0001 STD: 0.0550\n",
      "[270/600] Loss: 0.0030 MAE: 0.0035 Mean Error: -0.0002 STD: 0.0544\n",
      "[280/600] Loss: 0.0029 MAE: 0.0035 Mean Error: -0.0002 STD: 0.0542\n",
      "[290/600] Loss: 0.0029 MAE: 0.0035 Mean Error: -0.0002 STD: 0.0542\n",
      "[300/600] Loss: 0.0029 MAE: 0.0034 Mean Error: -0.0002 STD: 0.0542\n",
      "[310/600] Loss: 0.0029 MAE: 0.0034 Mean Error: -0.0002 STD: 0.0542\n",
      "[320/600] Loss: 0.0029 MAE: 0.0034 Mean Error: -0.0002 STD: 0.0542\n",
      "[330/600] Loss: 0.0029 MAE: 0.0034 Mean Error: -0.0002 STD: 0.0541\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[340/600] Loss: 0.0029 MAE: 0.0033 Mean Error: -0.0002 STD: 0.0541\n",
      "[350/600] Loss: 0.0029 MAE: 0.0033 Mean Error: -0.0002 STD: 0.0541\n",
      "[360/600] Loss: 0.0029 MAE: 0.0033 Mean Error: -0.0002 STD: 0.0541\n",
      "[370/600] Loss: 0.0029 MAE: 0.0033 Mean Error: -0.0002 STD: 0.0541\n",
      "[380/600] Loss: 0.0029 MAE: 0.0033 Mean Error: -0.0002 STD: 0.0541\n",
      "[390/600] Loss: 0.0029 MAE: 0.0033 Mean Error: -0.0002 STD: 0.0541\n",
      "[400/600] Loss: 0.0029 MAE: 0.0033 Mean Error: -0.0002 STD: 0.0541\n",
      "[410/600] Loss: 0.0029 MAE: 0.0033 Mean Error: -0.0002 STD: 0.0541\n",
      "[420/600] Loss: 0.0029 MAE: 0.0033 Mean Error: -0.0002 STD: 0.0541\n",
      "[430/600] Loss: 0.0029 MAE: 0.0033 Mean Error: -0.0002 STD: 0.0541\n",
      "[440/600] Loss: 0.0029 MAE: 0.0033 Mean Error: -0.0002 STD: 0.0541\n",
      "[450/600] Loss: 0.0029 MAE: 0.0033 Mean Error: -0.0002 STD: 0.0541\n",
      "[460/600] Loss: 0.0029 MAE: 0.0033 Mean Error: -0.0002 STD: 0.0541\n",
      "[470/600] Loss: 0.0029 MAE: 0.0032 Mean Error: -0.0002 STD: 0.0537\n",
      "[480/600] Loss: 0.0028 MAE: 0.0032 Mean Error: -0.0001 STD: 0.0532\n",
      "[490/600] Loss: 0.0028 MAE: 0.0033 Mean Error: -0.0001 STD: 0.0532\n",
      "[500/600] Loss: 0.0028 MAE: 0.0032 Mean Error: -0.0001 STD: 0.0532\n",
      "[510/600] Loss: 0.0027 MAE: 0.0031 Mean Error: -0.0000 STD: 0.0524\n",
      "[520/600] Loss: 0.0027 MAE: 0.0031 Mean Error: 0.0000 STD: 0.0523\n",
      "[530/600] Loss: 0.0027 MAE: 0.0031 Mean Error: -0.0000 STD: 0.0523\n",
      "[540/600] Loss: 0.0027 MAE: 0.0030 Mean Error: -0.0000 STD: 0.0523\n",
      "[550/600] Loss: 0.0027 MAE: 0.0030 Mean Error: -0.0000 STD: 0.0523\n",
      "[560/600] Loss: 0.0027 MAE: 0.0030 Mean Error: -0.0000 STD: 0.0523\n",
      "[570/600] Loss: 0.0027 MAE: 0.0030 Mean Error: -0.0000 STD: 0.0523\n",
      "[580/600] Loss: 0.0027 MAE: 0.0030 Mean Error: -0.0000 STD: 0.0523\n",
      "[590/600] Loss: 0.0027 MAE: 0.0030 Mean Error: -0.0000 STD: 0.0523\n",
      "[599/600] Loss: 0.0027 MAE: 0.0030 Mean Error: -0.0000 STD: 0.0523\n",
      "------------------------------------\n",
      "Training dataset with noise standard deviation 0.001\n",
      "[0/600] Loss: 0.2501 MAE: 0.5000 Mean Error: 0.0945 STD: 0.4911\n",
      "[10/600] Loss: 0.1438 MAE: 0.2032 Mean Error: 0.0218 STD: 0.3786\n",
      "[20/600] Loss: 0.1250 MAE: 0.2424 Mean Error: 0.0075 STD: 0.3535\n",
      "[30/600] Loss: 0.1053 MAE: 0.2152 Mean Error: 0.0018 STD: 0.3244\n",
      "[40/600] Loss: 0.0885 MAE: 0.1843 Mean Error: -0.0007 STD: 0.2974\n",
      "[50/600] Loss: 0.0732 MAE: 0.1563 Mean Error: -0.0038 STD: 0.2706\n",
      "[60/600] Loss: 0.0481 MAE: 0.1088 Mean Error: -0.0023 STD: 0.2192\n",
      "[70/600] Loss: 0.0259 MAE: 0.0578 Mean Error: -0.0028 STD: 0.1610\n",
      "[80/600] Loss: 0.0118 MAE: 0.0262 Mean Error: -0.0015 STD: 0.1088\n",
      "[90/600] Loss: 0.0075 MAE: 0.0128 Mean Error: -0.0012 STD: 0.0868\n",
      "[100/600] Loss: 0.0067 MAE: 0.0089 Mean Error: -0.0009 STD: 0.0816\n",
      "[110/600] Loss: 0.0063 MAE: 0.0076 Mean Error: -0.0008 STD: 0.0795\n",
      "[120/600] Loss: 0.0063 MAE: 0.0072 Mean Error: -0.0008 STD: 0.0792\n",
      "[130/600] Loss: 0.0063 MAE: 0.0070 Mean Error: -0.0008 STD: 0.0791\n",
      "[140/600] Loss: 0.0063 MAE: 0.0069 Mean Error: -0.0008 STD: 0.0791\n",
      "[150/600] Loss: 0.0063 MAE: 0.0068 Mean Error: -0.0008 STD: 0.0791\n",
      "[160/600] Loss: 0.0063 MAE: 0.0068 Mean Error: -0.0008 STD: 0.0791\n",
      "[170/600] Loss: 0.0063 MAE: 0.0068 Mean Error: -0.0008 STD: 0.0791\n",
      "[180/600] Loss: 0.0062 MAE: 0.0067 Mean Error: -0.0006 STD: 0.0787\n",
      "[190/600] Loss: 0.0062 MAE: 0.0066 Mean Error: -0.0007 STD: 0.0785\n",
      "[200/600] Loss: 0.0061 MAE: 0.0066 Mean Error: -0.0007 STD: 0.0783\n",
      "[210/600] Loss: 0.0060 MAE: 0.0066 Mean Error: -0.0010 STD: 0.0773\n",
      "[220/600] Loss: 0.0060 MAE: 0.0065 Mean Error: -0.0009 STD: 0.0772\n",
      "[230/600] Loss: 0.0060 MAE: 0.0064 Mean Error: -0.0009 STD: 0.0772\n",
      "[240/600] Loss: 0.0060 MAE: 0.0064 Mean Error: -0.0009 STD: 0.0772\n",
      "[250/600] Loss: 0.0060 MAE: 0.0064 Mean Error: -0.0009 STD: 0.0772\n",
      "[260/600] Loss: 0.0059 MAE: 0.0063 Mean Error: -0.0008 STD: 0.0766\n",
      "[270/600] Loss: 0.0059 MAE: 0.0062 Mean Error: -0.0008 STD: 0.0766\n",
      "[280/600] Loss: 0.0059 MAE: 0.0062 Mean Error: -0.0008 STD: 0.0766\n",
      "[290/600] Loss: 0.0059 MAE: 0.0062 Mean Error: -0.0008 STD: 0.0766\n",
      "[300/600] Loss: 0.0059 MAE: 0.0062 Mean Error: -0.0008 STD: 0.0766\n",
      "[310/600] Loss: 0.0059 MAE: 0.0062 Mean Error: -0.0008 STD: 0.0766\n",
      "[320/600] Loss: 0.0059 MAE: 0.0062 Mean Error: -0.0008 STD: 0.0766\n",
      "[330/600] Loss: 0.0059 MAE: 0.0062 Mean Error: -0.0008 STD: 0.0766\n",
      "[340/600] Loss: 0.0059 MAE: 0.0062 Mean Error: -0.0008 STD: 0.0766\n",
      "[350/600] Loss: 0.0059 MAE: 0.0062 Mean Error: -0.0008 STD: 0.0766\n",
      "[360/600] Loss: 0.0059 MAE: 0.0061 Mean Error: -0.0008 STD: 0.0766\n",
      "[370/600] Loss: 0.0059 MAE: 0.0061 Mean Error: -0.0008 STD: 0.0766\n",
      "[380/600] Loss: 0.0059 MAE: 0.0061 Mean Error: -0.0008 STD: 0.0766\n",
      "[390/600] Loss: 0.0059 MAE: 0.0061 Mean Error: -0.0008 STD: 0.0766\n",
      "[400/600] Loss: 0.0059 MAE: 0.0061 Mean Error: -0.0008 STD: 0.0766\n",
      "[410/600] Loss: 0.0059 MAE: 0.0061 Mean Error: -0.0008 STD: 0.0766\n",
      "[420/600] Loss: 0.0059 MAE: 0.0061 Mean Error: -0.0008 STD: 0.0766\n",
      "[430/600] Loss: 0.0059 MAE: 0.0061 Mean Error: -0.0008 STD: 0.0766\n",
      "[440/600] Loss: 0.0059 MAE: 0.0061 Mean Error: -0.0008 STD: 0.0766\n",
      "[450/600] Loss: 0.0059 MAE: 0.0061 Mean Error: -0.0008 STD: 0.0766\n",
      "[460/600] Loss: 0.0059 MAE: 0.0061 Mean Error: -0.0008 STD: 0.0766\n",
      "[470/600] Loss: 0.0059 MAE: 0.0061 Mean Error: -0.0008 STD: 0.0766\n",
      "[480/600] Loss: 0.0059 MAE: 0.0061 Mean Error: -0.0008 STD: 0.0766\n",
      "[490/600] Loss: 0.0059 MAE: 0.0061 Mean Error: -0.0008 STD: 0.0766\n",
      "[500/600] Loss: 0.0059 MAE: 0.0061 Mean Error: -0.0008 STD: 0.0766\n",
      "[510/600] Loss: 0.0059 MAE: 0.0061 Mean Error: -0.0008 STD: 0.0765\n",
      "[520/600] Loss: 0.0058 MAE: 0.0061 Mean Error: -0.0007 STD: 0.0764\n",
      "[530/600] Loss: 0.0059 MAE: 0.0063 Mean Error: -0.0009 STD: 0.0766\n",
      "[540/600] Loss: 0.0059 MAE: 0.0062 Mean Error: -0.0008 STD: 0.0766\n",
      "[550/600] Loss: 0.0059 MAE: 0.0061 Mean Error: -0.0008 STD: 0.0766\n",
      "[560/600] Loss: 0.0059 MAE: 0.0061 Mean Error: -0.0008 STD: 0.0766\n",
      "[570/600] Loss: 0.0059 MAE: 0.0061 Mean Error: -0.0008 STD: 0.0766\n",
      "[580/600] Loss: 0.0059 MAE: 0.0061 Mean Error: -0.0008 STD: 0.0766\n",
      "[590/600] Loss: 0.0059 MAE: 0.0061 Mean Error: -0.0008 STD: 0.0766\n",
      "[599/600] Loss: 0.0059 MAE: 0.0061 Mean Error: -0.0008 STD: 0.0766\n",
      "------------------------------------\n",
      "Training dataset with noise standard deviation 0.002\n",
      "[0/600] Loss: 0.2500 MAE: 0.5000 Mean Error: 0.0944 STD: 0.4911\n",
      "[10/600] Loss: 0.1414 MAE: 0.2074 Mean Error: 0.0113 STD: 0.3759\n",
      "[20/600] Loss: 0.1252 MAE: 0.2430 Mean Error: 0.0033 STD: 0.3538\n",
      "[30/600] Loss: 0.1077 MAE: 0.2240 Mean Error: 0.0017 STD: 0.3282\n",
      "[40/600] Loss: 0.0884 MAE: 0.1799 Mean Error: -0.0014 STD: 0.2974\n",
      "[50/600] Loss: 0.0690 MAE: 0.1497 Mean Error: -0.0024 STD: 0.2627\n",
      "[60/600] Loss: 0.0413 MAE: 0.0931 Mean Error: -0.0061 STD: 0.2032\n",
      "[70/600] Loss: 0.0197 MAE: 0.0471 Mean Error: -0.0011 STD: 0.1404\n",
      "[80/600] Loss: 0.0099 MAE: 0.0209 Mean Error: -0.0007 STD: 0.0996\n",
      "[90/600] Loss: 0.0065 MAE: 0.0114 Mean Error: -0.0006 STD: 0.0808\n",
      "[100/600] Loss: 0.0057 MAE: 0.0078 Mean Error: -0.0001 STD: 0.0754\n",
      "[110/600] Loss: 0.0055 MAE: 0.0066 Mean Error: -0.0000 STD: 0.0741\n",
      "[120/600] Loss: 0.0055 MAE: 0.0063 Mean Error: -0.0000 STD: 0.0740\n",
      "[130/600] Loss: 0.0053 MAE: 0.0061 Mean Error: 0.0002 STD: 0.0726\n",
      "[140/600] Loss: 0.0051 MAE: 0.0059 Mean Error: 0.0001 STD: 0.0714\n",
      "[150/600] Loss: 0.0050 MAE: 0.0057 Mean Error: 0.0002 STD: 0.0706\n",
      "[160/600] Loss: 0.0050 MAE: 0.0056 Mean Error: 0.0003 STD: 0.0706\n",
      "[170/600] Loss: 0.0050 MAE: 0.0056 Mean Error: 0.0003 STD: 0.0705\n",
      "[180/600] Loss: 0.0049 MAE: 0.0055 Mean Error: 0.0003 STD: 0.0699\n",
      "[190/600] Loss: 0.0049 MAE: 0.0054 Mean Error: 0.0004 STD: 0.0699\n",
      "[200/600] Loss: 0.0048 MAE: 0.0054 Mean Error: 0.0005 STD: 0.0696\n",
      "[210/600] Loss: 0.0048 MAE: 0.0053 Mean Error: 0.0005 STD: 0.0692\n",
      "[220/600] Loss: 0.0048 MAE: 0.0053 Mean Error: 0.0005 STD: 0.0692\n",
      "[230/600] Loss: 0.0048 MAE: 0.0052 Mean Error: 0.0005 STD: 0.0692\n",
      "[240/600] Loss: 0.0048 MAE: 0.0052 Mean Error: 0.0005 STD: 0.0692\n",
      "[250/600] Loss: 0.0046 MAE: 0.0052 Mean Error: 0.0004 STD: 0.0682\n",
      "[260/600] Loss: 0.0045 MAE: 0.0051 Mean Error: 0.0005 STD: 0.0671\n",
      "[270/600] Loss: 0.0045 MAE: 0.0050 Mean Error: 0.0006 STD: 0.0671\n",
      "[280/600] Loss: 0.0045 MAE: 0.0049 Mean Error: 0.0006 STD: 0.0670\n",
      "[290/600] Loss: 0.0045 MAE: 0.0049 Mean Error: 0.0006 STD: 0.0670\n",
      "[300/600] Loss: 0.0045 MAE: 0.0049 Mean Error: 0.0006 STD: 0.0670\n",
      "[310/600] Loss: 0.0045 MAE: 0.0049 Mean Error: 0.0006 STD: 0.0670\n",
      "[320/600] Loss: 0.0045 MAE: 0.0048 Mean Error: 0.0006 STD: 0.0670\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[330/600] Loss: 0.0045 MAE: 0.0048 Mean Error: 0.0006 STD: 0.0670\n",
      "[340/600] Loss: 0.0045 MAE: 0.0048 Mean Error: 0.0006 STD: 0.0670\n",
      "[350/600] Loss: 0.0045 MAE: 0.0048 Mean Error: 0.0006 STD: 0.0670\n",
      "[360/600] Loss: 0.0045 MAE: 0.0049 Mean Error: 0.0006 STD: 0.0670\n",
      "[370/600] Loss: 0.0044 MAE: 0.0049 Mean Error: 0.0007 STD: 0.0664\n",
      "[380/600] Loss: 0.0044 MAE: 0.0048 Mean Error: 0.0007 STD: 0.0663\n",
      "[390/600] Loss: 0.0044 MAE: 0.0047 Mean Error: 0.0007 STD: 0.0663\n",
      "[400/600] Loss: 0.0044 MAE: 0.0047 Mean Error: 0.0007 STD: 0.0663\n",
      "[410/600] Loss: 0.0044 MAE: 0.0047 Mean Error: 0.0007 STD: 0.0663\n",
      "[420/600] Loss: 0.0044 MAE: 0.0047 Mean Error: 0.0007 STD: 0.0663\n",
      "[430/600] Loss: 0.0044 MAE: 0.0047 Mean Error: 0.0007 STD: 0.0663\n",
      "[440/600] Loss: 0.0044 MAE: 0.0047 Mean Error: 0.0007 STD: 0.0663\n",
      "[450/600] Loss: 0.0044 MAE: 0.0047 Mean Error: 0.0009 STD: 0.0667\n",
      "[460/600] Loss: 0.0042 MAE: 0.0046 Mean Error: 0.0008 STD: 0.0652\n",
      "[470/600] Loss: 0.0042 MAE: 0.0046 Mean Error: 0.0009 STD: 0.0648\n",
      "[480/600] Loss: 0.0042 MAE: 0.0046 Mean Error: 0.0009 STD: 0.0648\n",
      "[490/600] Loss: 0.0042 MAE: 0.0045 Mean Error: 0.0009 STD: 0.0648\n",
      "[500/600] Loss: 0.0042 MAE: 0.0045 Mean Error: 0.0009 STD: 0.0648\n",
      "[510/600] Loss: 0.0042 MAE: 0.0045 Mean Error: 0.0009 STD: 0.0648\n",
      "[520/600] Loss: 0.0041 MAE: 0.0044 Mean Error: 0.0008 STD: 0.0641\n",
      "[530/600] Loss: 0.0041 MAE: 0.0044 Mean Error: 0.0007 STD: 0.0641\n",
      "[540/600] Loss: 0.0041 MAE: 0.0044 Mean Error: 0.0007 STD: 0.0641\n",
      "[550/600] Loss: 0.0041 MAE: 0.0044 Mean Error: 0.0008 STD: 0.0640\n",
      "[560/600] Loss: 0.0041 MAE: 0.0044 Mean Error: 0.0008 STD: 0.0640\n",
      "[570/600] Loss: 0.0041 MAE: 0.0044 Mean Error: 0.0008 STD: 0.0640\n",
      "[580/600] Loss: 0.0041 MAE: 0.0043 Mean Error: 0.0008 STD: 0.0640\n",
      "[590/600] Loss: 0.0041 MAE: 0.0043 Mean Error: 0.0008 STD: 0.0640\n",
      "[599/600] Loss: 0.0041 MAE: 0.0043 Mean Error: 0.0008 STD: 0.0640\n",
      "------------------------------------\n",
      "Training dataset with noise standard deviation 0.003\n",
      "[0/600] Loss: 0.2498 MAE: 0.4997 Mean Error: 0.0937 STD: 0.4910\n",
      "[10/600] Loss: 0.1419 MAE: 0.2067 Mean Error: 0.0142 STD: 0.3764\n",
      "[20/600] Loss: 0.1255 MAE: 0.2530 Mean Error: 0.0055 STD: 0.3542\n",
      "[30/600] Loss: 0.1099 MAE: 0.2325 Mean Error: 0.0044 STD: 0.3315\n",
      "[40/600] Loss: 0.0898 MAE: 0.1831 Mean Error: -0.0014 STD: 0.2997\n",
      "[50/600] Loss: 0.0743 MAE: 0.1562 Mean Error: -0.0024 STD: 0.2727\n",
      "[60/600] Loss: 0.0520 MAE: 0.1172 Mean Error: -0.0004 STD: 0.2279\n",
      "[70/600] Loss: 0.0293 MAE: 0.0673 Mean Error: -0.0007 STD: 0.1712\n",
      "[80/600] Loss: 0.0117 MAE: 0.0303 Mean Error: -0.0014 STD: 0.1081\n",
      "[90/600] Loss: 0.0062 MAE: 0.0124 Mean Error: -0.0004 STD: 0.0784\n",
      "[100/600] Loss: 0.0053 MAE: 0.0077 Mean Error: -0.0002 STD: 0.0729\n",
      "[110/600] Loss: 0.0051 MAE: 0.0064 Mean Error: -0.0003 STD: 0.0716\n",
      "[120/600] Loss: 0.0050 MAE: 0.0060 Mean Error: -0.0003 STD: 0.0709\n",
      "[130/600] Loss: 0.0050 MAE: 0.0057 Mean Error: -0.0003 STD: 0.0706\n",
      "[140/600] Loss: 0.0048 MAE: 0.0055 Mean Error: -0.0003 STD: 0.0692\n",
      "[150/600] Loss: 0.0047 MAE: 0.0054 Mean Error: -0.0002 STD: 0.0686\n",
      "[160/600] Loss: 0.0047 MAE: 0.0053 Mean Error: -0.0002 STD: 0.0685\n",
      "[170/600] Loss: 0.0047 MAE: 0.0053 Mean Error: -0.0002 STD: 0.0685\n",
      "[180/600] Loss: 0.0046 MAE: 0.0052 Mean Error: -0.0001 STD: 0.0678\n",
      "[190/600] Loss: 0.0046 MAE: 0.0052 Mean Error: -0.0001 STD: 0.0678\n",
      "[200/600] Loss: 0.0046 MAE: 0.0051 Mean Error: -0.0001 STD: 0.0678\n",
      "[210/600] Loss: 0.0046 MAE: 0.0051 Mean Error: -0.0001 STD: 0.0678\n",
      "[220/600] Loss: 0.0046 MAE: 0.0051 Mean Error: -0.0001 STD: 0.0678\n",
      "[230/600] Loss: 0.0046 MAE: 0.0050 Mean Error: -0.0001 STD: 0.0678\n",
      "[240/600] Loss: 0.0046 MAE: 0.0050 Mean Error: -0.0001 STD: 0.0678\n",
      "[250/600] Loss: 0.0046 MAE: 0.0050 Mean Error: -0.0001 STD: 0.0678\n",
      "[260/600] Loss: 0.0046 MAE: 0.0050 Mean Error: -0.0001 STD: 0.0678\n",
      "[270/600] Loss: 0.0046 MAE: 0.0049 Mean Error: -0.0001 STD: 0.0678\n",
      "[280/600] Loss: 0.0046 MAE: 0.0049 Mean Error: -0.0001 STD: 0.0678\n",
      "[290/600] Loss: 0.0046 MAE: 0.0049 Mean Error: -0.0001 STD: 0.0678\n",
      "[300/600] Loss: 0.0046 MAE: 0.0049 Mean Error: -0.0001 STD: 0.0678\n",
      "[310/600] Loss: 0.0045 MAE: 0.0049 Mean Error: -0.0002 STD: 0.0671\n",
      "[320/600] Loss: 0.0045 MAE: 0.0049 Mean Error: -0.0002 STD: 0.0670\n",
      "[330/600] Loss: 0.0045 MAE: 0.0048 Mean Error: -0.0002 STD: 0.0670\n",
      "[340/600] Loss: 0.0045 MAE: 0.0048 Mean Error: -0.0002 STD: 0.0670\n",
      "[350/600] Loss: 0.0045 MAE: 0.0048 Mean Error: -0.0002 STD: 0.0670\n",
      "[360/600] Loss: 0.0045 MAE: 0.0048 Mean Error: -0.0002 STD: 0.0670\n",
      "[370/600] Loss: 0.0045 MAE: 0.0048 Mean Error: -0.0002 STD: 0.0670\n",
      "[380/600] Loss: 0.0045 MAE: 0.0048 Mean Error: -0.0002 STD: 0.0670\n",
      "[390/600] Loss: 0.0043 MAE: 0.0047 Mean Error: -0.0002 STD: 0.0656\n",
      "[400/600] Loss: 0.0043 MAE: 0.0047 Mean Error: -0.0002 STD: 0.0656\n",
      "[410/600] Loss: 0.0043 MAE: 0.0046 Mean Error: -0.0002 STD: 0.0656\n",
      "[420/600] Loss: 0.0043 MAE: 0.0046 Mean Error: -0.0002 STD: 0.0656\n",
      "[430/600] Loss: 0.0043 MAE: 0.0046 Mean Error: -0.0002 STD: 0.0656\n",
      "[440/600] Loss: 0.0043 MAE: 0.0045 Mean Error: -0.0002 STD: 0.0656\n",
      "[450/600] Loss: 0.0042 MAE: 0.0045 Mean Error: -0.0000 STD: 0.0650\n",
      "[460/600] Loss: 0.0042 MAE: 0.0045 Mean Error: -0.0001 STD: 0.0648\n",
      "[470/600] Loss: 0.0042 MAE: 0.0045 Mean Error: -0.0001 STD: 0.0648\n",
      "[480/600] Loss: 0.0042 MAE: 0.0045 Mean Error: -0.0001 STD: 0.0648\n",
      "[490/600] Loss: 0.0042 MAE: 0.0044 Mean Error: -0.0001 STD: 0.0648\n",
      "[500/600] Loss: 0.0042 MAE: 0.0044 Mean Error: -0.0001 STD: 0.0648\n",
      "[510/600] Loss: 0.0042 MAE: 0.0044 Mean Error: -0.0001 STD: 0.0648\n",
      "[520/600] Loss: 0.0041 MAE: 0.0043 Mean Error: -0.0000 STD: 0.0641\n",
      "[530/600] Loss: 0.0041 MAE: 0.0044 Mean Error: -0.0000 STD: 0.0641\n",
      "[540/600] Loss: 0.0041 MAE: 0.0043 Mean Error: -0.0000 STD: 0.0641\n",
      "[550/600] Loss: 0.0041 MAE: 0.0043 Mean Error: -0.0000 STD: 0.0641\n",
      "[560/600] Loss: 0.0040 MAE: 0.0042 Mean Error: -0.0001 STD: 0.0633\n",
      "[570/600] Loss: 0.0040 MAE: 0.0043 Mean Error: -0.0001 STD: 0.0633\n",
      "[580/600] Loss: 0.0040 MAE: 0.0042 Mean Error: -0.0001 STD: 0.0633\n",
      "[590/600] Loss: 0.0040 MAE: 0.0042 Mean Error: -0.0001 STD: 0.0633\n",
      "[599/600] Loss: 0.0040 MAE: 0.0042 Mean Error: -0.0001 STD: 0.0633\n",
      "------------------------------------\n",
      "Training dataset with noise standard deviation 0.005\n",
      "[0/600] Loss: 0.2503 MAE: 0.5002 Mean Error: 0.0942 STD: 0.4914\n",
      "[10/600] Loss: 0.1398 MAE: 0.2104 Mean Error: 0.0080 STD: 0.3738\n",
      "[20/600] Loss: 0.1238 MAE: 0.2504 Mean Error: 0.0049 STD: 0.3518\n",
      "[30/600] Loss: 0.1042 MAE: 0.2131 Mean Error: -0.0004 STD: 0.3228\n",
      "[40/600] Loss: 0.0870 MAE: 0.1862 Mean Error: -0.0031 STD: 0.2949\n",
      "[50/600] Loss: 0.0610 MAE: 0.1337 Mean Error: -0.0033 STD: 0.2470\n",
      "[60/600] Loss: 0.0339 MAE: 0.0790 Mean Error: -0.0012 STD: 0.1840\n",
      "[70/600] Loss: 0.0149 MAE: 0.0339 Mean Error: 0.0007 STD: 0.1221\n",
      "[80/600] Loss: 0.0078 MAE: 0.0138 Mean Error: 0.0020 STD: 0.0881\n",
      "[90/600] Loss: 0.0064 MAE: 0.0088 Mean Error: 0.0016 STD: 0.0799\n",
      "[100/600] Loss: 0.0060 MAE: 0.0074 Mean Error: 0.0016 STD: 0.0775\n",
      "[110/600] Loss: 0.0060 MAE: 0.0069 Mean Error: 0.0016 STD: 0.0773\n",
      "[120/600] Loss: 0.0060 MAE: 0.0067 Mean Error: 0.0016 STD: 0.0772\n",
      "[130/600] Loss: 0.0060 MAE: 0.0066 Mean Error: 0.0016 STD: 0.0772\n",
      "[140/600] Loss: 0.0060 MAE: 0.0065 Mean Error: 0.0016 STD: 0.0772\n",
      "[150/600] Loss: 0.0060 MAE: 0.0065 Mean Error: 0.0016 STD: 0.0772\n",
      "[160/600] Loss: 0.0060 MAE: 0.0064 Mean Error: 0.0016 STD: 0.0772\n",
      "[170/600] Loss: 0.0060 MAE: 0.0064 Mean Error: 0.0016 STD: 0.0772\n",
      "[180/600] Loss: 0.0060 MAE: 0.0064 Mean Error: 0.0016 STD: 0.0772\n",
      "[190/600] Loss: 0.0060 MAE: 0.0064 Mean Error: 0.0016 STD: 0.0772\n",
      "[200/600] Loss: 0.0060 MAE: 0.0064 Mean Error: 0.0016 STD: 0.0772\n",
      "[210/600] Loss: 0.0059 MAE: 0.0064 Mean Error: 0.0015 STD: 0.0769\n",
      "[220/600] Loss: 0.0059 MAE: 0.0063 Mean Error: 0.0015 STD: 0.0766\n",
      "[230/600] Loss: 0.0059 MAE: 0.0063 Mean Error: 0.0016 STD: 0.0766\n",
      "[240/600] Loss: 0.0059 MAE: 0.0063 Mean Error: 0.0015 STD: 0.0766\n",
      "[250/600] Loss: 0.0059 MAE: 0.0062 Mean Error: 0.0015 STD: 0.0765\n",
      "[260/600] Loss: 0.0059 MAE: 0.0062 Mean Error: 0.0015 STD: 0.0765\n",
      "[270/600] Loss: 0.0059 MAE: 0.0062 Mean Error: 0.0015 STD: 0.0765\n",
      "[280/600] Loss: 0.0059 MAE: 0.0062 Mean Error: 0.0015 STD: 0.0765\n",
      "[290/600] Loss: 0.0059 MAE: 0.0062 Mean Error: 0.0015 STD: 0.0765\n",
      "[300/600] Loss: 0.0059 MAE: 0.0062 Mean Error: 0.0015 STD: 0.0765\n",
      "[310/600] Loss: 0.0059 MAE: 0.0062 Mean Error: 0.0015 STD: 0.0765\n",
      "[320/600] Loss: 0.0059 MAE: 0.0062 Mean Error: 0.0015 STD: 0.0765\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[330/600] Loss: 0.0059 MAE: 0.0062 Mean Error: 0.0015 STD: 0.0765\n",
      "[340/600] Loss: 0.0059 MAE: 0.0062 Mean Error: 0.0015 STD: 0.0765\n",
      "[350/600] Loss: 0.0059 MAE: 0.0062 Mean Error: 0.0015 STD: 0.0765\n",
      "[360/600] Loss: 0.0059 MAE: 0.0062 Mean Error: 0.0016 STD: 0.0765\n",
      "[370/600] Loss: 0.0058 MAE: 0.0061 Mean Error: 0.0016 STD: 0.0759\n",
      "[380/600] Loss: 0.0058 MAE: 0.0061 Mean Error: 0.0016 STD: 0.0759\n",
      "[390/600] Loss: 0.0058 MAE: 0.0061 Mean Error: 0.0016 STD: 0.0759\n",
      "[400/600] Loss: 0.0057 MAE: 0.0061 Mean Error: 0.0015 STD: 0.0753\n",
      "[410/600] Loss: 0.0057 MAE: 0.0060 Mean Error: 0.0015 STD: 0.0753\n",
      "[420/600] Loss: 0.0057 MAE: 0.0060 Mean Error: 0.0015 STD: 0.0753\n",
      "[430/600] Loss: 0.0057 MAE: 0.0060 Mean Error: 0.0015 STD: 0.0753\n",
      "[440/600] Loss: 0.0056 MAE: 0.0059 Mean Error: 0.0015 STD: 0.0746\n",
      "[450/600] Loss: 0.0056 MAE: 0.0059 Mean Error: 0.0015 STD: 0.0746\n",
      "[460/600] Loss: 0.0056 MAE: 0.0059 Mean Error: 0.0015 STD: 0.0746\n",
      "[470/600] Loss: 0.0056 MAE: 0.0058 Mean Error: 0.0015 STD: 0.0746\n",
      "[480/600] Loss: 0.0056 MAE: 0.0058 Mean Error: 0.0015 STD: 0.0746\n",
      "[490/600] Loss: 0.0056 MAE: 0.0058 Mean Error: 0.0015 STD: 0.0746\n",
      "[500/600] Loss: 0.0056 MAE: 0.0058 Mean Error: 0.0015 STD: 0.0746\n",
      "[510/600] Loss: 0.0056 MAE: 0.0058 Mean Error: 0.0015 STD: 0.0746\n",
      "[520/600] Loss: 0.0056 MAE: 0.0058 Mean Error: 0.0015 STD: 0.0746\n",
      "[530/600] Loss: 0.0056 MAE: 0.0058 Mean Error: 0.0015 STD: 0.0746\n",
      "[540/600] Loss: 0.0056 MAE: 0.0058 Mean Error: 0.0015 STD: 0.0746\n",
      "[550/600] Loss: 0.0056 MAE: 0.0058 Mean Error: 0.0015 STD: 0.0746\n",
      "[560/600] Loss: 0.0056 MAE: 0.0058 Mean Error: 0.0015 STD: 0.0746\n",
      "[570/600] Loss: 0.0056 MAE: 0.0058 Mean Error: 0.0015 STD: 0.0746\n",
      "[580/600] Loss: 0.0056 MAE: 0.0058 Mean Error: 0.0015 STD: 0.0746\n",
      "[590/600] Loss: 0.0056 MAE: 0.0059 Mean Error: 0.0016 STD: 0.0751\n",
      "[599/600] Loss: 0.0055 MAE: 0.0058 Mean Error: 0.0012 STD: 0.0743\n",
      "------------------------------------\n",
      "Training dataset with noise standard deviation 0.01\n",
      "[0/600] Loss: 0.2505 MAE: 0.5004 Mean Error: 0.0946 STD: 0.4915\n",
      "[10/600] Loss: 0.1406 MAE: 0.2089 Mean Error: 0.0108 STD: 0.3748\n",
      "[20/600] Loss: 0.1260 MAE: 0.2497 Mean Error: 0.0076 STD: 0.3549\n",
      "[30/600] Loss: 0.1144 MAE: 0.2412 Mean Error: 0.0062 STD: 0.3382\n",
      "[40/600] Loss: 0.0909 MAE: 0.1806 Mean Error: -0.0020 STD: 0.3015\n",
      "[50/600] Loss: 0.0705 MAE: 0.1545 Mean Error: -0.0071 STD: 0.2654\n",
      "[60/600] Loss: 0.0417 MAE: 0.0911 Mean Error: -0.0013 STD: 0.2041\n",
      "[70/600] Loss: 0.0205 MAE: 0.0463 Mean Error: -0.0028 STD: 0.1431\n",
      "[80/600] Loss: 0.0116 MAE: 0.0224 Mean Error: -0.0018 STD: 0.1079\n",
      "[90/600] Loss: 0.0085 MAE: 0.0136 Mean Error: -0.0015 STD: 0.0922\n",
      "[100/600] Loss: 0.0074 MAE: 0.0100 Mean Error: -0.0011 STD: 0.0861\n",
      "[110/600] Loss: 0.0073 MAE: 0.0087 Mean Error: -0.0012 STD: 0.0852\n",
      "[120/600] Loss: 0.0072 MAE: 0.0082 Mean Error: -0.0012 STD: 0.0851\n",
      "[130/600] Loss: 0.0071 MAE: 0.0079 Mean Error: -0.0011 STD: 0.0840\n",
      "[140/600] Loss: 0.0070 MAE: 0.0078 Mean Error: -0.0010 STD: 0.0839\n",
      "[150/600] Loss: 0.0069 MAE: 0.0077 Mean Error: -0.0009 STD: 0.0833\n",
      "[160/600] Loss: 0.0069 MAE: 0.0076 Mean Error: -0.0009 STD: 0.0833\n",
      "[170/600] Loss: 0.0069 MAE: 0.0075 Mean Error: -0.0009 STD: 0.0833\n",
      "[180/600] Loss: 0.0068 MAE: 0.0074 Mean Error: -0.0009 STD: 0.0822\n",
      "[190/600] Loss: 0.0067 MAE: 0.0074 Mean Error: -0.0009 STD: 0.0821\n",
      "[200/600] Loss: 0.0067 MAE: 0.0073 Mean Error: -0.0008 STD: 0.0816\n",
      "[210/600] Loss: 0.0066 MAE: 0.0072 Mean Error: -0.0008 STD: 0.0815\n",
      "[220/600] Loss: 0.0066 MAE: 0.0072 Mean Error: -0.0009 STD: 0.0811\n",
      "[230/600] Loss: 0.0065 MAE: 0.0071 Mean Error: -0.0009 STD: 0.0809\n",
      "[240/600] Loss: 0.0065 MAE: 0.0071 Mean Error: -0.0011 STD: 0.0808\n",
      "[250/600] Loss: 0.0064 MAE: 0.0069 Mean Error: -0.0009 STD: 0.0797\n",
      "[260/600] Loss: 0.0063 MAE: 0.0068 Mean Error: -0.0007 STD: 0.0792\n",
      "[270/600] Loss: 0.0062 MAE: 0.0068 Mean Error: -0.0007 STD: 0.0785\n",
      "[280/600] Loss: 0.0062 MAE: 0.0066 Mean Error: -0.0007 STD: 0.0785\n",
      "[290/600] Loss: 0.0061 MAE: 0.0065 Mean Error: -0.0006 STD: 0.0779\n",
      "[300/600] Loss: 0.0061 MAE: 0.0065 Mean Error: -0.0006 STD: 0.0778\n",
      "[310/600] Loss: 0.0060 MAE: 0.0064 Mean Error: -0.0005 STD: 0.0772\n",
      "[320/600] Loss: 0.0060 MAE: 0.0063 Mean Error: -0.0005 STD: 0.0772\n",
      "[330/600] Loss: 0.0059 MAE: 0.0064 Mean Error: -0.0003 STD: 0.0770\n",
      "[340/600] Loss: 0.0058 MAE: 0.0062 Mean Error: -0.0003 STD: 0.0760\n",
      "[350/600] Loss: 0.0057 MAE: 0.0061 Mean Error: -0.0004 STD: 0.0753\n",
      "[360/600] Loss: 0.0057 MAE: 0.0061 Mean Error: -0.0004 STD: 0.0753\n",
      "[370/600] Loss: 0.0055 MAE: 0.0059 Mean Error: -0.0002 STD: 0.0740\n",
      "[380/600] Loss: 0.0054 MAE: 0.0058 Mean Error: -0.0001 STD: 0.0733\n",
      "[390/600] Loss: 0.0054 MAE: 0.0058 Mean Error: -0.0001 STD: 0.0733\n",
      "[400/600] Loss: 0.0054 MAE: 0.0057 Mean Error: -0.0001 STD: 0.0733\n",
      "[410/600] Loss: 0.0054 MAE: 0.0057 Mean Error: -0.0001 STD: 0.0733\n",
      "[420/600] Loss: 0.0053 MAE: 0.0056 Mean Error: -0.0001 STD: 0.0730\n",
      "[430/600] Loss: 0.0053 MAE: 0.0057 Mean Error: 0.0000 STD: 0.0726\n",
      "[440/600] Loss: 0.0053 MAE: 0.0057 Mean Error: 0.0000 STD: 0.0726\n",
      "[450/600] Loss: 0.0052 MAE: 0.0055 Mean Error: 0.0000 STD: 0.0720\n",
      "[460/600] Loss: 0.0052 MAE: 0.0055 Mean Error: 0.0001 STD: 0.0720\n",
      "[470/600] Loss: 0.0051 MAE: 0.0055 Mean Error: 0.0003 STD: 0.0716\n",
      "[480/600] Loss: 0.0051 MAE: 0.0054 Mean Error: 0.0002 STD: 0.0713\n",
      "[490/600] Loss: 0.0050 MAE: 0.0053 Mean Error: 0.0003 STD: 0.0706\n",
      "[500/600] Loss: 0.0049 MAE: 0.0054 Mean Error: 0.0004 STD: 0.0700\n",
      "[510/600] Loss: 0.0049 MAE: 0.0052 Mean Error: 0.0004 STD: 0.0699\n",
      "[520/600] Loss: 0.0049 MAE: 0.0052 Mean Error: 0.0004 STD: 0.0699\n",
      "[530/600] Loss: 0.0046 MAE: 0.0050 Mean Error: 0.0005 STD: 0.0679\n",
      "[540/600] Loss: 0.0045 MAE: 0.0049 Mean Error: 0.0006 STD: 0.0671\n",
      "[550/600] Loss: 0.0045 MAE: 0.0048 Mean Error: 0.0006 STD: 0.0670\n",
      "[560/600] Loss: 0.0045 MAE: 0.0048 Mean Error: 0.0006 STD: 0.0670\n",
      "[570/600] Loss: 0.0044 MAE: 0.0049 Mean Error: 0.0007 STD: 0.0666\n",
      "[580/600] Loss: 0.0044 MAE: 0.0048 Mean Error: 0.0006 STD: 0.0663\n",
      "[590/600] Loss: 0.0042 MAE: 0.0046 Mean Error: 0.0009 STD: 0.0648\n",
      "[599/600] Loss: 0.0042 MAE: 0.0046 Mean Error: 0.0009 STD: 0.0648\n",
      "------------------------------------\n",
      "Training dataset with noise standard deviation 0.02\n",
      "[0/600] Loss: 0.2502 MAE: 0.5001 Mean Error: 0.0945 STD: 0.4912\n",
      "[10/600] Loss: 0.1393 MAE: 0.2119 Mean Error: 0.0109 STD: 0.3731\n",
      "[20/600] Loss: 0.1258 MAE: 0.2554 Mean Error: 0.0040 STD: 0.3547\n",
      "[30/600] Loss: 0.1167 MAE: 0.2473 Mean Error: 0.0099 STD: 0.3414\n",
      "[40/600] Loss: 0.0951 MAE: 0.1891 Mean Error: -0.0010 STD: 0.3084\n",
      "[50/600] Loss: 0.0804 MAE: 0.1656 Mean Error: 0.0013 STD: 0.2836\n",
      "[60/600] Loss: 0.0614 MAE: 0.1377 Mean Error: -0.0033 STD: 0.2478\n",
      "[70/600] Loss: 0.0301 MAE: 0.0752 Mean Error: 0.0015 STD: 0.1735\n",
      "[80/600] Loss: 0.0113 MAE: 0.0279 Mean Error: 0.0009 STD: 0.1061\n",
      "[90/600] Loss: 0.0060 MAE: 0.0126 Mean Error: 0.0014 STD: 0.0776\n",
      "[100/600] Loss: 0.0049 MAE: 0.0076 Mean Error: 0.0018 STD: 0.0698\n",
      "[110/600] Loss: 0.0045 MAE: 0.0061 Mean Error: 0.0017 STD: 0.0669\n",
      "[120/600] Loss: 0.0043 MAE: 0.0054 Mean Error: 0.0020 STD: 0.0657\n",
      "[130/600] Loss: 0.0043 MAE: 0.0052 Mean Error: 0.0018 STD: 0.0652\n",
      "[140/600] Loss: 0.0042 MAE: 0.0050 Mean Error: 0.0018 STD: 0.0649\n",
      "[150/600] Loss: 0.0042 MAE: 0.0049 Mean Error: 0.0018 STD: 0.0648\n",
      "[160/600] Loss: 0.0042 MAE: 0.0048 Mean Error: 0.0018 STD: 0.0648\n",
      "[170/600] Loss: 0.0042 MAE: 0.0048 Mean Error: 0.0018 STD: 0.0648\n",
      "[180/600] Loss: 0.0042 MAE: 0.0048 Mean Error: 0.0018 STD: 0.0648\n",
      "[190/600] Loss: 0.0042 MAE: 0.0048 Mean Error: 0.0018 STD: 0.0648\n",
      "[200/600] Loss: 0.0042 MAE: 0.0047 Mean Error: 0.0018 STD: 0.0648\n",
      "[210/600] Loss: 0.0041 MAE: 0.0047 Mean Error: 0.0018 STD: 0.0641\n",
      "[220/600] Loss: 0.0041 MAE: 0.0047 Mean Error: 0.0017 STD: 0.0641\n",
      "[230/600] Loss: 0.0041 MAE: 0.0046 Mean Error: 0.0017 STD: 0.0640\n",
      "[240/600] Loss: 0.0041 MAE: 0.0046 Mean Error: 0.0017 STD: 0.0640\n",
      "[250/600] Loss: 0.0041 MAE: 0.0046 Mean Error: 0.0017 STD: 0.0640\n",
      "[260/600] Loss: 0.0041 MAE: 0.0046 Mean Error: 0.0017 STD: 0.0640\n",
      "[270/600] Loss: 0.0040 MAE: 0.0046 Mean Error: 0.0016 STD: 0.0636\n",
      "[280/600] Loss: 0.0039 MAE: 0.0045 Mean Error: 0.0015 STD: 0.0626\n",
      "[290/600] Loss: 0.0039 MAE: 0.0044 Mean Error: 0.0015 STD: 0.0625\n",
      "[300/600] Loss: 0.0039 MAE: 0.0044 Mean Error: 0.0015 STD: 0.0625\n",
      "[310/600] Loss: 0.0039 MAE: 0.0044 Mean Error: 0.0013 STD: 0.0623\n",
      "[320/600] Loss: 0.0038 MAE: 0.0043 Mean Error: 0.0014 STD: 0.0617\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[330/600] Loss: 0.0038 MAE: 0.0043 Mean Error: 0.0014 STD: 0.0617\n",
      "[340/600] Loss: 0.0038 MAE: 0.0042 Mean Error: 0.0014 STD: 0.0617\n",
      "[350/600] Loss: 0.0038 MAE: 0.0042 Mean Error: 0.0014 STD: 0.0617\n",
      "[360/600] Loss: 0.0038 MAE: 0.0042 Mean Error: 0.0014 STD: 0.0617\n",
      "[370/600] Loss: 0.0038 MAE: 0.0042 Mean Error: 0.0014 STD: 0.0617\n",
      "[380/600] Loss: 0.0037 MAE: 0.0042 Mean Error: 0.0013 STD: 0.0610\n",
      "[390/600] Loss: 0.0036 MAE: 0.0040 Mean Error: 0.0012 STD: 0.0601\n",
      "[400/600] Loss: 0.0036 MAE: 0.0041 Mean Error: 0.0012 STD: 0.0601\n",
      "[410/600] Loss: 0.0036 MAE: 0.0040 Mean Error: 0.0013 STD: 0.0601\n",
      "[420/600] Loss: 0.0036 MAE: 0.0040 Mean Error: 0.0013 STD: 0.0601\n",
      "[430/600] Loss: 0.0036 MAE: 0.0040 Mean Error: 0.0012 STD: 0.0601\n",
      "[440/600] Loss: 0.0036 MAE: 0.0039 Mean Error: 0.0013 STD: 0.0601\n",
      "[450/600] Loss: 0.0036 MAE: 0.0039 Mean Error: 0.0012 STD: 0.0600\n",
      "[460/600] Loss: 0.0035 MAE: 0.0038 Mean Error: 0.0012 STD: 0.0593\n",
      "[470/600] Loss: 0.0035 MAE: 0.0038 Mean Error: 0.0012 STD: 0.0593\n",
      "[480/600] Loss: 0.0035 MAE: 0.0038 Mean Error: 0.0012 STD: 0.0593\n",
      "[490/600] Loss: 0.0035 MAE: 0.0038 Mean Error: 0.0012 STD: 0.0593\n",
      "[500/600] Loss: 0.0035 MAE: 0.0038 Mean Error: 0.0012 STD: 0.0593\n",
      "[510/600] Loss: 0.0035 MAE: 0.0038 Mean Error: 0.0012 STD: 0.0593\n",
      "[520/600] Loss: 0.0035 MAE: 0.0038 Mean Error: 0.0012 STD: 0.0593\n",
      "[530/600] Loss: 0.0035 MAE: 0.0038 Mean Error: 0.0012 STD: 0.0593\n",
      "[540/600] Loss: 0.0035 MAE: 0.0038 Mean Error: 0.0012 STD: 0.0593\n",
      "[550/600] Loss: 0.0035 MAE: 0.0038 Mean Error: 0.0012 STD: 0.0593\n",
      "[560/600] Loss: 0.0035 MAE: 0.0038 Mean Error: 0.0012 STD: 0.0593\n",
      "[570/600] Loss: 0.0035 MAE: 0.0038 Mean Error: 0.0012 STD: 0.0593\n",
      "[580/600] Loss: 0.0035 MAE: 0.0038 Mean Error: 0.0012 STD: 0.0593\n",
      "[590/600] Loss: 0.0035 MAE: 0.0037 Mean Error: 0.0012 STD: 0.0593\n",
      "[599/600] Loss: 0.0035 MAE: 0.0037 Mean Error: 0.0012 STD: 0.0593\n",
      "------------------------------------\n",
      "Training dataset with noise standard deviation 0.03\n",
      "[0/600] Loss: 0.2502 MAE: 0.5001 Mean Error: 0.0947 STD: 0.4911\n",
      "[10/600] Loss: 0.1407 MAE: 0.2086 Mean Error: 0.0094 STD: 0.3750\n",
      "[20/600] Loss: 0.1253 MAE: 0.2449 Mean Error: 0.0025 STD: 0.3540\n",
      "[30/600] Loss: 0.1089 MAE: 0.2255 Mean Error: 0.0028 STD: 0.3301\n",
      "[40/600] Loss: 0.0901 MAE: 0.1816 Mean Error: 0.0021 STD: 0.3002\n",
      "[50/600] Loss: 0.0704 MAE: 0.1544 Mean Error: -0.0034 STD: 0.2653\n",
      "[60/600] Loss: 0.0395 MAE: 0.0897 Mean Error: -0.0016 STD: 0.1987\n",
      "[70/600] Loss: 0.0155 MAE: 0.0366 Mean Error: -0.0010 STD: 0.1243\n",
      "[80/600] Loss: 0.0076 MAE: 0.0147 Mean Error: -0.0001 STD: 0.0869\n",
      "[90/600] Loss: 0.0056 MAE: 0.0081 Mean Error: 0.0001 STD: 0.0750\n",
      "[100/600] Loss: 0.0052 MAE: 0.0065 Mean Error: 0.0002 STD: 0.0722\n",
      "[110/600] Loss: 0.0049 MAE: 0.0058 Mean Error: 0.0002 STD: 0.0701\n",
      "[120/600] Loss: 0.0048 MAE: 0.0055 Mean Error: 0.0001 STD: 0.0693\n",
      "[130/600] Loss: 0.0047 MAE: 0.0053 Mean Error: -0.0001 STD: 0.0686\n",
      "[140/600] Loss: 0.0047 MAE: 0.0052 Mean Error: -0.0000 STD: 0.0685\n",
      "[150/600] Loss: 0.0046 MAE: 0.0052 Mean Error: 0.0002 STD: 0.0678\n",
      "[160/600] Loss: 0.0046 MAE: 0.0050 Mean Error: 0.0001 STD: 0.0678\n",
      "[170/600] Loss: 0.0046 MAE: 0.0050 Mean Error: 0.0001 STD: 0.0678\n",
      "[180/600] Loss: 0.0046 MAE: 0.0049 Mean Error: 0.0001 STD: 0.0678\n",
      "[190/600] Loss: 0.0046 MAE: 0.0049 Mean Error: 0.0001 STD: 0.0678\n",
      "[200/600] Loss: 0.0046 MAE: 0.0049 Mean Error: 0.0001 STD: 0.0678\n",
      "[210/600] Loss: 0.0046 MAE: 0.0049 Mean Error: 0.0001 STD: 0.0678\n",
      "[220/600] Loss: 0.0046 MAE: 0.0049 Mean Error: 0.0001 STD: 0.0678\n",
      "[230/600] Loss: 0.0046 MAE: 0.0049 Mean Error: 0.0001 STD: 0.0678\n",
      "[240/600] Loss: 0.0046 MAE: 0.0049 Mean Error: 0.0001 STD: 0.0678\n",
      "[250/600] Loss: 0.0046 MAE: 0.0049 Mean Error: 0.0001 STD: 0.0678\n",
      "[260/600] Loss: 0.0046 MAE: 0.0049 Mean Error: 0.0001 STD: 0.0678\n",
      "[270/600] Loss: 0.0046 MAE: 0.0049 Mean Error: 0.0001 STD: 0.0678\n",
      "[280/600] Loss: 0.0046 MAE: 0.0049 Mean Error: 0.0001 STD: 0.0678\n",
      "[290/600] Loss: 0.0046 MAE: 0.0048 Mean Error: 0.0001 STD: 0.0678\n",
      "[300/600] Loss: 0.0046 MAE: 0.0048 Mean Error: 0.0001 STD: 0.0678\n",
      "[310/600] Loss: 0.0046 MAE: 0.0048 Mean Error: 0.0001 STD: 0.0678\n",
      "[320/600] Loss: 0.0046 MAE: 0.0048 Mean Error: 0.0001 STD: 0.0678\n",
      "[330/600] Loss: 0.0045 MAE: 0.0048 Mean Error: 0.0002 STD: 0.0670\n",
      "[340/600] Loss: 0.0045 MAE: 0.0048 Mean Error: 0.0002 STD: 0.0670\n",
      "[350/600] Loss: 0.0045 MAE: 0.0049 Mean Error: -0.0001 STD: 0.0672\n",
      "[360/600] Loss: 0.0044 MAE: 0.0047 Mean Error: 0.0001 STD: 0.0663\n",
      "[370/600] Loss: 0.0044 MAE: 0.0047 Mean Error: 0.0001 STD: 0.0663\n",
      "[380/600] Loss: 0.0044 MAE: 0.0047 Mean Error: 0.0001 STD: 0.0663\n",
      "[390/600] Loss: 0.0044 MAE: 0.0047 Mean Error: 0.0001 STD: 0.0663\n",
      "[400/600] Loss: 0.0044 MAE: 0.0046 Mean Error: 0.0001 STD: 0.0663\n",
      "[410/600] Loss: 0.0044 MAE: 0.0046 Mean Error: 0.0001 STD: 0.0663\n",
      "[420/600] Loss: 0.0044 MAE: 0.0046 Mean Error: 0.0001 STD: 0.0663\n",
      "[430/600] Loss: 0.0044 MAE: 0.0046 Mean Error: 0.0001 STD: 0.0663\n",
      "[440/600] Loss: 0.0044 MAE: 0.0046 Mean Error: 0.0001 STD: 0.0663\n",
      "[450/600] Loss: 0.0044 MAE: 0.0046 Mean Error: 0.0001 STD: 0.0663\n",
      "[460/600] Loss: 0.0044 MAE: 0.0046 Mean Error: 0.0001 STD: 0.0663\n",
      "[470/600] Loss: 0.0044 MAE: 0.0046 Mean Error: 0.0001 STD: 0.0663\n",
      "[480/600] Loss: 0.0044 MAE: 0.0046 Mean Error: 0.0001 STD: 0.0663\n",
      "[490/600] Loss: 0.0044 MAE: 0.0046 Mean Error: 0.0001 STD: 0.0663\n",
      "[500/600] Loss: 0.0044 MAE: 0.0046 Mean Error: 0.0001 STD: 0.0663\n",
      "[510/600] Loss: 0.0044 MAE: 0.0046 Mean Error: 0.0001 STD: 0.0663\n",
      "[520/600] Loss: 0.0044 MAE: 0.0046 Mean Error: 0.0001 STD: 0.0663\n",
      "[530/600] Loss: 0.0044 MAE: 0.0046 Mean Error: 0.0001 STD: 0.0663\n",
      "[540/600] Loss: 0.0044 MAE: 0.0046 Mean Error: 0.0001 STD: 0.0663\n",
      "[550/600] Loss: 0.0044 MAE: 0.0046 Mean Error: 0.0001 STD: 0.0663\n",
      "[560/600] Loss: 0.0044 MAE: 0.0046 Mean Error: 0.0001 STD: 0.0663\n",
      "[570/600] Loss: 0.0043 MAE: 0.0045 Mean Error: 0.0002 STD: 0.0656\n",
      "[580/600] Loss: 0.0042 MAE: 0.0045 Mean Error: 0.0001 STD: 0.0649\n",
      "[590/600] Loss: 0.0042 MAE: 0.0045 Mean Error: 0.0001 STD: 0.0648\n",
      "[599/600] Loss: 0.0041 MAE: 0.0044 Mean Error: 0.0002 STD: 0.0641\n",
      "------------------------------------\n",
      "Training dataset with noise standard deviation 0.05\n",
      "[0/600] Loss: 0.2498 MAE: 0.4998 Mean Error: 0.0937 STD: 0.4910\n",
      "[10/600] Loss: 0.1396 MAE: 0.2102 Mean Error: 0.0106 STD: 0.3735\n",
      "[20/600] Loss: 0.1239 MAE: 0.2474 Mean Error: 0.0048 STD: 0.3520\n",
      "[30/600] Loss: 0.1035 MAE: 0.2131 Mean Error: 0.0014 STD: 0.3217\n",
      "[40/600] Loss: 0.0858 MAE: 0.1768 Mean Error: -0.0004 STD: 0.2929\n",
      "[50/600] Loss: 0.0704 MAE: 0.1486 Mean Error: -0.0071 STD: 0.2653\n",
      "[60/600] Loss: 0.0474 MAE: 0.1062 Mean Error: 0.0003 STD: 0.2177\n",
      "[70/600] Loss: 0.0274 MAE: 0.0632 Mean Error: -0.0012 STD: 0.1654\n",
      "[80/600] Loss: 0.0143 MAE: 0.0345 Mean Error: 0.0006 STD: 0.1195\n",
      "[90/600] Loss: 0.0065 MAE: 0.0144 Mean Error: 0.0009 STD: 0.0809\n",
      "[100/600] Loss: 0.0054 MAE: 0.0082 Mean Error: 0.0010 STD: 0.0734\n",
      "[110/600] Loss: 0.0048 MAE: 0.0065 Mean Error: 0.0013 STD: 0.0692\n",
      "[120/600] Loss: 0.0046 MAE: 0.0058 Mean Error: 0.0012 STD: 0.0680\n",
      "[130/600] Loss: 0.0046 MAE: 0.0055 Mean Error: 0.0013 STD: 0.0678\n",
      "[140/600] Loss: 0.0046 MAE: 0.0053 Mean Error: 0.0012 STD: 0.0678\n",
      "[150/600] Loss: 0.0046 MAE: 0.0053 Mean Error: 0.0013 STD: 0.0678\n",
      "[160/600] Loss: 0.0046 MAE: 0.0052 Mean Error: 0.0013 STD: 0.0678\n",
      "[170/600] Loss: 0.0046 MAE: 0.0052 Mean Error: 0.0013 STD: 0.0678\n",
      "[180/600] Loss: 0.0045 MAE: 0.0052 Mean Error: 0.0013 STD: 0.0673\n",
      "[190/600] Loss: 0.0044 MAE: 0.0050 Mean Error: 0.0012 STD: 0.0664\n",
      "[200/600] Loss: 0.0044 MAE: 0.0050 Mean Error: 0.0012 STD: 0.0663\n",
      "[210/600] Loss: 0.0043 MAE: 0.0049 Mean Error: 0.0011 STD: 0.0656\n",
      "[220/600] Loss: 0.0043 MAE: 0.0049 Mean Error: 0.0012 STD: 0.0656\n",
      "[230/600] Loss: 0.0043 MAE: 0.0048 Mean Error: 0.0012 STD: 0.0656\n",
      "[240/600] Loss: 0.0043 MAE: 0.0048 Mean Error: 0.0012 STD: 0.0656\n",
      "[250/600] Loss: 0.0043 MAE: 0.0048 Mean Error: 0.0012 STD: 0.0656\n",
      "[260/600] Loss: 0.0042 MAE: 0.0047 Mean Error: 0.0013 STD: 0.0649\n",
      "[270/600] Loss: 0.0042 MAE: 0.0046 Mean Error: 0.0013 STD: 0.0648\n",
      "[280/600] Loss: 0.0042 MAE: 0.0046 Mean Error: 0.0013 STD: 0.0648\n",
      "[290/600] Loss: 0.0042 MAE: 0.0046 Mean Error: 0.0013 STD: 0.0648\n",
      "[300/600] Loss: 0.0042 MAE: 0.0046 Mean Error: 0.0013 STD: 0.0648\n",
      "[310/600] Loss: 0.0042 MAE: 0.0046 Mean Error: 0.0013 STD: 0.0648\n",
      "[320/600] Loss: 0.0042 MAE: 0.0046 Mean Error: 0.0013 STD: 0.0648\n",
      "[330/600] Loss: 0.0042 MAE: 0.0046 Mean Error: 0.0013 STD: 0.0648\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[340/600] Loss: 0.0042 MAE: 0.0046 Mean Error: 0.0013 STD: 0.0648\n",
      "[350/600] Loss: 0.0042 MAE: 0.0046 Mean Error: 0.0013 STD: 0.0648\n",
      "[360/600] Loss: 0.0042 MAE: 0.0046 Mean Error: 0.0013 STD: 0.0648\n",
      "[370/600] Loss: 0.0042 MAE: 0.0045 Mean Error: 0.0013 STD: 0.0648\n",
      "[380/600] Loss: 0.0042 MAE: 0.0045 Mean Error: 0.0013 STD: 0.0648\n",
      "[390/600] Loss: 0.0042 MAE: 0.0045 Mean Error: 0.0013 STD: 0.0648\n",
      "[400/600] Loss: 0.0042 MAE: 0.0045 Mean Error: 0.0013 STD: 0.0648\n",
      "[410/600] Loss: 0.0042 MAE: 0.0045 Mean Error: 0.0013 STD: 0.0648\n",
      "[420/600] Loss: 0.0042 MAE: 0.0045 Mean Error: 0.0013 STD: 0.0648\n",
      "[430/600] Loss: 0.0042 MAE: 0.0045 Mean Error: 0.0013 STD: 0.0648\n",
      "[440/600] Loss: 0.0041 MAE: 0.0045 Mean Error: 0.0014 STD: 0.0641\n",
      "[450/600] Loss: 0.0040 MAE: 0.0044 Mean Error: 0.0012 STD: 0.0633\n",
      "[460/600] Loss: 0.0040 MAE: 0.0044 Mean Error: 0.0013 STD: 0.0633\n",
      "[470/600] Loss: 0.0040 MAE: 0.0044 Mean Error: 0.0012 STD: 0.0633\n",
      "[480/600] Loss: 0.0040 MAE: 0.0043 Mean Error: 0.0013 STD: 0.0633\n",
      "[490/600] Loss: 0.0040 MAE: 0.0043 Mean Error: 0.0013 STD: 0.0633\n",
      "[500/600] Loss: 0.0040 MAE: 0.0043 Mean Error: 0.0013 STD: 0.0633\n",
      "[510/600] Loss: 0.0040 MAE: 0.0043 Mean Error: 0.0013 STD: 0.0633\n",
      "[520/600] Loss: 0.0040 MAE: 0.0043 Mean Error: 0.0013 STD: 0.0633\n",
      "[530/600] Loss: 0.0040 MAE: 0.0043 Mean Error: 0.0013 STD: 0.0633\n",
      "[540/600] Loss: 0.0040 MAE: 0.0043 Mean Error: 0.0013 STD: 0.0633\n",
      "[550/600] Loss: 0.0040 MAE: 0.0043 Mean Error: 0.0013 STD: 0.0633\n",
      "[560/600] Loss: 0.0040 MAE: 0.0043 Mean Error: 0.0013 STD: 0.0633\n",
      "[570/600] Loss: 0.0040 MAE: 0.0043 Mean Error: 0.0013 STD: 0.0633\n",
      "[580/600] Loss: 0.0040 MAE: 0.0043 Mean Error: 0.0013 STD: 0.0633\n",
      "[590/600] Loss: 0.0040 MAE: 0.0043 Mean Error: 0.0013 STD: 0.0633\n",
      "[599/600] Loss: 0.0040 MAE: 0.0043 Mean Error: 0.0013 STD: 0.0633\n",
      "------------------------------------\n",
      "Training dataset with noise standard deviation 0.1\n",
      "[0/600] Loss: 0.2497 MAE: 0.4997 Mean Error: 0.0943 STD: 0.4908\n",
      "[10/600] Loss: 0.1394 MAE: 0.2105 Mean Error: 0.0067 STD: 0.3733\n",
      "[20/600] Loss: 0.1242 MAE: 0.2514 Mean Error: 0.0047 STD: 0.3524\n",
      "[30/600] Loss: 0.1046 MAE: 0.2196 Mean Error: 0.0006 STD: 0.3235\n",
      "[40/600] Loss: 0.0862 MAE: 0.1791 Mean Error: -0.0016 STD: 0.2937\n",
      "[50/600] Loss: 0.0709 MAE: 0.1521 Mean Error: 0.0003 STD: 0.2664\n",
      "[60/600] Loss: 0.0433 MAE: 0.1037 Mean Error: -0.0028 STD: 0.2080\n",
      "[70/600] Loss: 0.0166 MAE: 0.0402 Mean Error: 0.0012 STD: 0.1288\n",
      "[80/600] Loss: 0.0085 MAE: 0.0162 Mean Error: -0.0005 STD: 0.0923\n",
      "[90/600] Loss: 0.0070 MAE: 0.0101 Mean Error: 0.0004 STD: 0.0837\n",
      "[100/600] Loss: 0.0066 MAE: 0.0082 Mean Error: 0.0001 STD: 0.0813\n",
      "[110/600] Loss: 0.0063 MAE: 0.0075 Mean Error: 0.0004 STD: 0.0795\n",
      "[120/600] Loss: 0.0062 MAE: 0.0071 Mean Error: 0.0002 STD: 0.0790\n",
      "[130/600] Loss: 0.0062 MAE: 0.0069 Mean Error: 0.0003 STD: 0.0785\n",
      "[140/600] Loss: 0.0062 MAE: 0.0068 Mean Error: 0.0003 STD: 0.0785\n",
      "[150/600] Loss: 0.0061 MAE: 0.0067 Mean Error: 0.0004 STD: 0.0779\n",
      "[160/600] Loss: 0.0060 MAE: 0.0066 Mean Error: 0.0005 STD: 0.0772\n",
      "[170/600] Loss: 0.0058 MAE: 0.0064 Mean Error: 0.0002 STD: 0.0762\n",
      "[180/600] Loss: 0.0058 MAE: 0.0063 Mean Error: 0.0003 STD: 0.0759\n",
      "[190/600] Loss: 0.0058 MAE: 0.0063 Mean Error: 0.0003 STD: 0.0759\n",
      "[200/600] Loss: 0.0057 MAE: 0.0063 Mean Error: 0.0004 STD: 0.0754\n",
      "[210/600] Loss: 0.0056 MAE: 0.0061 Mean Error: 0.0003 STD: 0.0747\n",
      "[220/600] Loss: 0.0056 MAE: 0.0061 Mean Error: 0.0003 STD: 0.0746\n",
      "[230/600] Loss: 0.0056 MAE: 0.0060 Mean Error: 0.0003 STD: 0.0746\n",
      "[240/600] Loss: 0.0056 MAE: 0.0060 Mean Error: 0.0003 STD: 0.0746\n",
      "[250/600] Loss: 0.0056 MAE: 0.0060 Mean Error: 0.0003 STD: 0.0746\n",
      "[260/600] Loss: 0.0056 MAE: 0.0060 Mean Error: 0.0003 STD: 0.0746\n",
      "[270/600] Loss: 0.0056 MAE: 0.0059 Mean Error: 0.0003 STD: 0.0746\n",
      "[280/600] Loss: 0.0056 MAE: 0.0059 Mean Error: 0.0003 STD: 0.0746\n",
      "[290/600] Loss: 0.0056 MAE: 0.0059 Mean Error: 0.0003 STD: 0.0746\n",
      "[300/600] Loss: 0.0055 MAE: 0.0060 Mean Error: 0.0001 STD: 0.0745\n",
      "[310/600] Loss: 0.0055 MAE: 0.0059 Mean Error: -0.0001 STD: 0.0739\n",
      "[320/600] Loss: 0.0054 MAE: 0.0059 Mean Error: 0.0001 STD: 0.0733\n",
      "[330/600] Loss: 0.0054 MAE: 0.0058 Mean Error: 0.0001 STD: 0.0733\n",
      "[340/600] Loss: 0.0053 MAE: 0.0057 Mean Error: 0.0000 STD: 0.0728\n",
      "[350/600] Loss: 0.0053 MAE: 0.0057 Mean Error: -0.0000 STD: 0.0726\n",
      "[360/600] Loss: 0.0053 MAE: 0.0056 Mean Error: 0.0000 STD: 0.0726\n",
      "[370/600] Loss: 0.0053 MAE: 0.0056 Mean Error: -0.0000 STD: 0.0726\n",
      "[380/600] Loss: 0.0053 MAE: 0.0056 Mean Error: -0.0000 STD: 0.0726\n",
      "[390/600] Loss: 0.0053 MAE: 0.0056 Mean Error: -0.0000 STD: 0.0726\n",
      "[400/600] Loss: 0.0053 MAE: 0.0056 Mean Error: -0.0000 STD: 0.0726\n",
      "[410/600] Loss: 0.0053 MAE: 0.0055 Mean Error: -0.0000 STD: 0.0726\n",
      "[420/600] Loss: 0.0053 MAE: 0.0055 Mean Error: -0.0000 STD: 0.0726\n",
      "[430/600] Loss: 0.0053 MAE: 0.0055 Mean Error: -0.0000 STD: 0.0726\n",
      "[440/600] Loss: 0.0053 MAE: 0.0055 Mean Error: -0.0000 STD: 0.0726\n",
      "[450/600] Loss: 0.0053 MAE: 0.0055 Mean Error: -0.0000 STD: 0.0726\n",
      "[460/600] Loss: 0.0053 MAE: 0.0055 Mean Error: 0.0000 STD: 0.0726\n",
      "[470/600] Loss: 0.0052 MAE: 0.0055 Mean Error: 0.0002 STD: 0.0720\n",
      "[480/600] Loss: 0.0052 MAE: 0.0055 Mean Error: 0.0001 STD: 0.0720\n",
      "[490/600] Loss: 0.0052 MAE: 0.0054 Mean Error: 0.0001 STD: 0.0720\n",
      "[500/600] Loss: 0.0052 MAE: 0.0054 Mean Error: 0.0001 STD: 0.0720\n",
      "[510/600] Loss: 0.0052 MAE: 0.0054 Mean Error: 0.0001 STD: 0.0719\n",
      "[520/600] Loss: 0.0051 MAE: 0.0053 Mean Error: 0.0002 STD: 0.0713\n",
      "[530/600] Loss: 0.0051 MAE: 0.0053 Mean Error: 0.0002 STD: 0.0713\n",
      "[540/600] Loss: 0.0051 MAE: 0.0053 Mean Error: 0.0002 STD: 0.0713\n",
      "[550/600] Loss: 0.0051 MAE: 0.0053 Mean Error: 0.0002 STD: 0.0713\n",
      "[560/600] Loss: 0.0051 MAE: 0.0053 Mean Error: 0.0002 STD: 0.0713\n",
      "[570/600] Loss: 0.0051 MAE: 0.0053 Mean Error: 0.0002 STD: 0.0713\n",
      "[580/600] Loss: 0.0051 MAE: 0.0053 Mean Error: 0.0002 STD: 0.0713\n",
      "[590/600] Loss: 0.0051 MAE: 0.0053 Mean Error: 0.0002 STD: 0.0713\n",
      "[599/600] Loss: 0.0051 MAE: 0.0053 Mean Error: 0.0002 STD: 0.0713\n",
      "------------------------------------\n",
      "Training dataset with noise standard deviation 0.001\n",
      "[0/600] Loss: 0.2499 MAE: 0.4998 Mean Error: 0.0939 STD: 0.4910\n",
      "[10/600] Loss: 0.1400 MAE: 0.2099 Mean Error: 0.0128 STD: 0.3740\n",
      "[20/600] Loss: 0.1242 MAE: 0.2480 Mean Error: 0.0047 STD: 0.3524\n",
      "[30/600] Loss: 0.1052 MAE: 0.2181 Mean Error: -0.0017 STD: 0.3243\n",
      "[40/600] Loss: 0.0878 MAE: 0.1829 Mean Error: -0.0035 STD: 0.2964\n",
      "[50/600] Loss: 0.0654 MAE: 0.1450 Mean Error: -0.0033 STD: 0.2558\n",
      "[60/600] Loss: 0.0379 MAE: 0.0840 Mean Error: -0.0038 STD: 0.1946\n",
      "[70/600] Loss: 0.0183 MAE: 0.0410 Mean Error: -0.0012 STD: 0.1354\n",
      "[80/600] Loss: 0.0105 MAE: 0.0197 Mean Error: -0.0007 STD: 0.1023\n",
      "[90/600] Loss: 0.0078 MAE: 0.0118 Mean Error: -0.0008 STD: 0.0883\n",
      "[100/600] Loss: 0.0070 MAE: 0.0090 Mean Error: -0.0004 STD: 0.0838\n",
      "[110/600] Loss: 0.0068 MAE: 0.0080 Mean Error: -0.0004 STD: 0.0822\n",
      "[120/600] Loss: 0.0067 MAE: 0.0075 Mean Error: -0.0003 STD: 0.0816\n",
      "[130/600] Loss: 0.0065 MAE: 0.0072 Mean Error: -0.0002 STD: 0.0805\n",
      "[140/600] Loss: 0.0064 MAE: 0.0072 Mean Error: -0.0002 STD: 0.0803\n",
      "[150/600] Loss: 0.0062 MAE: 0.0070 Mean Error: -0.0000 STD: 0.0788\n",
      "[160/600] Loss: 0.0062 MAE: 0.0068 Mean Error: 0.0001 STD: 0.0785\n",
      "[170/600] Loss: 0.0062 MAE: 0.0067 Mean Error: 0.0001 STD: 0.0785\n",
      "[180/600] Loss: 0.0062 MAE: 0.0067 Mean Error: 0.0001 STD: 0.0785\n",
      "[190/600] Loss: 0.0061 MAE: 0.0066 Mean Error: 0.0002 STD: 0.0779\n",
      "[200/600] Loss: 0.0061 MAE: 0.0065 Mean Error: 0.0002 STD: 0.0778\n",
      "[210/600] Loss: 0.0061 MAE: 0.0065 Mean Error: 0.0002 STD: 0.0778\n",
      "[220/600] Loss: 0.0061 MAE: 0.0065 Mean Error: 0.0002 STD: 0.0778\n",
      "[230/600] Loss: 0.0061 MAE: 0.0065 Mean Error: 0.0002 STD: 0.0778\n",
      "[240/600] Loss: 0.0060 MAE: 0.0065 Mean Error: 0.0002 STD: 0.0777\n",
      "[250/600] Loss: 0.0060 MAE: 0.0064 Mean Error: 0.0001 STD: 0.0772\n",
      "[260/600] Loss: 0.0059 MAE: 0.0064 Mean Error: 0.0002 STD: 0.0766\n",
      "[270/600] Loss: 0.0059 MAE: 0.0063 Mean Error: 0.0002 STD: 0.0766\n",
      "[280/600] Loss: 0.0059 MAE: 0.0063 Mean Error: 0.0004 STD: 0.0765\n",
      "[290/600] Loss: 0.0059 MAE: 0.0063 Mean Error: 0.0002 STD: 0.0766\n",
      "[300/600] Loss: 0.0058 MAE: 0.0062 Mean Error: 0.0003 STD: 0.0759\n",
      "[310/600] Loss: 0.0058 MAE: 0.0062 Mean Error: 0.0003 STD: 0.0759\n",
      "[320/600] Loss: 0.0058 MAE: 0.0061 Mean Error: 0.0003 STD: 0.0759\n",
      "[330/600] Loss: 0.0057 MAE: 0.0061 Mean Error: 0.0002 STD: 0.0754\n",
      "[340/600] Loss: 0.0057 MAE: 0.0061 Mean Error: 0.0004 STD: 0.0753\n",
      "[350/600] Loss: 0.0057 MAE: 0.0060 Mean Error: 0.0004 STD: 0.0753\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[360/600] Loss: 0.0057 MAE: 0.0060 Mean Error: 0.0004 STD: 0.0753\n",
      "[370/600] Loss: 0.0055 MAE: 0.0059 Mean Error: 0.0005 STD: 0.0742\n",
      "[380/600] Loss: 0.0055 MAE: 0.0058 Mean Error: 0.0004 STD: 0.0740\n",
      "[390/600] Loss: 0.0055 MAE: 0.0059 Mean Error: 0.0004 STD: 0.0740\n",
      "[400/600] Loss: 0.0055 MAE: 0.0058 Mean Error: 0.0004 STD: 0.0740\n",
      "[410/600] Loss: 0.0055 MAE: 0.0058 Mean Error: 0.0004 STD: 0.0740\n",
      "[420/600] Loss: 0.0055 MAE: 0.0058 Mean Error: 0.0004 STD: 0.0740\n",
      "[430/600] Loss: 0.0055 MAE: 0.0058 Mean Error: 0.0006 STD: 0.0738\n",
      "[440/600] Loss: 0.0054 MAE: 0.0057 Mean Error: 0.0005 STD: 0.0733\n",
      "[450/600] Loss: 0.0054 MAE: 0.0057 Mean Error: 0.0005 STD: 0.0733\n",
      "[460/600] Loss: 0.0054 MAE: 0.0056 Mean Error: 0.0005 STD: 0.0733\n",
      "[470/600] Loss: 0.0054 MAE: 0.0056 Mean Error: 0.0005 STD: 0.0733\n",
      "[480/600] Loss: 0.0054 MAE: 0.0056 Mean Error: 0.0005 STD: 0.0733\n",
      "[490/600] Loss: 0.0054 MAE: 0.0056 Mean Error: 0.0005 STD: 0.0733\n",
      "[500/600] Loss: 0.0054 MAE: 0.0056 Mean Error: 0.0005 STD: 0.0733\n",
      "[510/600] Loss: 0.0054 MAE: 0.0056 Mean Error: 0.0005 STD: 0.0733\n",
      "[520/600] Loss: 0.0054 MAE: 0.0056 Mean Error: 0.0005 STD: 0.0733\n",
      "[530/600] Loss: 0.0054 MAE: 0.0056 Mean Error: 0.0005 STD: 0.0733\n",
      "[540/600] Loss: 0.0054 MAE: 0.0056 Mean Error: 0.0005 STD: 0.0733\n",
      "[550/600] Loss: 0.0054 MAE: 0.0056 Mean Error: 0.0005 STD: 0.0733\n",
      "[560/600] Loss: 0.0054 MAE: 0.0056 Mean Error: 0.0005 STD: 0.0733\n",
      "[570/600] Loss: 0.0054 MAE: 0.0056 Mean Error: 0.0005 STD: 0.0733\n",
      "[580/600] Loss: 0.0054 MAE: 0.0056 Mean Error: 0.0005 STD: 0.0733\n",
      "[590/600] Loss: 0.0054 MAE: 0.0056 Mean Error: 0.0005 STD: 0.0733\n",
      "[599/600] Loss: 0.0054 MAE: 0.0056 Mean Error: 0.0005 STD: 0.0733\n",
      "------------------------------------\n",
      "Training dataset with noise standard deviation 0.002\n",
      "[0/600] Loss: 0.2502 MAE: 0.5001 Mean Error: 0.0938 STD: 0.4913\n",
      "[10/600] Loss: 0.1388 MAE: 0.2114 Mean Error: 0.0087 STD: 0.3724\n",
      "[20/600] Loss: 0.1227 MAE: 0.2514 Mean Error: 0.0024 STD: 0.3503\n",
      "[30/600] Loss: 0.1017 MAE: 0.2074 Mean Error: 0.0013 STD: 0.3189\n",
      "[40/600] Loss: 0.0821 MAE: 0.1754 Mean Error: -0.0020 STD: 0.2866\n",
      "[50/600] Loss: 0.0496 MAE: 0.1093 Mean Error: -0.0018 STD: 0.2227\n",
      "[60/600] Loss: 0.0243 MAE: 0.0524 Mean Error: -0.0016 STD: 0.1558\n",
      "[70/600] Loss: 0.0133 MAE: 0.0252 Mean Error: -0.0013 STD: 0.1152\n",
      "[80/600] Loss: 0.0096 MAE: 0.0149 Mean Error: -0.0010 STD: 0.0982\n",
      "[90/600] Loss: 0.0085 MAE: 0.0110 Mean Error: -0.0012 STD: 0.0923\n",
      "[100/600] Loss: 0.0082 MAE: 0.0096 Mean Error: -0.0009 STD: 0.0905\n",
      "[110/600] Loss: 0.0081 MAE: 0.0091 Mean Error: -0.0009 STD: 0.0901\n",
      "[120/600] Loss: 0.0080 MAE: 0.0088 Mean Error: -0.0008 STD: 0.0896\n",
      "[130/600] Loss: 0.0080 MAE: 0.0087 Mean Error: -0.0008 STD: 0.0895\n",
      "[140/600] Loss: 0.0080 MAE: 0.0086 Mean Error: -0.0008 STD: 0.0895\n",
      "[150/600] Loss: 0.0080 MAE: 0.0086 Mean Error: -0.0008 STD: 0.0895\n",
      "[160/600] Loss: 0.0080 MAE: 0.0085 Mean Error: -0.0008 STD: 0.0895\n",
      "[170/600] Loss: 0.0080 MAE: 0.0085 Mean Error: -0.0008 STD: 0.0895\n",
      "[180/600] Loss: 0.0079 MAE: 0.0085 Mean Error: -0.0007 STD: 0.0890\n",
      "[190/600] Loss: 0.0078 MAE: 0.0084 Mean Error: -0.0005 STD: 0.0884\n",
      "[200/600] Loss: 0.0078 MAE: 0.0083 Mean Error: -0.0006 STD: 0.0884\n",
      "[210/600] Loss: 0.0078 MAE: 0.0083 Mean Error: -0.0006 STD: 0.0884\n",
      "[220/600] Loss: 0.0078 MAE: 0.0082 Mean Error: -0.0006 STD: 0.0884\n",
      "[230/600] Loss: 0.0078 MAE: 0.0082 Mean Error: -0.0006 STD: 0.0884\n",
      "[240/600] Loss: 0.0078 MAE: 0.0082 Mean Error: -0.0006 STD: 0.0884\n",
      "[250/600] Loss: 0.0078 MAE: 0.0082 Mean Error: -0.0006 STD: 0.0884\n",
      "[260/600] Loss: 0.0077 MAE: 0.0081 Mean Error: -0.0007 STD: 0.0878\n",
      "[270/600] Loss: 0.0077 MAE: 0.0081 Mean Error: -0.0007 STD: 0.0878\n",
      "[280/600] Loss: 0.0077 MAE: 0.0080 Mean Error: -0.0007 STD: 0.0878\n",
      "[290/600] Loss: 0.0077 MAE: 0.0080 Mean Error: -0.0007 STD: 0.0878\n",
      "[300/600] Loss: 0.0077 MAE: 0.0080 Mean Error: -0.0007 STD: 0.0878\n",
      "[310/600] Loss: 0.0077 MAE: 0.0080 Mean Error: -0.0007 STD: 0.0878\n",
      "[320/600] Loss: 0.0077 MAE: 0.0080 Mean Error: -0.0007 STD: 0.0878\n",
      "[330/600] Loss: 0.0077 MAE: 0.0080 Mean Error: -0.0007 STD: 0.0878\n",
      "[340/600] Loss: 0.0077 MAE: 0.0080 Mean Error: -0.0007 STD: 0.0878\n",
      "[350/600] Loss: 0.0077 MAE: 0.0080 Mean Error: -0.0007 STD: 0.0878\n",
      "[360/600] Loss: 0.0077 MAE: 0.0080 Mean Error: -0.0007 STD: 0.0878\n",
      "[370/600] Loss: 0.0077 MAE: 0.0080 Mean Error: -0.0007 STD: 0.0878\n",
      "[380/600] Loss: 0.0077 MAE: 0.0080 Mean Error: -0.0007 STD: 0.0878\n",
      "[390/600] Loss: 0.0077 MAE: 0.0080 Mean Error: -0.0007 STD: 0.0878\n",
      "[400/600] Loss: 0.0077 MAE: 0.0080 Mean Error: -0.0007 STD: 0.0878\n",
      "[410/600] Loss: 0.0077 MAE: 0.0080 Mean Error: -0.0007 STD: 0.0878\n",
      "[420/600] Loss: 0.0077 MAE: 0.0080 Mean Error: -0.0007 STD: 0.0878\n",
      "[430/600] Loss: 0.0077 MAE: 0.0080 Mean Error: -0.0007 STD: 0.0878\n",
      "[440/600] Loss: 0.0077 MAE: 0.0079 Mean Error: -0.0007 STD: 0.0878\n",
      "[450/600] Loss: 0.0077 MAE: 0.0080 Mean Error: -0.0006 STD: 0.0876\n",
      "[460/600] Loss: 0.0076 MAE: 0.0079 Mean Error: -0.0006 STD: 0.0873\n",
      "[470/600] Loss: 0.0075 MAE: 0.0079 Mean Error: -0.0005 STD: 0.0868\n",
      "[480/600] Loss: 0.0075 MAE: 0.0079 Mean Error: -0.0005 STD: 0.0867\n",
      "[490/600] Loss: 0.0075 MAE: 0.0078 Mean Error: -0.0005 STD: 0.0867\n",
      "[500/600] Loss: 0.0075 MAE: 0.0078 Mean Error: -0.0005 STD: 0.0867\n",
      "[510/600] Loss: 0.0075 MAE: 0.0078 Mean Error: -0.0005 STD: 0.0867\n",
      "[520/600] Loss: 0.0075 MAE: 0.0077 Mean Error: -0.0005 STD: 0.0867\n",
      "[530/600] Loss: 0.0075 MAE: 0.0077 Mean Error: -0.0005 STD: 0.0867\n",
      "[540/600] Loss: 0.0075 MAE: 0.0077 Mean Error: -0.0005 STD: 0.0867\n",
      "[550/600] Loss: 0.0075 MAE: 0.0077 Mean Error: -0.0005 STD: 0.0867\n",
      "[560/600] Loss: 0.0075 MAE: 0.0077 Mean Error: -0.0005 STD: 0.0867\n",
      "[570/600] Loss: 0.0075 MAE: 0.0077 Mean Error: -0.0005 STD: 0.0867\n",
      "[580/600] Loss: 0.0075 MAE: 0.0077 Mean Error: -0.0005 STD: 0.0867\n",
      "[590/600] Loss: 0.0075 MAE: 0.0077 Mean Error: -0.0005 STD: 0.0867\n",
      "[599/600] Loss: 0.0075 MAE: 0.0077 Mean Error: -0.0005 STD: 0.0867\n",
      "------------------------------------\n",
      "Training dataset with noise standard deviation 0.003\n",
      "[0/600] Loss: 0.2501 MAE: 0.5000 Mean Error: 0.0945 STD: 0.4911\n",
      "[10/600] Loss: 0.1413 MAE: 0.2064 Mean Error: 0.0131 STD: 0.3757\n",
      "[20/600] Loss: 0.1262 MAE: 0.2409 Mean Error: 0.0026 STD: 0.3552\n",
      "[30/600] Loss: 0.1111 MAE: 0.2295 Mean Error: 0.0053 STD: 0.3334\n",
      "[40/600] Loss: 0.0892 MAE: 0.1765 Mean Error: -0.0001 STD: 0.2987\n",
      "[50/600] Loss: 0.0710 MAE: 0.1526 Mean Error: -0.0025 STD: 0.2665\n",
      "[60/600] Loss: 0.0452 MAE: 0.1019 Mean Error: -0.0016 STD: 0.2126\n",
      "[70/600] Loss: 0.0254 MAE: 0.0579 Mean Error: -0.0003 STD: 0.1595\n",
      "[80/600] Loss: 0.0114 MAE: 0.0274 Mean Error: -0.0006 STD: 0.1066\n",
      "[90/600] Loss: 0.0055 MAE: 0.0106 Mean Error: 0.0005 STD: 0.0743\n",
      "[100/600] Loss: 0.0047 MAE: 0.0067 Mean Error: 0.0006 STD: 0.0687\n",
      "[110/600] Loss: 0.0045 MAE: 0.0055 Mean Error: 0.0007 STD: 0.0672\n",
      "[120/600] Loss: 0.0045 MAE: 0.0052 Mean Error: 0.0008 STD: 0.0671\n",
      "[130/600] Loss: 0.0045 MAE: 0.0051 Mean Error: 0.0007 STD: 0.0671\n",
      "[140/600] Loss: 0.0045 MAE: 0.0050 Mean Error: 0.0007 STD: 0.0670\n",
      "[150/600] Loss: 0.0045 MAE: 0.0050 Mean Error: 0.0008 STD: 0.0670\n",
      "[160/600] Loss: 0.0045 MAE: 0.0049 Mean Error: 0.0007 STD: 0.0670\n",
      "[170/600] Loss: 0.0045 MAE: 0.0049 Mean Error: 0.0008 STD: 0.0670\n",
      "[180/600] Loss: 0.0045 MAE: 0.0049 Mean Error: 0.0008 STD: 0.0670\n",
      "[190/600] Loss: 0.0045 MAE: 0.0049 Mean Error: 0.0007 STD: 0.0670\n",
      "[200/600] Loss: 0.0044 MAE: 0.0049 Mean Error: 0.0006 STD: 0.0663\n",
      "[210/600] Loss: 0.0043 MAE: 0.0048 Mean Error: 0.0005 STD: 0.0656\n",
      "[220/600] Loss: 0.0043 MAE: 0.0047 Mean Error: 0.0006 STD: 0.0656\n",
      "[230/600] Loss: 0.0043 MAE: 0.0047 Mean Error: 0.0006 STD: 0.0656\n",
      "[240/600] Loss: 0.0042 MAE: 0.0046 Mean Error: 0.0006 STD: 0.0647\n",
      "[250/600] Loss: 0.0041 MAE: 0.0045 Mean Error: 0.0006 STD: 0.0641\n",
      "[260/600] Loss: 0.0041 MAE: 0.0045 Mean Error: 0.0006 STD: 0.0641\n",
      "[270/600] Loss: 0.0041 MAE: 0.0045 Mean Error: 0.0006 STD: 0.0640\n",
      "[280/600] Loss: 0.0040 MAE: 0.0044 Mean Error: 0.0007 STD: 0.0633\n",
      "[290/600] Loss: 0.0040 MAE: 0.0044 Mean Error: 0.0007 STD: 0.0633\n",
      "[300/600] Loss: 0.0040 MAE: 0.0044 Mean Error: 0.0007 STD: 0.0633\n",
      "[310/600] Loss: 0.0040 MAE: 0.0043 Mean Error: 0.0007 STD: 0.0633\n",
      "[320/600] Loss: 0.0040 MAE: 0.0043 Mean Error: 0.0007 STD: 0.0633\n",
      "[330/600] Loss: 0.0040 MAE: 0.0043 Mean Error: 0.0007 STD: 0.0633\n",
      "[340/600] Loss: 0.0040 MAE: 0.0043 Mean Error: 0.0007 STD: 0.0633\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[350/600] Loss: 0.0040 MAE: 0.0043 Mean Error: 0.0007 STD: 0.0633\n",
      "[360/600] Loss: 0.0040 MAE: 0.0043 Mean Error: 0.0007 STD: 0.0633\n",
      "[370/600] Loss: 0.0040 MAE: 0.0043 Mean Error: 0.0007 STD: 0.0633\n",
      "[380/600] Loss: 0.0040 MAE: 0.0043 Mean Error: 0.0007 STD: 0.0633\n",
      "[390/600] Loss: 0.0040 MAE: 0.0043 Mean Error: 0.0007 STD: 0.0633\n",
      "[400/600] Loss: 0.0040 MAE: 0.0043 Mean Error: 0.0007 STD: 0.0633\n",
      "[410/600] Loss: 0.0040 MAE: 0.0043 Mean Error: 0.0007 STD: 0.0633\n",
      "[420/600] Loss: 0.0039 MAE: 0.0042 Mean Error: 0.0005 STD: 0.0625\n",
      "[430/600] Loss: 0.0039 MAE: 0.0042 Mean Error: 0.0006 STD: 0.0625\n",
      "[440/600] Loss: 0.0039 MAE: 0.0042 Mean Error: 0.0006 STD: 0.0625\n",
      "[450/600] Loss: 0.0039 MAE: 0.0042 Mean Error: 0.0006 STD: 0.0625\n",
      "[460/600] Loss: 0.0039 MAE: 0.0042 Mean Error: 0.0006 STD: 0.0625\n",
      "[470/600] Loss: 0.0038 MAE: 0.0041 Mean Error: 0.0006 STD: 0.0617\n",
      "[480/600] Loss: 0.0038 MAE: 0.0041 Mean Error: 0.0007 STD: 0.0617\n",
      "[490/600] Loss: 0.0038 MAE: 0.0041 Mean Error: 0.0007 STD: 0.0617\n",
      "[500/600] Loss: 0.0038 MAE: 0.0041 Mean Error: 0.0007 STD: 0.0617\n",
      "[510/600] Loss: 0.0038 MAE: 0.0040 Mean Error: 0.0007 STD: 0.0617\n",
      "[520/600] Loss: 0.0038 MAE: 0.0040 Mean Error: 0.0007 STD: 0.0617\n",
      "[530/600] Loss: 0.0038 MAE: 0.0040 Mean Error: 0.0007 STD: 0.0617\n",
      "[540/600] Loss: 0.0038 MAE: 0.0040 Mean Error: 0.0007 STD: 0.0617\n",
      "[550/600] Loss: 0.0038 MAE: 0.0040 Mean Error: 0.0007 STD: 0.0617\n",
      "[560/600] Loss: 0.0039 MAE: 0.0042 Mean Error: 0.0007 STD: 0.0624\n",
      "[570/600] Loss: 0.0039 MAE: 0.0042 Mean Error: 0.0008 STD: 0.0625\n",
      "[580/600] Loss: 0.0038 MAE: 0.0041 Mean Error: 0.0006 STD: 0.0617\n",
      "[590/600] Loss: 0.0038 MAE: 0.0041 Mean Error: 0.0006 STD: 0.0617\n",
      "[599/600] Loss: 0.0037 MAE: 0.0041 Mean Error: 0.0005 STD: 0.0609\n",
      "------------------------------------\n",
      "Training dataset with noise standard deviation 0.005\n",
      "[0/600] Loss: 0.2503 MAE: 0.5002 Mean Error: 0.0942 STD: 0.4914\n",
      "[10/600] Loss: 0.1405 MAE: 0.2086 Mean Error: 0.0107 STD: 0.3747\n",
      "[20/600] Loss: 0.1259 MAE: 0.2483 Mean Error: 0.0024 STD: 0.3548\n",
      "[30/600] Loss: 0.1142 MAE: 0.2387 Mean Error: 0.0030 STD: 0.3379\n",
      "[40/600] Loss: 0.0927 MAE: 0.1840 Mean Error: -0.0047 STD: 0.3044\n",
      "[50/600] Loss: 0.0737 MAE: 0.1568 Mean Error: -0.0032 STD: 0.2715\n",
      "[60/600] Loss: 0.0485 MAE: 0.1060 Mean Error: -0.0041 STD: 0.2202\n",
      "[70/600] Loss: 0.0286 MAE: 0.0631 Mean Error: -0.0009 STD: 0.1690\n",
      "[80/600] Loss: 0.0139 MAE: 0.0323 Mean Error: 0.0004 STD: 0.1181\n",
      "[90/600] Loss: 0.0074 MAE: 0.0134 Mean Error: -0.0001 STD: 0.0858\n",
      "[100/600] Loss: 0.0064 MAE: 0.0087 Mean Error: -0.0001 STD: 0.0797\n",
      "[110/600] Loss: 0.0059 MAE: 0.0073 Mean Error: 0.0003 STD: 0.0771\n",
      "[120/600] Loss: 0.0058 MAE: 0.0067 Mean Error: 0.0005 STD: 0.0761\n",
      "[130/600] Loss: 0.0057 MAE: 0.0064 Mean Error: 0.0003 STD: 0.0754\n",
      "[140/600] Loss: 0.0056 MAE: 0.0062 Mean Error: 0.0004 STD: 0.0746\n",
      "[150/600] Loss: 0.0054 MAE: 0.0060 Mean Error: 0.0002 STD: 0.0734\n",
      "[160/600] Loss: 0.0053 MAE: 0.0059 Mean Error: 0.0002 STD: 0.0727\n",
      "[170/600] Loss: 0.0052 MAE: 0.0058 Mean Error: 0.0001 STD: 0.0720\n",
      "[180/600] Loss: 0.0051 MAE: 0.0057 Mean Error: -0.0000 STD: 0.0715\n",
      "[190/600] Loss: 0.0051 MAE: 0.0056 Mean Error: -0.0000 STD: 0.0713\n",
      "[200/600] Loss: 0.0051 MAE: 0.0056 Mean Error: -0.0000 STD: 0.0713\n",
      "[210/600] Loss: 0.0050 MAE: 0.0055 Mean Error: -0.0001 STD: 0.0708\n",
      "[220/600] Loss: 0.0050 MAE: 0.0054 Mean Error: -0.0001 STD: 0.0706\n",
      "[230/600] Loss: 0.0050 MAE: 0.0054 Mean Error: -0.0001 STD: 0.0706\n",
      "[240/600] Loss: 0.0050 MAE: 0.0054 Mean Error: -0.0001 STD: 0.0706\n",
      "[250/600] Loss: 0.0049 MAE: 0.0054 Mean Error: -0.0001 STD: 0.0699\n",
      "[260/600] Loss: 0.0049 MAE: 0.0054 Mean Error: 0.0000 STD: 0.0699\n",
      "[270/600] Loss: 0.0049 MAE: 0.0053 Mean Error: 0.0000 STD: 0.0699\n",
      "[280/600] Loss: 0.0049 MAE: 0.0052 Mean Error: -0.0000 STD: 0.0699\n",
      "[290/600] Loss: 0.0049 MAE: 0.0052 Mean Error: -0.0000 STD: 0.0699\n",
      "[300/600] Loss: 0.0049 MAE: 0.0052 Mean Error: 0.0000 STD: 0.0699\n",
      "[310/600] Loss: 0.0048 MAE: 0.0051 Mean Error: 0.0001 STD: 0.0692\n",
      "[320/600] Loss: 0.0048 MAE: 0.0051 Mean Error: 0.0001 STD: 0.0692\n",
      "[330/600] Loss: 0.0048 MAE: 0.0051 Mean Error: 0.0001 STD: 0.0689\n",
      "[340/600] Loss: 0.0047 MAE: 0.0051 Mean Error: 0.0002 STD: 0.0685\n",
      "[350/600] Loss: 0.0047 MAE: 0.0050 Mean Error: 0.0002 STD: 0.0685\n",
      "[360/600] Loss: 0.0047 MAE: 0.0050 Mean Error: 0.0002 STD: 0.0685\n",
      "[370/600] Loss: 0.0047 MAE: 0.0049 Mean Error: 0.0002 STD: 0.0685\n",
      "[380/600] Loss: 0.0047 MAE: 0.0049 Mean Error: 0.0002 STD: 0.0685\n",
      "[390/600] Loss: 0.0047 MAE: 0.0049 Mean Error: 0.0002 STD: 0.0685\n",
      "[400/600] Loss: 0.0047 MAE: 0.0049 Mean Error: 0.0002 STD: 0.0685\n",
      "[410/600] Loss: 0.0047 MAE: 0.0049 Mean Error: 0.0002 STD: 0.0685\n",
      "[420/600] Loss: 0.0047 MAE: 0.0049 Mean Error: 0.0002 STD: 0.0685\n",
      "[430/600] Loss: 0.0047 MAE: 0.0049 Mean Error: 0.0002 STD: 0.0685\n",
      "[440/600] Loss: 0.0047 MAE: 0.0049 Mean Error: 0.0002 STD: 0.0685\n",
      "[450/600] Loss: 0.0047 MAE: 0.0049 Mean Error: 0.0002 STD: 0.0685\n",
      "[460/600] Loss: 0.0047 MAE: 0.0049 Mean Error: 0.0002 STD: 0.0685\n",
      "[470/600] Loss: 0.0047 MAE: 0.0049 Mean Error: 0.0002 STD: 0.0685\n",
      "[480/600] Loss: 0.0047 MAE: 0.0049 Mean Error: 0.0002 STD: 0.0685\n",
      "[490/600] Loss: 0.0047 MAE: 0.0049 Mean Error: 0.0002 STD: 0.0685\n",
      "[500/600] Loss: 0.0047 MAE: 0.0049 Mean Error: 0.0002 STD: 0.0685\n",
      "[510/600] Loss: 0.0047 MAE: 0.0049 Mean Error: 0.0002 STD: 0.0685\n",
      "[520/600] Loss: 0.0047 MAE: 0.0049 Mean Error: 0.0002 STD: 0.0685\n",
      "[530/600] Loss: 0.0047 MAE: 0.0050 Mean Error: 0.0002 STD: 0.0685\n",
      "[540/600] Loss: 0.0047 MAE: 0.0049 Mean Error: 0.0002 STD: 0.0685\n",
      "[550/600] Loss: 0.0047 MAE: 0.0049 Mean Error: 0.0002 STD: 0.0685\n",
      "[560/600] Loss: 0.0047 MAE: 0.0049 Mean Error: 0.0002 STD: 0.0685\n",
      "[570/600] Loss: 0.0047 MAE: 0.0049 Mean Error: 0.0002 STD: 0.0685\n",
      "[580/600] Loss: 0.0047 MAE: 0.0049 Mean Error: 0.0002 STD: 0.0685\n",
      "[590/600] Loss: 0.0047 MAE: 0.0049 Mean Error: 0.0002 STD: 0.0685\n",
      "[599/600] Loss: 0.0047 MAE: 0.0049 Mean Error: 0.0002 STD: 0.0685\n",
      "------------------------------------\n",
      "Training dataset with noise standard deviation 0.01\n",
      "[0/600] Loss: 0.2499 MAE: 0.4998 Mean Error: 0.0940 STD: 0.4910\n",
      "[10/600] Loss: 0.1404 MAE: 0.2074 Mean Error: 0.0111 STD: 0.3745\n",
      "[20/600] Loss: 0.1226 MAE: 0.2483 Mean Error: 0.0027 STD: 0.3502\n",
      "[30/600] Loss: 0.1004 MAE: 0.2031 Mean Error: -0.0010 STD: 0.3168\n",
      "[40/600] Loss: 0.0844 MAE: 0.1752 Mean Error: -0.0031 STD: 0.2905\n",
      "[50/600] Loss: 0.0624 MAE: 0.1392 Mean Error: 0.0034 STD: 0.2498\n",
      "[60/600] Loss: 0.0312 MAE: 0.0741 Mean Error: -0.0021 STD: 0.1766\n",
      "[70/600] Loss: 0.0137 MAE: 0.0308 Mean Error: -0.0031 STD: 0.1169\n",
      "[80/600] Loss: 0.0090 MAE: 0.0158 Mean Error: -0.0019 STD: 0.0951\n",
      "[90/600] Loss: 0.0073 MAE: 0.0108 Mean Error: -0.0018 STD: 0.0853\n",
      "[100/600] Loss: 0.0066 MAE: 0.0086 Mean Error: -0.0019 STD: 0.0811\n",
      "[110/600] Loss: 0.0063 MAE: 0.0077 Mean Error: -0.0021 STD: 0.0793\n",
      "[120/600] Loss: 0.0062 MAE: 0.0072 Mean Error: -0.0018 STD: 0.0786\n",
      "[130/600] Loss: 0.0062 MAE: 0.0069 Mean Error: -0.0019 STD: 0.0785\n",
      "[140/600] Loss: 0.0062 MAE: 0.0068 Mean Error: -0.0019 STD: 0.0785\n",
      "[150/600] Loss: 0.0062 MAE: 0.0068 Mean Error: -0.0019 STD: 0.0785\n",
      "[160/600] Loss: 0.0062 MAE: 0.0067 Mean Error: -0.0019 STD: 0.0784\n",
      "[170/600] Loss: 0.0062 MAE: 0.0067 Mean Error: -0.0019 STD: 0.0784\n",
      "[180/600] Loss: 0.0062 MAE: 0.0067 Mean Error: -0.0019 STD: 0.0784\n",
      "[190/600] Loss: 0.0061 MAE: 0.0066 Mean Error: -0.0020 STD: 0.0778\n",
      "[200/600] Loss: 0.0061 MAE: 0.0066 Mean Error: -0.0019 STD: 0.0778\n",
      "[210/600] Loss: 0.0061 MAE: 0.0065 Mean Error: -0.0020 STD: 0.0778\n",
      "[220/600] Loss: 0.0061 MAE: 0.0065 Mean Error: -0.0020 STD: 0.0778\n",
      "[230/600] Loss: 0.0061 MAE: 0.0065 Mean Error: -0.0020 STD: 0.0778\n",
      "[240/600] Loss: 0.0061 MAE: 0.0065 Mean Error: -0.0020 STD: 0.0778\n",
      "[250/600] Loss: 0.0061 MAE: 0.0065 Mean Error: -0.0020 STD: 0.0778\n",
      "[260/600] Loss: 0.0061 MAE: 0.0065 Mean Error: -0.0020 STD: 0.0778\n",
      "[270/600] Loss: 0.0061 MAE: 0.0064 Mean Error: -0.0020 STD: 0.0778\n",
      "[280/600] Loss: 0.0061 MAE: 0.0064 Mean Error: -0.0020 STD: 0.0778\n",
      "[290/600] Loss: 0.0060 MAE: 0.0064 Mean Error: -0.0020 STD: 0.0776\n",
      "[300/600] Loss: 0.0060 MAE: 0.0064 Mean Error: -0.0021 STD: 0.0772\n",
      "[310/600] Loss: 0.0060 MAE: 0.0064 Mean Error: -0.0021 STD: 0.0772\n",
      "[320/600] Loss: 0.0060 MAE: 0.0064 Mean Error: -0.0021 STD: 0.0772\n",
      "[330/600] Loss: 0.0060 MAE: 0.0063 Mean Error: -0.0021 STD: 0.0772\n",
      "[340/600] Loss: 0.0060 MAE: 0.0063 Mean Error: -0.0021 STD: 0.0772\n",
      "[350/600] Loss: 0.0060 MAE: 0.0063 Mean Error: -0.0021 STD: 0.0772\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[360/600] Loss: 0.0060 MAE: 0.0063 Mean Error: -0.0021 STD: 0.0772\n",
      "[370/600] Loss: 0.0060 MAE: 0.0063 Mean Error: -0.0021 STD: 0.0772\n",
      "[380/600] Loss: 0.0059 MAE: 0.0063 Mean Error: -0.0020 STD: 0.0770\n",
      "[390/600] Loss: 0.0058 MAE: 0.0062 Mean Error: -0.0020 STD: 0.0762\n",
      "[400/600] Loss: 0.0058 MAE: 0.0062 Mean Error: -0.0021 STD: 0.0759\n",
      "[410/600] Loss: 0.0058 MAE: 0.0062 Mean Error: -0.0021 STD: 0.0759\n",
      "[420/600] Loss: 0.0058 MAE: 0.0061 Mean Error: -0.0021 STD: 0.0759\n",
      "[430/600] Loss: 0.0058 MAE: 0.0061 Mean Error: -0.0021 STD: 0.0759\n",
      "[440/600] Loss: 0.0058 MAE: 0.0061 Mean Error: -0.0021 STD: 0.0759\n",
      "[450/600] Loss: 0.0058 MAE: 0.0061 Mean Error: -0.0021 STD: 0.0759\n",
      "[460/600] Loss: 0.0058 MAE: 0.0061 Mean Error: -0.0021 STD: 0.0759\n",
      "[470/600] Loss: 0.0058 MAE: 0.0061 Mean Error: -0.0021 STD: 0.0759\n",
      "[480/600] Loss: 0.0058 MAE: 0.0060 Mean Error: -0.0021 STD: 0.0759\n",
      "[490/600] Loss: 0.0058 MAE: 0.0060 Mean Error: -0.0021 STD: 0.0759\n",
      "[500/600] Loss: 0.0058 MAE: 0.0060 Mean Error: -0.0021 STD: 0.0759\n",
      "[510/600] Loss: 0.0058 MAE: 0.0060 Mean Error: -0.0021 STD: 0.0759\n",
      "[520/600] Loss: 0.0058 MAE: 0.0060 Mean Error: -0.0021 STD: 0.0759\n",
      "[530/600] Loss: 0.0058 MAE: 0.0060 Mean Error: -0.0021 STD: 0.0759\n",
      "[540/600] Loss: 0.0058 MAE: 0.0060 Mean Error: -0.0021 STD: 0.0759\n",
      "[550/600] Loss: 0.0058 MAE: 0.0060 Mean Error: -0.0021 STD: 0.0759\n",
      "[560/600] Loss: 0.0058 MAE: 0.0060 Mean Error: -0.0021 STD: 0.0759\n",
      "[570/600] Loss: 0.0058 MAE: 0.0060 Mean Error: -0.0021 STD: 0.0759\n",
      "[580/600] Loss: 0.0058 MAE: 0.0060 Mean Error: -0.0021 STD: 0.0759\n",
      "[590/600] Loss: 0.0058 MAE: 0.0060 Mean Error: -0.0021 STD: 0.0759\n",
      "[599/600] Loss: 0.0058 MAE: 0.0060 Mean Error: -0.0021 STD: 0.0759\n",
      "------------------------------------\n",
      "Training dataset with noise standard deviation 0.02\n",
      "[0/600] Loss: 0.2502 MAE: 0.5001 Mean Error: 0.0940 STD: 0.4913\n",
      "[10/600] Loss: 0.1410 MAE: 0.2081 Mean Error: 0.0095 STD: 0.3753\n",
      "[20/600] Loss: 0.1236 MAE: 0.2506 Mean Error: 0.0037 STD: 0.3515\n",
      "[30/600] Loss: 0.1016 MAE: 0.2086 Mean Error: -0.0001 STD: 0.3187\n",
      "[40/600] Loss: 0.0844 MAE: 0.1745 Mean Error: -0.0013 STD: 0.2905\n",
      "[50/600] Loss: 0.0639 MAE: 0.1388 Mean Error: 0.0021 STD: 0.2528\n",
      "[60/600] Loss: 0.0390 MAE: 0.0876 Mean Error: 0.0011 STD: 0.1976\n",
      "[70/600] Loss: 0.0216 MAE: 0.0498 Mean Error: -0.0027 STD: 0.1470\n",
      "[80/600] Loss: 0.0096 MAE: 0.0227 Mean Error: -0.0011 STD: 0.0981\n",
      "[90/600] Loss: 0.0063 MAE: 0.0111 Mean Error: -0.0009 STD: 0.0793\n",
      "[100/600] Loss: 0.0057 MAE: 0.0078 Mean Error: -0.0006 STD: 0.0752\n",
      "[110/600] Loss: 0.0055 MAE: 0.0068 Mean Error: -0.0008 STD: 0.0741\n",
      "[120/600] Loss: 0.0053 MAE: 0.0064 Mean Error: -0.0008 STD: 0.0731\n",
      "[130/600] Loss: 0.0053 MAE: 0.0061 Mean Error: -0.0008 STD: 0.0727\n",
      "[140/600] Loss: 0.0053 MAE: 0.0060 Mean Error: -0.0008 STD: 0.0727\n",
      "[150/600] Loss: 0.0053 MAE: 0.0059 Mean Error: -0.0008 STD: 0.0727\n",
      "[160/600] Loss: 0.0053 MAE: 0.0059 Mean Error: -0.0008 STD: 0.0726\n",
      "[170/600] Loss: 0.0053 MAE: 0.0058 Mean Error: -0.0008 STD: 0.0726\n",
      "[180/600] Loss: 0.0053 MAE: 0.0058 Mean Error: -0.0008 STD: 0.0726\n",
      "[190/600] Loss: 0.0053 MAE: 0.0058 Mean Error: -0.0008 STD: 0.0726\n",
      "[200/600] Loss: 0.0053 MAE: 0.0058 Mean Error: -0.0008 STD: 0.0726\n",
      "[210/600] Loss: 0.0053 MAE: 0.0058 Mean Error: -0.0008 STD: 0.0726\n",
      "[220/600] Loss: 0.0053 MAE: 0.0057 Mean Error: -0.0008 STD: 0.0726\n",
      "[230/600] Loss: 0.0053 MAE: 0.0057 Mean Error: -0.0008 STD: 0.0726\n",
      "[240/600] Loss: 0.0053 MAE: 0.0057 Mean Error: -0.0008 STD: 0.0726\n",
      "[250/600] Loss: 0.0053 MAE: 0.0057 Mean Error: -0.0008 STD: 0.0726\n",
      "[260/600] Loss: 0.0053 MAE: 0.0057 Mean Error: -0.0008 STD: 0.0725\n",
      "[270/600] Loss: 0.0052 MAE: 0.0057 Mean Error: -0.0009 STD: 0.0720\n",
      "[280/600] Loss: 0.0052 MAE: 0.0056 Mean Error: -0.0009 STD: 0.0720\n",
      "[290/600] Loss: 0.0052 MAE: 0.0056 Mean Error: -0.0009 STD: 0.0720\n",
      "[300/600] Loss: 0.0052 MAE: 0.0056 Mean Error: -0.0009 STD: 0.0720\n",
      "[310/600] Loss: 0.0052 MAE: 0.0056 Mean Error: -0.0009 STD: 0.0720\n",
      "[320/600] Loss: 0.0051 MAE: 0.0055 Mean Error: -0.0008 STD: 0.0715\n",
      "[330/600] Loss: 0.0050 MAE: 0.0055 Mean Error: -0.0007 STD: 0.0706\n",
      "[340/600] Loss: 0.0049 MAE: 0.0054 Mean Error: -0.0006 STD: 0.0699\n",
      "[350/600] Loss: 0.0049 MAE: 0.0053 Mean Error: -0.0006 STD: 0.0699\n",
      "[360/600] Loss: 0.0049 MAE: 0.0053 Mean Error: -0.0006 STD: 0.0699\n",
      "[370/600] Loss: 0.0049 MAE: 0.0052 Mean Error: -0.0006 STD: 0.0699\n",
      "[380/600] Loss: 0.0049 MAE: 0.0052 Mean Error: -0.0006 STD: 0.0699\n",
      "[390/600] Loss: 0.0049 MAE: 0.0052 Mean Error: -0.0006 STD: 0.0699\n",
      "[400/600] Loss: 0.0049 MAE: 0.0052 Mean Error: -0.0006 STD: 0.0699\n",
      "[410/600] Loss: 0.0048 MAE: 0.0053 Mean Error: -0.0006 STD: 0.0693\n",
      "[420/600] Loss: 0.0048 MAE: 0.0052 Mean Error: -0.0005 STD: 0.0692\n",
      "[430/600] Loss: 0.0048 MAE: 0.0052 Mean Error: -0.0005 STD: 0.0692\n",
      "[440/600] Loss: 0.0048 MAE: 0.0051 Mean Error: -0.0005 STD: 0.0692\n",
      "[450/600] Loss: 0.0048 MAE: 0.0051 Mean Error: -0.0005 STD: 0.0692\n",
      "[460/600] Loss: 0.0048 MAE: 0.0051 Mean Error: -0.0005 STD: 0.0692\n",
      "[470/600] Loss: 0.0048 MAE: 0.0051 Mean Error: -0.0005 STD: 0.0692\n",
      "[480/600] Loss: 0.0048 MAE: 0.0051 Mean Error: -0.0005 STD: 0.0692\n",
      "[490/600] Loss: 0.0047 MAE: 0.0051 Mean Error: -0.0005 STD: 0.0686\n",
      "[500/600] Loss: 0.0047 MAE: 0.0050 Mean Error: -0.0004 STD: 0.0685\n",
      "[510/600] Loss: 0.0047 MAE: 0.0050 Mean Error: -0.0004 STD: 0.0685\n",
      "[520/600] Loss: 0.0047 MAE: 0.0050 Mean Error: -0.0004 STD: 0.0685\n",
      "[530/600] Loss: 0.0047 MAE: 0.0049 Mean Error: -0.0004 STD: 0.0682\n",
      "[540/600] Loss: 0.0046 MAE: 0.0049 Mean Error: -0.0005 STD: 0.0678\n",
      "[550/600] Loss: 0.0046 MAE: 0.0049 Mean Error: -0.0005 STD: 0.0678\n",
      "[560/600] Loss: 0.0046 MAE: 0.0049 Mean Error: -0.0005 STD: 0.0678\n",
      "[570/600] Loss: 0.0046 MAE: 0.0049 Mean Error: -0.0005 STD: 0.0678\n",
      "[580/600] Loss: 0.0046 MAE: 0.0048 Mean Error: -0.0005 STD: 0.0678\n",
      "[590/600] Loss: 0.0046 MAE: 0.0048 Mean Error: -0.0005 STD: 0.0678\n",
      "[599/600] Loss: 0.0046 MAE: 0.0048 Mean Error: -0.0005 STD: 0.0678\n",
      "------------------------------------\n",
      "Training dataset with noise standard deviation 0.03\n",
      "[0/600] Loss: 0.2501 MAE: 0.5000 Mean Error: 0.0941 STD: 0.4912\n",
      "[10/600] Loss: 0.1409 MAE: 0.2092 Mean Error: 0.0111 STD: 0.3752\n",
      "[20/600] Loss: 0.1250 MAE: 0.2563 Mean Error: 0.0058 STD: 0.3535\n",
      "[30/600] Loss: 0.1069 MAE: 0.2293 Mean Error: 0.0033 STD: 0.3270\n",
      "[40/600] Loss: 0.0886 MAE: 0.1787 Mean Error: -0.0025 STD: 0.2977\n",
      "[50/600] Loss: 0.0724 MAE: 0.1543 Mean Error: -0.0021 STD: 0.2691\n",
      "[60/600] Loss: 0.0493 MAE: 0.1160 Mean Error: -0.0000 STD: 0.2222\n",
      "[70/600] Loss: 0.0257 MAE: 0.0641 Mean Error: -0.0003 STD: 0.1604\n",
      "[80/600] Loss: 0.0096 MAE: 0.0270 Mean Error: -0.0010 STD: 0.0978\n",
      "[90/600] Loss: 0.0041 MAE: 0.0100 Mean Error: -0.0002 STD: 0.0640\n",
      "[100/600] Loss: 0.0031 MAE: 0.0054 Mean Error: 0.0000 STD: 0.0559\n",
      "[110/600] Loss: 0.0029 MAE: 0.0042 Mean Error: -0.0000 STD: 0.0539\n",
      "[120/600] Loss: 0.0028 MAE: 0.0037 Mean Error: 0.0000 STD: 0.0533\n",
      "[130/600] Loss: 0.0028 MAE: 0.0036 Mean Error: 0.0001 STD: 0.0533\n",
      "[140/600] Loss: 0.0028 MAE: 0.0035 Mean Error: 0.0001 STD: 0.0531\n",
      "[150/600] Loss: 0.0027 MAE: 0.0034 Mean Error: 0.0000 STD: 0.0524\n",
      "[160/600] Loss: 0.0027 MAE: 0.0033 Mean Error: -0.0000 STD: 0.0523\n",
      "[170/600] Loss: 0.0027 MAE: 0.0033 Mean Error: -0.0000 STD: 0.0523\n",
      "[180/600] Loss: 0.0027 MAE: 0.0033 Mean Error: -0.0000 STD: 0.0523\n",
      "[190/600] Loss: 0.0027 MAE: 0.0032 Mean Error: -0.0000 STD: 0.0523\n",
      "[200/600] Loss: 0.0027 MAE: 0.0032 Mean Error: -0.0000 STD: 0.0523\n",
      "[210/600] Loss: 0.0026 MAE: 0.0032 Mean Error: -0.0002 STD: 0.0515\n",
      "[220/600] Loss: 0.0026 MAE: 0.0031 Mean Error: -0.0001 STD: 0.0514\n",
      "[230/600] Loss: 0.0026 MAE: 0.0031 Mean Error: -0.0001 STD: 0.0514\n",
      "[240/600] Loss: 0.0026 MAE: 0.0031 Mean Error: -0.0001 STD: 0.0514\n",
      "[250/600] Loss: 0.0026 MAE: 0.0031 Mean Error: -0.0001 STD: 0.0514\n",
      "[260/600] Loss: 0.0026 MAE: 0.0031 Mean Error: -0.0001 STD: 0.0514\n",
      "[270/600] Loss: 0.0026 MAE: 0.0030 Mean Error: -0.0001 STD: 0.0514\n",
      "[280/600] Loss: 0.0026 MAE: 0.0030 Mean Error: -0.0001 STD: 0.0514\n",
      "[290/600] Loss: 0.0026 MAE: 0.0030 Mean Error: -0.0001 STD: 0.0514\n",
      "[300/600] Loss: 0.0026 MAE: 0.0030 Mean Error: -0.0001 STD: 0.0514\n",
      "[310/600] Loss: 0.0026 MAE: 0.0030 Mean Error: -0.0001 STD: 0.0514\n",
      "[320/600] Loss: 0.0026 MAE: 0.0030 Mean Error: -0.0001 STD: 0.0514\n",
      "[330/600] Loss: 0.0026 MAE: 0.0030 Mean Error: -0.0001 STD: 0.0514\n",
      "[340/600] Loss: 0.0026 MAE: 0.0030 Mean Error: -0.0001 STD: 0.0514\n",
      "[350/600] Loss: 0.0026 MAE: 0.0030 Mean Error: -0.0001 STD: 0.0514\n",
      "[360/600] Loss: 0.0026 MAE: 0.0030 Mean Error: -0.0001 STD: 0.0514\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[370/600] Loss: 0.0026 MAE: 0.0030 Mean Error: -0.0001 STD: 0.0514\n",
      "[380/600] Loss: 0.0026 MAE: 0.0030 Mean Error: -0.0001 STD: 0.0514\n",
      "[390/600] Loss: 0.0026 MAE: 0.0029 Mean Error: -0.0001 STD: 0.0507\n",
      "[400/600] Loss: 0.0025 MAE: 0.0029 Mean Error: -0.0000 STD: 0.0504\n",
      "[410/600] Loss: 0.0025 MAE: 0.0029 Mean Error: -0.0000 STD: 0.0504\n",
      "[420/600] Loss: 0.0025 MAE: 0.0029 Mean Error: -0.0000 STD: 0.0504\n",
      "[430/600] Loss: 0.0025 MAE: 0.0029 Mean Error: -0.0000 STD: 0.0504\n",
      "[440/600] Loss: 0.0025 MAE: 0.0028 Mean Error: -0.0000 STD: 0.0504\n",
      "[450/600] Loss: 0.0025 MAE: 0.0028 Mean Error: -0.0000 STD: 0.0504\n",
      "[460/600] Loss: 0.0025 MAE: 0.0028 Mean Error: -0.0000 STD: 0.0504\n",
      "[470/600] Loss: 0.0025 MAE: 0.0028 Mean Error: -0.0000 STD: 0.0504\n",
      "[480/600] Loss: 0.0025 MAE: 0.0028 Mean Error: -0.0000 STD: 0.0504\n",
      "[490/600] Loss: 0.0025 MAE: 0.0028 Mean Error: -0.0000 STD: 0.0504\n",
      "[500/600] Loss: 0.0025 MAE: 0.0028 Mean Error: -0.0000 STD: 0.0504\n",
      "[510/600] Loss: 0.0025 MAE: 0.0028 Mean Error: -0.0000 STD: 0.0504\n",
      "[520/600] Loss: 0.0025 MAE: 0.0028 Mean Error: -0.0000 STD: 0.0504\n",
      "[530/600] Loss: 0.0025 MAE: 0.0028 Mean Error: -0.0000 STD: 0.0504\n",
      "[540/600] Loss: 0.0025 MAE: 0.0028 Mean Error: -0.0000 STD: 0.0504\n",
      "[550/600] Loss: 0.0025 MAE: 0.0028 Mean Error: -0.0000 STD: 0.0504\n",
      "[560/600] Loss: 0.0025 MAE: 0.0028 Mean Error: -0.0000 STD: 0.0504\n",
      "[570/600] Loss: 0.0025 MAE: 0.0028 Mean Error: -0.0000 STD: 0.0504\n",
      "[580/600] Loss: 0.0025 MAE: 0.0028 Mean Error: -0.0000 STD: 0.0504\n",
      "[590/600] Loss: 0.0025 MAE: 0.0028 Mean Error: -0.0000 STD: 0.0504\n",
      "[599/600] Loss: 0.0025 MAE: 0.0028 Mean Error: -0.0000 STD: 0.0504\n",
      "------------------------------------\n",
      "Training dataset with noise standard deviation 0.05\n",
      "[0/600] Loss: 0.2501 MAE: 0.5000 Mean Error: 0.0943 STD: 0.4912\n",
      "[10/600] Loss: 0.1394 MAE: 0.2135 Mean Error: 0.0080 STD: 0.3733\n",
      "[20/600] Loss: 0.1254 MAE: 0.2572 Mean Error: 0.0021 STD: 0.3541\n",
      "[30/600] Loss: 0.1120 MAE: 0.2407 Mean Error: 0.0060 STD: 0.3347\n",
      "[40/600] Loss: 0.0906 MAE: 0.1813 Mean Error: -0.0018 STD: 0.3010\n",
      "[50/600] Loss: 0.0739 MAE: 0.1561 Mean Error: -0.0015 STD: 0.2718\n",
      "[60/600] Loss: 0.0470 MAE: 0.1122 Mean Error: 0.0003 STD: 0.2168\n",
      "[70/600] Loss: 0.0209 MAE: 0.0542 Mean Error: -0.0005 STD: 0.1447\n",
      "[80/600] Loss: 0.0071 MAE: 0.0197 Mean Error: 0.0003 STD: 0.0843\n",
      "[90/600] Loss: 0.0041 MAE: 0.0084 Mean Error: 0.0005 STD: 0.0641\n",
      "[100/600] Loss: 0.0034 MAE: 0.0054 Mean Error: -0.0001 STD: 0.0585\n",
      "[110/600] Loss: 0.0031 MAE: 0.0043 Mean Error: -0.0001 STD: 0.0560\n",
      "[120/600] Loss: 0.0030 MAE: 0.0039 Mean Error: -0.0001 STD: 0.0551\n",
      "[130/600] Loss: 0.0030 MAE: 0.0037 Mean Error: -0.0001 STD: 0.0551\n",
      "[140/600] Loss: 0.0030 MAE: 0.0036 Mean Error: -0.0001 STD: 0.0551\n",
      "[150/600] Loss: 0.0030 MAE: 0.0036 Mean Error: -0.0000 STD: 0.0548\n",
      "[160/600] Loss: 0.0029 MAE: 0.0035 Mean Error: 0.0000 STD: 0.0542\n",
      "[170/600] Loss: 0.0029 MAE: 0.0034 Mean Error: 0.0000 STD: 0.0542\n",
      "[180/600] Loss: 0.0029 MAE: 0.0034 Mean Error: -0.0000 STD: 0.0542\n",
      "[190/600] Loss: 0.0029 MAE: 0.0034 Mean Error: -0.0000 STD: 0.0542\n",
      "[200/600] Loss: 0.0029 MAE: 0.0034 Mean Error: -0.0000 STD: 0.0542\n",
      "[210/600] Loss: 0.0029 MAE: 0.0033 Mean Error: -0.0000 STD: 0.0541\n",
      "[220/600] Loss: 0.0029 MAE: 0.0033 Mean Error: -0.0000 STD: 0.0541\n",
      "[230/600] Loss: 0.0029 MAE: 0.0033 Mean Error: -0.0000 STD: 0.0541\n",
      "[240/600] Loss: 0.0029 MAE: 0.0033 Mean Error: -0.0000 STD: 0.0541\n",
      "[250/600] Loss: 0.0029 MAE: 0.0033 Mean Error: -0.0000 STD: 0.0541\n",
      "[260/600] Loss: 0.0029 MAE: 0.0033 Mean Error: -0.0000 STD: 0.0541\n",
      "[270/600] Loss: 0.0029 MAE: 0.0033 Mean Error: -0.0000 STD: 0.0541\n",
      "[280/600] Loss: 0.0029 MAE: 0.0033 Mean Error: -0.0000 STD: 0.0541\n",
      "[290/600] Loss: 0.0029 MAE: 0.0033 Mean Error: -0.0000 STD: 0.0541\n",
      "[300/600] Loss: 0.0029 MAE: 0.0033 Mean Error: -0.0000 STD: 0.0541\n",
      "[310/600] Loss: 0.0029 MAE: 0.0033 Mean Error: -0.0000 STD: 0.0541\n",
      "[320/600] Loss: 0.0029 MAE: 0.0032 Mean Error: -0.0000 STD: 0.0541\n",
      "[330/600] Loss: 0.0029 MAE: 0.0032 Mean Error: -0.0000 STD: 0.0541\n",
      "[340/600] Loss: 0.0028 MAE: 0.0032 Mean Error: 0.0001 STD: 0.0532\n",
      "[350/600] Loss: 0.0028 MAE: 0.0032 Mean Error: 0.0001 STD: 0.0532\n",
      "[360/600] Loss: 0.0028 MAE: 0.0032 Mean Error: 0.0002 STD: 0.0526\n",
      "[370/600] Loss: 0.0027 MAE: 0.0031 Mean Error: 0.0002 STD: 0.0523\n",
      "[380/600] Loss: 0.0027 MAE: 0.0031 Mean Error: 0.0002 STD: 0.0523\n",
      "[390/600] Loss: 0.0027 MAE: 0.0031 Mean Error: 0.0002 STD: 0.0523\n",
      "[400/600] Loss: 0.0026 MAE: 0.0030 Mean Error: 0.0003 STD: 0.0514\n",
      "[410/600] Loss: 0.0026 MAE: 0.0030 Mean Error: 0.0003 STD: 0.0514\n",
      "[420/600] Loss: 0.0026 MAE: 0.0029 Mean Error: 0.0003 STD: 0.0514\n",
      "[430/600] Loss: 0.0026 MAE: 0.0029 Mean Error: 0.0003 STD: 0.0514\n",
      "[440/600] Loss: 0.0026 MAE: 0.0029 Mean Error: 0.0003 STD: 0.0514\n",
      "[450/600] Loss: 0.0026 MAE: 0.0029 Mean Error: 0.0003 STD: 0.0514\n",
      "[460/600] Loss: 0.0026 MAE: 0.0029 Mean Error: 0.0003 STD: 0.0514\n",
      "[470/600] Loss: 0.0026 MAE: 0.0029 Mean Error: 0.0003 STD: 0.0514\n",
      "[480/600] Loss: 0.0026 MAE: 0.0029 Mean Error: 0.0003 STD: 0.0514\n",
      "[490/600] Loss: 0.0026 MAE: 0.0029 Mean Error: 0.0003 STD: 0.0514\n",
      "[500/600] Loss: 0.0026 MAE: 0.0029 Mean Error: 0.0003 STD: 0.0514\n",
      "[510/600] Loss: 0.0026 MAE: 0.0029 Mean Error: 0.0003 STD: 0.0514\n",
      "[520/600] Loss: 0.0026 MAE: 0.0029 Mean Error: 0.0003 STD: 0.0514\n",
      "[530/600] Loss: 0.0026 MAE: 0.0029 Mean Error: 0.0003 STD: 0.0514\n",
      "[540/600] Loss: 0.0026 MAE: 0.0029 Mean Error: 0.0003 STD: 0.0514\n",
      "[550/600] Loss: 0.0026 MAE: 0.0029 Mean Error: 0.0003 STD: 0.0514\n",
      "[560/600] Loss: 0.0026 MAE: 0.0028 Mean Error: 0.0003 STD: 0.0511\n",
      "[570/600] Loss: 0.0025 MAE: 0.0028 Mean Error: 0.0002 STD: 0.0504\n",
      "[580/600] Loss: 0.0025 MAE: 0.0028 Mean Error: 0.0002 STD: 0.0504\n",
      "[590/600] Loss: 0.0025 MAE: 0.0028 Mean Error: 0.0002 STD: 0.0504\n",
      "[599/600] Loss: 0.0025 MAE: 0.0028 Mean Error: 0.0002 STD: 0.0504\n",
      "------------------------------------\n",
      "Training dataset with noise standard deviation 0.1\n",
      "[0/600] Loss: 0.2498 MAE: 0.4997 Mean Error: 0.0942 STD: 0.4908\n",
      "[10/600] Loss: 0.1395 MAE: 0.2116 Mean Error: 0.0099 STD: 0.3734\n",
      "[20/600] Loss: 0.1259 MAE: 0.2587 Mean Error: 0.0076 STD: 0.3548\n",
      "[30/600] Loss: 0.1172 MAE: 0.2494 Mean Error: 0.0086 STD: 0.3422\n",
      "[40/600] Loss: 0.0921 MAE: 0.1890 Mean Error: -0.0032 STD: 0.3035\n",
      "[50/600] Loss: 0.0638 MAE: 0.1386 Mean Error: -0.0081 STD: 0.2525\n",
      "[60/600] Loss: 0.0364 MAE: 0.0749 Mean Error: -0.0022 STD: 0.1907\n",
      "[70/600] Loss: 0.0215 MAE: 0.0410 Mean Error: 0.0002 STD: 0.1467\n",
      "[80/600] Loss: 0.0155 MAE: 0.0243 Mean Error: -0.0005 STD: 0.1246\n",
      "[90/600] Loss: 0.0135 MAE: 0.0179 Mean Error: -0.0007 STD: 0.1164\n",
      "[100/600] Loss: 0.0129 MAE: 0.0155 Mean Error: -0.0007 STD: 0.1138\n",
      "[110/600] Loss: 0.0127 MAE: 0.0143 Mean Error: -0.0007 STD: 0.1126\n",
      "[120/600] Loss: 0.0126 MAE: 0.0138 Mean Error: -0.0007 STD: 0.1124\n",
      "[130/600] Loss: 0.0126 MAE: 0.0136 Mean Error: -0.0007 STD: 0.1123\n",
      "[140/600] Loss: 0.0126 MAE: 0.0135 Mean Error: -0.0008 STD: 0.1122\n",
      "[150/600] Loss: 0.0124 MAE: 0.0133 Mean Error: -0.0009 STD: 0.1115\n",
      "[160/600] Loss: 0.0123 MAE: 0.0132 Mean Error: -0.0010 STD: 0.1110\n",
      "[170/600] Loss: 0.0122 MAE: 0.0131 Mean Error: -0.0011 STD: 0.1106\n",
      "[180/600] Loss: 0.0122 MAE: 0.0130 Mean Error: -0.0011 STD: 0.1105\n",
      "[190/600] Loss: 0.0121 MAE: 0.0129 Mean Error: -0.0011 STD: 0.1102\n",
      "[200/600] Loss: 0.0120 MAE: 0.0128 Mean Error: -0.0013 STD: 0.1097\n",
      "[210/600] Loss: 0.0120 MAE: 0.0127 Mean Error: -0.0013 STD: 0.1096\n",
      "[220/600] Loss: 0.0120 MAE: 0.0126 Mean Error: -0.0013 STD: 0.1096\n",
      "[230/600] Loss: 0.0120 MAE: 0.0126 Mean Error: -0.0013 STD: 0.1096\n",
      "[240/600] Loss: 0.0120 MAE: 0.0126 Mean Error: -0.0013 STD: 0.1096\n",
      "[250/600] Loss: 0.0120 MAE: 0.0125 Mean Error: -0.0013 STD: 0.1096\n",
      "[260/600] Loss: 0.0120 MAE: 0.0125 Mean Error: -0.0013 STD: 0.1096\n",
      "[270/600] Loss: 0.0120 MAE: 0.0125 Mean Error: -0.0013 STD: 0.1096\n",
      "[280/600] Loss: 0.0120 MAE: 0.0125 Mean Error: -0.0013 STD: 0.1096\n",
      "[290/600] Loss: 0.0120 MAE: 0.0125 Mean Error: -0.0013 STD: 0.1096\n",
      "[300/600] Loss: 0.0120 MAE: 0.0124 Mean Error: -0.0013 STD: 0.1096\n",
      "[310/600] Loss: 0.0120 MAE: 0.0124 Mean Error: -0.0013 STD: 0.1096\n",
      "[320/600] Loss: 0.0120 MAE: 0.0124 Mean Error: -0.0013 STD: 0.1096\n",
      "[330/600] Loss: 0.0119 MAE: 0.0124 Mean Error: -0.0014 STD: 0.1092\n",
      "[340/600] Loss: 0.0119 MAE: 0.0124 Mean Error: -0.0014 STD: 0.1092\n",
      "[350/600] Loss: 0.0119 MAE: 0.0124 Mean Error: -0.0012 STD: 0.1091\n",
      "[360/600] Loss: 0.0118 MAE: 0.0123 Mean Error: -0.0013 STD: 0.1087\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[370/600] Loss: 0.0118 MAE: 0.0123 Mean Error: -0.0013 STD: 0.1087\n",
      "[380/600] Loss: 0.0118 MAE: 0.0123 Mean Error: -0.0013 STD: 0.1087\n",
      "[390/600] Loss: 0.0118 MAE: 0.0122 Mean Error: -0.0013 STD: 0.1087\n",
      "[400/600] Loss: 0.0118 MAE: 0.0122 Mean Error: -0.0013 STD: 0.1087\n",
      "[410/600] Loss: 0.0118 MAE: 0.0122 Mean Error: -0.0013 STD: 0.1087\n",
      "[420/600] Loss: 0.0118 MAE: 0.0122 Mean Error: -0.0013 STD: 0.1087\n",
      "[430/600] Loss: 0.0118 MAE: 0.0122 Mean Error: -0.0013 STD: 0.1087\n",
      "[440/600] Loss: 0.0118 MAE: 0.0121 Mean Error: -0.0013 STD: 0.1087\n",
      "[450/600] Loss: 0.0118 MAE: 0.0121 Mean Error: -0.0013 STD: 0.1087\n",
      "[460/600] Loss: 0.0117 MAE: 0.0121 Mean Error: -0.0012 STD: 0.1083\n",
      "[470/600] Loss: 0.0117 MAE: 0.0121 Mean Error: -0.0012 STD: 0.1083\n",
      "[480/600] Loss: 0.0117 MAE: 0.0121 Mean Error: -0.0012 STD: 0.1083\n",
      "[490/600] Loss: 0.0117 MAE: 0.0120 Mean Error: -0.0012 STD: 0.1083\n",
      "[500/600] Loss: 0.0117 MAE: 0.0120 Mean Error: -0.0012 STD: 0.1083\n",
      "[510/600] Loss: 0.0117 MAE: 0.0120 Mean Error: -0.0012 STD: 0.1083\n",
      "[520/600] Loss: 0.0117 MAE: 0.0120 Mean Error: -0.0012 STD: 0.1083\n",
      "[530/600] Loss: 0.0117 MAE: 0.0120 Mean Error: -0.0012 STD: 0.1083\n",
      "[540/600] Loss: 0.0117 MAE: 0.0120 Mean Error: -0.0012 STD: 0.1083\n",
      "[550/600] Loss: 0.0117 MAE: 0.0120 Mean Error: -0.0012 STD: 0.1083\n",
      "[560/600] Loss: 0.0117 MAE: 0.0120 Mean Error: -0.0012 STD: 0.1083\n",
      "[570/600] Loss: 0.0117 MAE: 0.0120 Mean Error: -0.0012 STD: 0.1083\n",
      "[580/600] Loss: 0.0117 MAE: 0.0120 Mean Error: -0.0012 STD: 0.1083\n",
      "[590/600] Loss: 0.0117 MAE: 0.0119 Mean Error: -0.0012 STD: 0.1083\n",
      "[599/600] Loss: 0.0116 MAE: 0.0120 Mean Error: -0.0012 STD: 0.1078\n",
      "------------------------------------\n",
      "Training dataset with noise standard deviation 0.001\n",
      "[0/600] Loss: 0.2500 MAE: 0.4999 Mean Error: 0.0942 STD: 0.4911\n",
      "[10/600] Loss: 0.1405 MAE: 0.2078 Mean Error: 0.0068 STD: 0.3748\n",
      "[20/600] Loss: 0.1228 MAE: 0.2537 Mean Error: 0.0039 STD: 0.3504\n",
      "[30/600] Loss: 0.1021 MAE: 0.2064 Mean Error: -0.0031 STD: 0.3196\n",
      "[40/600] Loss: 0.0858 MAE: 0.1837 Mean Error: -0.0010 STD: 0.2929\n",
      "[50/600] Loss: 0.0645 MAE: 0.1426 Mean Error: -0.0017 STD: 0.2540\n",
      "[60/600] Loss: 0.0348 MAE: 0.0821 Mean Error: -0.0046 STD: 0.1864\n",
      "[70/600] Loss: 0.0140 MAE: 0.0344 Mean Error: 0.0006 STD: 0.1183\n",
      "[80/600] Loss: 0.0070 MAE: 0.0153 Mean Error: 0.0015 STD: 0.0836\n",
      "[90/600] Loss: 0.0050 MAE: 0.0085 Mean Error: 0.0009 STD: 0.0704\n",
      "[100/600] Loss: 0.0047 MAE: 0.0064 Mean Error: 0.0009 STD: 0.0682\n",
      "[110/600] Loss: 0.0044 MAE: 0.0058 Mean Error: 0.0007 STD: 0.0661\n",
      "[120/600] Loss: 0.0041 MAE: 0.0052 Mean Error: 0.0009 STD: 0.0642\n",
      "[130/600] Loss: 0.0040 MAE: 0.0050 Mean Error: 0.0009 STD: 0.0635\n",
      "[140/600] Loss: 0.0040 MAE: 0.0048 Mean Error: 0.0009 STD: 0.0634\n",
      "[150/600] Loss: 0.0040 MAE: 0.0047 Mean Error: 0.0009 STD: 0.0633\n",
      "[160/600] Loss: 0.0040 MAE: 0.0047 Mean Error: 0.0009 STD: 0.0633\n",
      "[170/600] Loss: 0.0039 MAE: 0.0046 Mean Error: 0.0008 STD: 0.0626\n",
      "[180/600] Loss: 0.0039 MAE: 0.0045 Mean Error: 0.0008 STD: 0.0625\n",
      "[190/600] Loss: 0.0039 MAE: 0.0045 Mean Error: 0.0008 STD: 0.0625\n",
      "[200/600] Loss: 0.0039 MAE: 0.0045 Mean Error: 0.0008 STD: 0.0625\n",
      "[210/600] Loss: 0.0039 MAE: 0.0044 Mean Error: 0.0008 STD: 0.0625\n",
      "[220/600] Loss: 0.0039 MAE: 0.0044 Mean Error: 0.0008 STD: 0.0625\n",
      "[230/600] Loss: 0.0039 MAE: 0.0044 Mean Error: 0.0008 STD: 0.0625\n",
      "[240/600] Loss: 0.0039 MAE: 0.0044 Mean Error: 0.0008 STD: 0.0625\n",
      "[250/600] Loss: 0.0038 MAE: 0.0044 Mean Error: 0.0009 STD: 0.0618\n",
      "[260/600] Loss: 0.0038 MAE: 0.0043 Mean Error: 0.0009 STD: 0.0617\n",
      "[270/600] Loss: 0.0038 MAE: 0.0043 Mean Error: 0.0009 STD: 0.0617\n",
      "[280/600] Loss: 0.0038 MAE: 0.0042 Mean Error: 0.0009 STD: 0.0617\n",
      "[290/600] Loss: 0.0038 MAE: 0.0042 Mean Error: 0.0009 STD: 0.0617\n",
      "[300/600] Loss: 0.0038 MAE: 0.0042 Mean Error: 0.0009 STD: 0.0617\n",
      "[310/600] Loss: 0.0038 MAE: 0.0042 Mean Error: 0.0009 STD: 0.0617\n",
      "[320/600] Loss: 0.0037 MAE: 0.0041 Mean Error: 0.0009 STD: 0.0611\n",
      "[330/600] Loss: 0.0037 MAE: 0.0041 Mean Error: 0.0010 STD: 0.0609\n",
      "[340/600] Loss: 0.0037 MAE: 0.0041 Mean Error: 0.0010 STD: 0.0609\n",
      "[350/600] Loss: 0.0037 MAE: 0.0041 Mean Error: 0.0010 STD: 0.0609\n",
      "[360/600] Loss: 0.0037 MAE: 0.0041 Mean Error: 0.0010 STD: 0.0609\n",
      "[370/600] Loss: 0.0037 MAE: 0.0041 Mean Error: 0.0010 STD: 0.0609\n",
      "[380/600] Loss: 0.0037 MAE: 0.0040 Mean Error: 0.0010 STD: 0.0609\n",
      "[390/600] Loss: 0.0037 MAE: 0.0040 Mean Error: 0.0010 STD: 0.0609\n",
      "[400/600] Loss: 0.0037 MAE: 0.0040 Mean Error: 0.0010 STD: 0.0609\n",
      "[410/600] Loss: 0.0037 MAE: 0.0040 Mean Error: 0.0010 STD: 0.0609\n",
      "[420/600] Loss: 0.0037 MAE: 0.0040 Mean Error: 0.0010 STD: 0.0609\n",
      "[430/600] Loss: 0.0037 MAE: 0.0040 Mean Error: 0.0010 STD: 0.0609\n",
      "[440/600] Loss: 0.0037 MAE: 0.0040 Mean Error: 0.0010 STD: 0.0609\n",
      "[450/600] Loss: 0.0037 MAE: 0.0040 Mean Error: 0.0010 STD: 0.0609\n",
      "[460/600] Loss: 0.0037 MAE: 0.0040 Mean Error: 0.0010 STD: 0.0609\n",
      "[470/600] Loss: 0.0037 MAE: 0.0040 Mean Error: 0.0010 STD: 0.0609\n",
      "[480/600] Loss: 0.0037 MAE: 0.0040 Mean Error: 0.0010 STD: 0.0609\n",
      "[490/600] Loss: 0.0037 MAE: 0.0040 Mean Error: 0.0010 STD: 0.0609\n",
      "[500/600] Loss: 0.0037 MAE: 0.0040 Mean Error: 0.0010 STD: 0.0609\n",
      "[510/600] Loss: 0.0037 MAE: 0.0040 Mean Error: 0.0010 STD: 0.0609\n",
      "[520/600] Loss: 0.0037 MAE: 0.0040 Mean Error: 0.0010 STD: 0.0609\n",
      "[530/600] Loss: 0.0037 MAE: 0.0040 Mean Error: 0.0010 STD: 0.0609\n",
      "[540/600] Loss: 0.0037 MAE: 0.0040 Mean Error: 0.0010 STD: 0.0609\n",
      "[550/600] Loss: 0.0037 MAE: 0.0040 Mean Error: 0.0010 STD: 0.0609\n",
      "[560/600] Loss: 0.0037 MAE: 0.0040 Mean Error: 0.0010 STD: 0.0609\n",
      "[570/600] Loss: 0.0037 MAE: 0.0040 Mean Error: 0.0010 STD: 0.0609\n",
      "[580/600] Loss: 0.0037 MAE: 0.0039 Mean Error: 0.0010 STD: 0.0609\n",
      "[590/600] Loss: 0.0037 MAE: 0.0039 Mean Error: 0.0010 STD: 0.0609\n",
      "[599/600] Loss: 0.0037 MAE: 0.0039 Mean Error: 0.0010 STD: 0.0609\n",
      "------------------------------------\n",
      "Training dataset with noise standard deviation 0.002\n",
      "[0/600] Loss: 0.2500 MAE: 0.4999 Mean Error: 0.0942 STD: 0.4911\n",
      "[10/600] Loss: 0.1401 MAE: 0.2110 Mean Error: 0.0085 STD: 0.3742\n",
      "[20/600] Loss: 0.1257 MAE: 0.2595 Mean Error: 0.0053 STD: 0.3545\n",
      "[30/600] Loss: 0.1132 MAE: 0.2423 Mean Error: 0.0014 STD: 0.3364\n",
      "[40/600] Loss: 0.0923 MAE: 0.1855 Mean Error: -0.0045 STD: 0.3038\n",
      "[50/600] Loss: 0.0761 MAE: 0.1623 Mean Error: -0.0058 STD: 0.2759\n",
      "[60/600] Loss: 0.0515 MAE: 0.1109 Mean Error: 0.0021 STD: 0.2270\n",
      "[70/600] Loss: 0.0316 MAE: 0.0685 Mean Error: -0.0007 STD: 0.1778\n",
      "[80/600] Loss: 0.0180 MAE: 0.0375 Mean Error: -0.0019 STD: 0.1341\n",
      "[90/600] Loss: 0.0111 MAE: 0.0198 Mean Error: -0.0009 STD: 0.1056\n",
      "[100/600] Loss: 0.0092 MAE: 0.0131 Mean Error: -0.0004 STD: 0.0959\n",
      "[110/600] Loss: 0.0086 MAE: 0.0107 Mean Error: -0.0005 STD: 0.0928\n",
      "[120/600] Loss: 0.0084 MAE: 0.0098 Mean Error: -0.0004 STD: 0.0918\n",
      "[130/600] Loss: 0.0082 MAE: 0.0095 Mean Error: -0.0008 STD: 0.0907\n",
      "[140/600] Loss: 0.0079 MAE: 0.0091 Mean Error: -0.0006 STD: 0.0891\n",
      "[150/600] Loss: 0.0079 MAE: 0.0089 Mean Error: -0.0008 STD: 0.0888\n",
      "[160/600] Loss: 0.0078 MAE: 0.0086 Mean Error: -0.0008 STD: 0.0884\n",
      "[170/600] Loss: 0.0077 MAE: 0.0085 Mean Error: -0.0007 STD: 0.0879\n",
      "[180/600] Loss: 0.0076 MAE: 0.0084 Mean Error: -0.0008 STD: 0.0873\n",
      "[190/600] Loss: 0.0076 MAE: 0.0082 Mean Error: -0.0008 STD: 0.0873\n",
      "[200/600] Loss: 0.0076 MAE: 0.0082 Mean Error: -0.0008 STD: 0.0873\n",
      "[210/600] Loss: 0.0075 MAE: 0.0081 Mean Error: -0.0010 STD: 0.0868\n",
      "[220/600] Loss: 0.0075 MAE: 0.0081 Mean Error: -0.0008 STD: 0.0867\n",
      "[230/600] Loss: 0.0073 MAE: 0.0079 Mean Error: -0.0008 STD: 0.0857\n",
      "[240/600] Loss: 0.0073 MAE: 0.0078 Mean Error: -0.0009 STD: 0.0856\n",
      "[250/600] Loss: 0.0073 MAE: 0.0078 Mean Error: -0.0009 STD: 0.0856\n",
      "[260/600] Loss: 0.0072 MAE: 0.0077 Mean Error: -0.0010 STD: 0.0850\n",
      "[270/600] Loss: 0.0072 MAE: 0.0077 Mean Error: -0.0010 STD: 0.0850\n",
      "[280/600] Loss: 0.0072 MAE: 0.0076 Mean Error: -0.0010 STD: 0.0850\n",
      "[290/600] Loss: 0.0071 MAE: 0.0075 Mean Error: -0.0009 STD: 0.0845\n",
      "[300/600] Loss: 0.0071 MAE: 0.0076 Mean Error: -0.0011 STD: 0.0844\n",
      "[310/600] Loss: 0.0070 MAE: 0.0075 Mean Error: -0.0010 STD: 0.0834\n",
      "[320/600] Loss: 0.0069 MAE: 0.0074 Mean Error: -0.0011 STD: 0.0833\n",
      "[330/600] Loss: 0.0068 MAE: 0.0073 Mean Error: -0.0012 STD: 0.0827\n",
      "[340/600] Loss: 0.0068 MAE: 0.0072 Mean Error: -0.0012 STD: 0.0827\n",
      "[350/600] Loss: 0.0068 MAE: 0.0072 Mean Error: -0.0012 STD: 0.0827\n",
      "[360/600] Loss: 0.0068 MAE: 0.0071 Mean Error: -0.0012 STD: 0.0827\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[370/600] Loss: 0.0068 MAE: 0.0071 Mean Error: -0.0012 STD: 0.0827\n",
      "[380/600] Loss: 0.0068 MAE: 0.0071 Mean Error: -0.0012 STD: 0.0827\n",
      "[390/600] Loss: 0.0068 MAE: 0.0071 Mean Error: -0.0012 STD: 0.0827\n",
      "[400/600] Loss: 0.0068 MAE: 0.0071 Mean Error: -0.0012 STD: 0.0827\n",
      "[410/600] Loss: 0.0068 MAE: 0.0071 Mean Error: -0.0012 STD: 0.0827\n",
      "[420/600] Loss: 0.0068 MAE: 0.0071 Mean Error: -0.0012 STD: 0.0827\n",
      "[430/600] Loss: 0.0068 MAE: 0.0071 Mean Error: -0.0012 STD: 0.0827\n",
      "[440/600] Loss: 0.0068 MAE: 0.0071 Mean Error: -0.0012 STD: 0.0827\n",
      "[450/600] Loss: 0.0068 MAE: 0.0071 Mean Error: -0.0012 STD: 0.0827\n",
      "[460/600] Loss: 0.0068 MAE: 0.0071 Mean Error: -0.0012 STD: 0.0827\n",
      "[470/600] Loss: 0.0068 MAE: 0.0071 Mean Error: -0.0012 STD: 0.0827\n",
      "[480/600] Loss: 0.0068 MAE: 0.0071 Mean Error: -0.0012 STD: 0.0827\n",
      "[490/600] Loss: 0.0068 MAE: 0.0071 Mean Error: -0.0012 STD: 0.0827\n",
      "[500/600] Loss: 0.0068 MAE: 0.0071 Mean Error: -0.0010 STD: 0.0826\n",
      "[510/600] Loss: 0.0067 MAE: 0.0070 Mean Error: -0.0011 STD: 0.0821\n",
      "[520/600] Loss: 0.0067 MAE: 0.0070 Mean Error: -0.0011 STD: 0.0821\n",
      "[530/600] Loss: 0.0067 MAE: 0.0070 Mean Error: -0.0011 STD: 0.0821\n",
      "[540/600] Loss: 0.0067 MAE: 0.0070 Mean Error: -0.0011 STD: 0.0821\n",
      "[550/600] Loss: 0.0067 MAE: 0.0070 Mean Error: -0.0011 STD: 0.0821\n",
      "[560/600] Loss: 0.0067 MAE: 0.0069 Mean Error: -0.0011 STD: 0.0821\n",
      "[570/600] Loss: 0.0067 MAE: 0.0069 Mean Error: -0.0011 STD: 0.0821\n",
      "[580/600] Loss: 0.0067 MAE: 0.0069 Mean Error: -0.0011 STD: 0.0821\n",
      "[590/600] Loss: 0.0067 MAE: 0.0069 Mean Error: -0.0009 STD: 0.0815\n",
      "[599/600] Loss: 0.0066 MAE: 0.0069 Mean Error: -0.0010 STD: 0.0815\n",
      "------------------------------------\n",
      "Training dataset with noise standard deviation 0.003\n",
      "[0/600] Loss: 0.2503 MAE: 0.5002 Mean Error: 0.0939 STD: 0.4914\n",
      "[10/600] Loss: 0.1416 MAE: 0.2093 Mean Error: 0.0120 STD: 0.3762\n",
      "[20/600] Loss: 0.1251 MAE: 0.2577 Mean Error: 0.0040 STD: 0.3538\n",
      "[30/600] Loss: 0.1089 MAE: 0.2333 Mean Error: 0.0057 STD: 0.3300\n",
      "[40/600] Loss: 0.0915 MAE: 0.1870 Mean Error: -0.0033 STD: 0.3025\n",
      "[50/600] Loss: 0.0768 MAE: 0.1615 Mean Error: -0.0005 STD: 0.2772\n",
      "[60/600] Loss: 0.0486 MAE: 0.1114 Mean Error: -0.0008 STD: 0.2205\n",
      "[70/600] Loss: 0.0235 MAE: 0.0531 Mean Error: -0.0025 STD: 0.1534\n",
      "[80/600] Loss: 0.0131 MAE: 0.0269 Mean Error: -0.0010 STD: 0.1145\n",
      "[90/600] Loss: 0.0093 MAE: 0.0160 Mean Error: -0.0006 STD: 0.0964\n",
      "[100/600] Loss: 0.0082 MAE: 0.0113 Mean Error: -0.0006 STD: 0.0905\n",
      "[110/600] Loss: 0.0079 MAE: 0.0098 Mean Error: -0.0008 STD: 0.0888\n",
      "[120/600] Loss: 0.0077 MAE: 0.0092 Mean Error: -0.0008 STD: 0.0880\n",
      "[130/600] Loss: 0.0076 MAE: 0.0088 Mean Error: -0.0008 STD: 0.0870\n",
      "[140/600] Loss: 0.0075 MAE: 0.0086 Mean Error: -0.0007 STD: 0.0868\n",
      "[150/600] Loss: 0.0075 MAE: 0.0084 Mean Error: -0.0007 STD: 0.0868\n",
      "[160/600] Loss: 0.0075 MAE: 0.0083 Mean Error: -0.0007 STD: 0.0868\n",
      "[170/600] Loss: 0.0075 MAE: 0.0083 Mean Error: -0.0006 STD: 0.0865\n",
      "[180/600] Loss: 0.0074 MAE: 0.0082 Mean Error: -0.0005 STD: 0.0862\n",
      "[190/600] Loss: 0.0074 MAE: 0.0082 Mean Error: -0.0006 STD: 0.0862\n",
      "[200/600] Loss: 0.0074 MAE: 0.0081 Mean Error: -0.0006 STD: 0.0862\n",
      "[210/600] Loss: 0.0074 MAE: 0.0081 Mean Error: -0.0006 STD: 0.0862\n",
      "[220/600] Loss: 0.0074 MAE: 0.0080 Mean Error: -0.0006 STD: 0.0862\n",
      "[230/600] Loss: 0.0074 MAE: 0.0080 Mean Error: -0.0006 STD: 0.0861\n",
      "[240/600] Loss: 0.0073 MAE: 0.0080 Mean Error: -0.0005 STD: 0.0857\n",
      "[250/600] Loss: 0.0073 MAE: 0.0079 Mean Error: -0.0005 STD: 0.0856\n",
      "[260/600] Loss: 0.0073 MAE: 0.0079 Mean Error: -0.0005 STD: 0.0856\n",
      "[270/600] Loss: 0.0072 MAE: 0.0078 Mean Error: -0.0007 STD: 0.0851\n",
      "[280/600] Loss: 0.0072 MAE: 0.0078 Mean Error: -0.0006 STD: 0.0850\n",
      "[290/600] Loss: 0.0072 MAE: 0.0077 Mean Error: -0.0006 STD: 0.0850\n",
      "[300/600] Loss: 0.0072 MAE: 0.0077 Mean Error: -0.0006 STD: 0.0850\n",
      "[310/600] Loss: 0.0072 MAE: 0.0077 Mean Error: -0.0006 STD: 0.0850\n",
      "[320/600] Loss: 0.0072 MAE: 0.0077 Mean Error: -0.0006 STD: 0.0850\n",
      "[330/600] Loss: 0.0071 MAE: 0.0076 Mean Error: -0.0007 STD: 0.0845\n",
      "[340/600] Loss: 0.0071 MAE: 0.0076 Mean Error: -0.0006 STD: 0.0845\n",
      "[350/600] Loss: 0.0071 MAE: 0.0076 Mean Error: -0.0007 STD: 0.0845\n",
      "[360/600] Loss: 0.0071 MAE: 0.0075 Mean Error: -0.0007 STD: 0.0844\n",
      "[370/600] Loss: 0.0071 MAE: 0.0075 Mean Error: -0.0007 STD: 0.0844\n",
      "[380/600] Loss: 0.0071 MAE: 0.0075 Mean Error: -0.0007 STD: 0.0844\n",
      "[390/600] Loss: 0.0071 MAE: 0.0075 Mean Error: -0.0007 STD: 0.0844\n",
      "[400/600] Loss: 0.0071 MAE: 0.0075 Mean Error: -0.0007 STD: 0.0844\n",
      "[410/600] Loss: 0.0071 MAE: 0.0075 Mean Error: -0.0007 STD: 0.0844\n",
      "[420/600] Loss: 0.0071 MAE: 0.0075 Mean Error: -0.0007 STD: 0.0844\n",
      "[430/600] Loss: 0.0071 MAE: 0.0075 Mean Error: -0.0007 STD: 0.0844\n",
      "[440/600] Loss: 0.0071 MAE: 0.0075 Mean Error: -0.0007 STD: 0.0844\n",
      "[450/600] Loss: 0.0071 MAE: 0.0074 Mean Error: -0.0007 STD: 0.0844\n",
      "[460/600] Loss: 0.0071 MAE: 0.0074 Mean Error: -0.0007 STD: 0.0844\n",
      "[470/600] Loss: 0.0071 MAE: 0.0074 Mean Error: -0.0007 STD: 0.0844\n",
      "[480/600] Loss: 0.0071 MAE: 0.0074 Mean Error: -0.0007 STD: 0.0844\n",
      "[490/600] Loss: 0.0071 MAE: 0.0074 Mean Error: -0.0007 STD: 0.0844\n",
      "[500/600] Loss: 0.0071 MAE: 0.0074 Mean Error: -0.0007 STD: 0.0844\n",
      "[510/600] Loss: 0.0071 MAE: 0.0074 Mean Error: -0.0007 STD: 0.0844\n",
      "[520/600] Loss: 0.0071 MAE: 0.0074 Mean Error: -0.0007 STD: 0.0844\n",
      "[530/600] Loss: 0.0071 MAE: 0.0074 Mean Error: -0.0007 STD: 0.0844\n",
      "[540/600] Loss: 0.0071 MAE: 0.0074 Mean Error: -0.0007 STD: 0.0844\n",
      "[550/600] Loss: 0.0071 MAE: 0.0074 Mean Error: -0.0007 STD: 0.0844\n",
      "[560/600] Loss: 0.0071 MAE: 0.0074 Mean Error: -0.0007 STD: 0.0844\n",
      "[570/600] Loss: 0.0070 MAE: 0.0073 Mean Error: -0.0008 STD: 0.0839\n",
      "[580/600] Loss: 0.0070 MAE: 0.0074 Mean Error: -0.0009 STD: 0.0839\n",
      "[590/600] Loss: 0.0070 MAE: 0.0074 Mean Error: -0.0008 STD: 0.0839\n",
      "[599/600] Loss: 0.0070 MAE: 0.0073 Mean Error: -0.0008 STD: 0.0839\n",
      "------------------------------------\n",
      "Training dataset with noise standard deviation 0.005\n",
      "[0/600] Loss: 0.2499 MAE: 0.4999 Mean Error: 0.0939 STD: 0.4911\n",
      "[10/600] Loss: 0.1413 MAE: 0.2083 Mean Error: 0.0088 STD: 0.3759\n",
      "[20/600] Loss: 0.1254 MAE: 0.2467 Mean Error: 0.0011 STD: 0.3542\n",
      "[30/600] Loss: 0.1096 MAE: 0.2311 Mean Error: 0.0033 STD: 0.3310\n",
      "[40/600] Loss: 0.0880 MAE: 0.1775 Mean Error: -0.0040 STD: 0.2966\n",
      "[50/600] Loss: 0.0645 MAE: 0.1426 Mean Error: -0.0015 STD: 0.2539\n",
      "[60/600] Loss: 0.0393 MAE: 0.0899 Mean Error: 0.0015 STD: 0.1982\n",
      "[70/600] Loss: 0.0144 MAE: 0.0388 Mean Error: -0.0015 STD: 0.1198\n",
      "[80/600] Loss: 0.0052 MAE: 0.0128 Mean Error: -0.0003 STD: 0.0721\n",
      "[90/600] Loss: 0.0037 MAE: 0.0062 Mean Error: -0.0003 STD: 0.0605\n",
      "[100/600] Loss: 0.0034 MAE: 0.0047 Mean Error: -0.0003 STD: 0.0583\n",
      "[110/600] Loss: 0.0033 MAE: 0.0041 Mean Error: -0.0003 STD: 0.0577\n",
      "[120/600] Loss: 0.0033 MAE: 0.0039 Mean Error: -0.0002 STD: 0.0575\n",
      "[130/600] Loss: 0.0031 MAE: 0.0037 Mean Error: -0.0003 STD: 0.0560\n",
      "[140/600] Loss: 0.0031 MAE: 0.0037 Mean Error: -0.0002 STD: 0.0560\n",
      "[150/600] Loss: 0.0031 MAE: 0.0036 Mean Error: -0.0002 STD: 0.0559\n",
      "[160/600] Loss: 0.0031 MAE: 0.0036 Mean Error: -0.0002 STD: 0.0559\n",
      "[170/600] Loss: 0.0031 MAE: 0.0035 Mean Error: -0.0002 STD: 0.0559\n",
      "[180/600] Loss: 0.0030 MAE: 0.0035 Mean Error: -0.0001 STD: 0.0545\n",
      "[190/600] Loss: 0.0029 MAE: 0.0034 Mean Error: -0.0002 STD: 0.0542\n",
      "[200/600] Loss: 0.0029 MAE: 0.0033 Mean Error: -0.0002 STD: 0.0542\n",
      "[210/600] Loss: 0.0029 MAE: 0.0033 Mean Error: -0.0002 STD: 0.0541\n",
      "[220/600] Loss: 0.0029 MAE: 0.0033 Mean Error: -0.0003 STD: 0.0539\n",
      "[230/600] Loss: 0.0028 MAE: 0.0033 Mean Error: -0.0004 STD: 0.0532\n",
      "[240/600] Loss: 0.0027 MAE: 0.0032 Mean Error: -0.0004 STD: 0.0524\n",
      "[250/600] Loss: 0.0027 MAE: 0.0031 Mean Error: -0.0004 STD: 0.0523\n",
      "[260/600] Loss: 0.0027 MAE: 0.0031 Mean Error: -0.0004 STD: 0.0523\n",
      "[270/600] Loss: 0.0027 MAE: 0.0031 Mean Error: -0.0004 STD: 0.0523\n",
      "[280/600] Loss: 0.0027 MAE: 0.0031 Mean Error: -0.0004 STD: 0.0523\n",
      "[290/600] Loss: 0.0027 MAE: 0.0030 Mean Error: -0.0004 STD: 0.0523\n",
      "[300/600] Loss: 0.0027 MAE: 0.0030 Mean Error: -0.0004 STD: 0.0523\n",
      "[310/600] Loss: 0.0027 MAE: 0.0030 Mean Error: -0.0004 STD: 0.0523\n",
      "[320/600] Loss: 0.0027 MAE: 0.0030 Mean Error: -0.0004 STD: 0.0523\n",
      "[330/600] Loss: 0.0027 MAE: 0.0030 Mean Error: -0.0004 STD: 0.0523\n",
      "[340/600] Loss: 0.0027 MAE: 0.0030 Mean Error: -0.0004 STD: 0.0523\n",
      "[350/600] Loss: 0.0027 MAE: 0.0030 Mean Error: -0.0004 STD: 0.0523\n",
      "[360/600] Loss: 0.0027 MAE: 0.0030 Mean Error: -0.0004 STD: 0.0523\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[370/600] Loss: 0.0027 MAE: 0.0030 Mean Error: -0.0004 STD: 0.0523\n",
      "[380/600] Loss: 0.0027 MAE: 0.0030 Mean Error: -0.0004 STD: 0.0523\n",
      "[390/600] Loss: 0.0027 MAE: 0.0030 Mean Error: -0.0004 STD: 0.0523\n",
      "[400/600] Loss: 0.0027 MAE: 0.0030 Mean Error: -0.0004 STD: 0.0523\n",
      "[410/600] Loss: 0.0027 MAE: 0.0030 Mean Error: -0.0004 STD: 0.0523\n",
      "[420/600] Loss: 0.0027 MAE: 0.0030 Mean Error: -0.0004 STD: 0.0523\n",
      "[430/600] Loss: 0.0027 MAE: 0.0030 Mean Error: -0.0004 STD: 0.0523\n",
      "[440/600] Loss: 0.0027 MAE: 0.0030 Mean Error: -0.0004 STD: 0.0523\n",
      "[450/600] Loss: 0.0027 MAE: 0.0030 Mean Error: -0.0004 STD: 0.0523\n",
      "[460/600] Loss: 0.0027 MAE: 0.0030 Mean Error: -0.0004 STD: 0.0523\n",
      "[470/600] Loss: 0.0027 MAE: 0.0029 Mean Error: -0.0004 STD: 0.0523\n",
      "[480/600] Loss: 0.0027 MAE: 0.0029 Mean Error: -0.0004 STD: 0.0523\n",
      "[490/600] Loss: 0.0027 MAE: 0.0029 Mean Error: -0.0004 STD: 0.0523\n",
      "[500/600] Loss: 0.0027 MAE: 0.0029 Mean Error: -0.0004 STD: 0.0523\n",
      "[510/600] Loss: 0.0027 MAE: 0.0029 Mean Error: -0.0004 STD: 0.0523\n",
      "[520/600] Loss: 0.0026 MAE: 0.0029 Mean Error: -0.0005 STD: 0.0514\n",
      "[530/600] Loss: 0.0026 MAE: 0.0029 Mean Error: -0.0005 STD: 0.0514\n",
      "[540/600] Loss: 0.0026 MAE: 0.0029 Mean Error: -0.0005 STD: 0.0514\n",
      "[550/600] Loss: 0.0026 MAE: 0.0029 Mean Error: -0.0005 STD: 0.0514\n",
      "[560/600] Loss: 0.0026 MAE: 0.0029 Mean Error: -0.0005 STD: 0.0514\n",
      "[570/600] Loss: 0.0026 MAE: 0.0029 Mean Error: -0.0005 STD: 0.0514\n",
      "[580/600] Loss: 0.0026 MAE: 0.0028 Mean Error: -0.0005 STD: 0.0514\n",
      "[590/600] Loss: 0.0026 MAE: 0.0028 Mean Error: -0.0005 STD: 0.0514\n",
      "[599/600] Loss: 0.0026 MAE: 0.0028 Mean Error: -0.0005 STD: 0.0514\n",
      "------------------------------------\n",
      "Training dataset with noise standard deviation 0.01\n",
      "[0/600] Loss: 0.2501 MAE: 0.5000 Mean Error: 0.0940 STD: 0.4912\n",
      "[10/600] Loss: 0.1405 MAE: 0.2080 Mean Error: 0.0109 STD: 0.3747\n",
      "[20/600] Loss: 0.1244 MAE: 0.2530 Mean Error: 0.0059 STD: 0.3526\n",
      "[30/600] Loss: 0.1034 MAE: 0.2176 Mean Error: 0.0041 STD: 0.3215\n",
      "[40/600] Loss: 0.0855 MAE: 0.1769 Mean Error: -0.0019 STD: 0.2924\n",
      "[50/600] Loss: 0.0643 MAE: 0.1411 Mean Error: -0.0060 STD: 0.2535\n",
      "[60/600] Loss: 0.0346 MAE: 0.0813 Mean Error: -0.0036 STD: 0.1859\n",
      "[70/600] Loss: 0.0139 MAE: 0.0348 Mean Error: 0.0003 STD: 0.1178\n",
      "[80/600] Loss: 0.0065 MAE: 0.0136 Mean Error: -0.0007 STD: 0.0804\n",
      "[90/600] Loss: 0.0052 MAE: 0.0076 Mean Error: -0.0003 STD: 0.0721\n",
      "[100/600] Loss: 0.0049 MAE: 0.0061 Mean Error: -0.0002 STD: 0.0703\n",
      "[110/600] Loss: 0.0045 MAE: 0.0054 Mean Error: 0.0002 STD: 0.0674\n",
      "[120/600] Loss: 0.0044 MAE: 0.0052 Mean Error: 0.0001 STD: 0.0664\n",
      "[130/600] Loss: 0.0044 MAE: 0.0050 Mean Error: 0.0001 STD: 0.0663\n",
      "[140/600] Loss: 0.0044 MAE: 0.0050 Mean Error: 0.0001 STD: 0.0663\n",
      "[150/600] Loss: 0.0044 MAE: 0.0049 Mean Error: 0.0001 STD: 0.0663\n",
      "[160/600] Loss: 0.0044 MAE: 0.0049 Mean Error: 0.0001 STD: 0.0663\n",
      "[170/600] Loss: 0.0043 MAE: 0.0048 Mean Error: -0.0001 STD: 0.0656\n",
      "[180/600] Loss: 0.0043 MAE: 0.0048 Mean Error: -0.0000 STD: 0.0656\n",
      "[190/600] Loss: 0.0043 MAE: 0.0047 Mean Error: -0.0000 STD: 0.0656\n",
      "[200/600] Loss: 0.0043 MAE: 0.0047 Mean Error: -0.0000 STD: 0.0656\n",
      "[210/600] Loss: 0.0042 MAE: 0.0046 Mean Error: -0.0001 STD: 0.0649\n",
      "[220/600] Loss: 0.0042 MAE: 0.0046 Mean Error: -0.0001 STD: 0.0648\n",
      "[230/600] Loss: 0.0042 MAE: 0.0046 Mean Error: -0.0001 STD: 0.0648\n",
      "[240/600] Loss: 0.0042 MAE: 0.0046 Mean Error: -0.0001 STD: 0.0648\n",
      "[250/600] Loss: 0.0042 MAE: 0.0046 Mean Error: -0.0001 STD: 0.0648\n",
      "[260/600] Loss: 0.0042 MAE: 0.0045 Mean Error: -0.0001 STD: 0.0648\n",
      "[270/600] Loss: 0.0042 MAE: 0.0045 Mean Error: -0.0001 STD: 0.0648\n",
      "[280/600] Loss: 0.0042 MAE: 0.0045 Mean Error: -0.0001 STD: 0.0648\n",
      "[290/600] Loss: 0.0042 MAE: 0.0045 Mean Error: -0.0001 STD: 0.0648\n",
      "[300/600] Loss: 0.0042 MAE: 0.0045 Mean Error: -0.0001 STD: 0.0648\n",
      "[310/600] Loss: 0.0042 MAE: 0.0045 Mean Error: -0.0001 STD: 0.0648\n",
      "[320/600] Loss: 0.0042 MAE: 0.0045 Mean Error: -0.0001 STD: 0.0648\n",
      "[330/600] Loss: 0.0042 MAE: 0.0045 Mean Error: -0.0001 STD: 0.0648\n",
      "[340/600] Loss: 0.0042 MAE: 0.0045 Mean Error: -0.0001 STD: 0.0648\n",
      "[350/600] Loss: 0.0042 MAE: 0.0045 Mean Error: -0.0001 STD: 0.0648\n",
      "[360/600] Loss: 0.0042 MAE: 0.0045 Mean Error: -0.0001 STD: 0.0648\n",
      "[370/600] Loss: 0.0042 MAE: 0.0045 Mean Error: -0.0001 STD: 0.0648\n",
      "[380/600] Loss: 0.0042 MAE: 0.0045 Mean Error: -0.0001 STD: 0.0648\n",
      "[390/600] Loss: 0.0042 MAE: 0.0045 Mean Error: -0.0001 STD: 0.0648\n",
      "[400/600] Loss: 0.0042 MAE: 0.0045 Mean Error: -0.0001 STD: 0.0648\n",
      "[410/600] Loss: 0.0042 MAE: 0.0045 Mean Error: -0.0001 STD: 0.0648\n",
      "[420/600] Loss: 0.0042 MAE: 0.0045 Mean Error: -0.0001 STD: 0.0648\n",
      "[430/600] Loss: 0.0041 MAE: 0.0044 Mean Error: 0.0000 STD: 0.0641\n",
      "[440/600] Loss: 0.0041 MAE: 0.0045 Mean Error: -0.0001 STD: 0.0641\n",
      "[450/600] Loss: 0.0041 MAE: 0.0044 Mean Error: -0.0000 STD: 0.0641\n",
      "[460/600] Loss: 0.0041 MAE: 0.0044 Mean Error: -0.0000 STD: 0.0641\n",
      "[470/600] Loss: 0.0041 MAE: 0.0044 Mean Error: -0.0000 STD: 0.0641\n",
      "[480/600] Loss: 0.0041 MAE: 0.0044 Mean Error: -0.0000 STD: 0.0641\n",
      "[490/600] Loss: 0.0041 MAE: 0.0043 Mean Error: -0.0000 STD: 0.0641\n",
      "[500/600] Loss: 0.0041 MAE: 0.0043 Mean Error: -0.0000 STD: 0.0641\n",
      "[510/600] Loss: 0.0041 MAE: 0.0043 Mean Error: -0.0000 STD: 0.0641\n",
      "[520/600] Loss: 0.0041 MAE: 0.0043 Mean Error: -0.0000 STD: 0.0641\n",
      "[530/600] Loss: 0.0041 MAE: 0.0043 Mean Error: -0.0000 STD: 0.0641\n",
      "[540/600] Loss: 0.0041 MAE: 0.0043 Mean Error: -0.0000 STD: 0.0641\n",
      "[550/600] Loss: 0.0041 MAE: 0.0043 Mean Error: -0.0000 STD: 0.0640\n",
      "[560/600] Loss: 0.0041 MAE: 0.0044 Mean Error: 0.0000 STD: 0.0641\n",
      "[570/600] Loss: 0.0041 MAE: 0.0044 Mean Error: 0.0000 STD: 0.0641\n",
      "[580/600] Loss: 0.0041 MAE: 0.0044 Mean Error: -0.0000 STD: 0.0641\n",
      "[590/600] Loss: 0.0041 MAE: 0.0043 Mean Error: -0.0000 STD: 0.0641\n",
      "[599/600] Loss: 0.0041 MAE: 0.0043 Mean Error: -0.0000 STD: 0.0641\n",
      "------------------------------------\n",
      "Training dataset with noise standard deviation 0.02\n",
      "[0/600] Loss: 0.2503 MAE: 0.5003 Mean Error: 0.0945 STD: 0.4914\n",
      "[10/600] Loss: 0.1409 MAE: 0.2089 Mean Error: 0.0117 STD: 0.3752\n",
      "[20/600] Loss: 0.1249 MAE: 0.2541 Mean Error: 0.0066 STD: 0.3534\n",
      "[30/600] Loss: 0.1079 MAE: 0.2293 Mean Error: 0.0020 STD: 0.3285\n",
      "[40/600] Loss: 0.0875 MAE: 0.1803 Mean Error: -0.0019 STD: 0.2958\n",
      "[50/600] Loss: 0.0624 MAE: 0.1415 Mean Error: -0.0013 STD: 0.2498\n",
      "[60/600] Loss: 0.0283 MAE: 0.0691 Mean Error: -0.0037 STD: 0.1681\n",
      "[70/600] Loss: 0.0096 MAE: 0.0252 Mean Error: -0.0006 STD: 0.0981\n",
      "[80/600] Loss: 0.0052 MAE: 0.0102 Mean Error: -0.0005 STD: 0.0722\n",
      "[90/600] Loss: 0.0045 MAE: 0.0063 Mean Error: -0.0002 STD: 0.0668\n",
      "[100/600] Loss: 0.0043 MAE: 0.0053 Mean Error: 0.0002 STD: 0.0652\n",
      "[110/600] Loss: 0.0040 MAE: 0.0051 Mean Error: -0.0004 STD: 0.0629\n",
      "[120/600] Loss: 0.0038 MAE: 0.0047 Mean Error: -0.0004 STD: 0.0613\n",
      "[130/600] Loss: 0.0036 MAE: 0.0044 Mean Error: -0.0001 STD: 0.0602\n",
      "[140/600] Loss: 0.0036 MAE: 0.0043 Mean Error: -0.0001 STD: 0.0602\n",
      "[150/600] Loss: 0.0036 MAE: 0.0042 Mean Error: -0.0001 STD: 0.0601\n",
      "[160/600] Loss: 0.0035 MAE: 0.0041 Mean Error: -0.0002 STD: 0.0594\n",
      "[170/600] Loss: 0.0035 MAE: 0.0041 Mean Error: -0.0002 STD: 0.0593\n",
      "[180/600] Loss: 0.0035 MAE: 0.0040 Mean Error: -0.0002 STD: 0.0593\n",
      "[190/600] Loss: 0.0035 MAE: 0.0040 Mean Error: -0.0002 STD: 0.0593\n",
      "[200/600] Loss: 0.0035 MAE: 0.0040 Mean Error: -0.0002 STD: 0.0593\n",
      "[210/600] Loss: 0.0035 MAE: 0.0039 Mean Error: -0.0002 STD: 0.0593\n",
      "[220/600] Loss: 0.0035 MAE: 0.0039 Mean Error: -0.0002 STD: 0.0593\n",
      "[230/600] Loss: 0.0035 MAE: 0.0039 Mean Error: -0.0002 STD: 0.0593\n",
      "[240/600] Loss: 0.0034 MAE: 0.0038 Mean Error: -0.0001 STD: 0.0585\n",
      "[250/600] Loss: 0.0034 MAE: 0.0039 Mean Error: -0.0001 STD: 0.0585\n",
      "[260/600] Loss: 0.0033 MAE: 0.0038 Mean Error: -0.0003 STD: 0.0578\n",
      "[270/600] Loss: 0.0032 MAE: 0.0037 Mean Error: -0.0002 STD: 0.0569\n",
      "[280/600] Loss: 0.0032 MAE: 0.0037 Mean Error: -0.0001 STD: 0.0568\n",
      "[290/600] Loss: 0.0032 MAE: 0.0036 Mean Error: -0.0001 STD: 0.0568\n",
      "[300/600] Loss: 0.0032 MAE: 0.0036 Mean Error: -0.0001 STD: 0.0567\n",
      "[310/600] Loss: 0.0031 MAE: 0.0035 Mean Error: -0.0000 STD: 0.0559\n",
      "[320/600] Loss: 0.0031 MAE: 0.0035 Mean Error: -0.0000 STD: 0.0559\n",
      "[330/600] Loss: 0.0031 MAE: 0.0035 Mean Error: -0.0000 STD: 0.0559\n",
      "[340/600] Loss: 0.0031 MAE: 0.0034 Mean Error: 0.0000 STD: 0.0559\n",
      "[350/600] Loss: 0.0031 MAE: 0.0034 Mean Error: -0.0000 STD: 0.0559\n",
      "[360/600] Loss: 0.0031 MAE: 0.0034 Mean Error: -0.0000 STD: 0.0559\n",
      "[370/600] Loss: 0.0031 MAE: 0.0034 Mean Error: -0.0000 STD: 0.0559\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[380/600] Loss: 0.0031 MAE: 0.0034 Mean Error: -0.0000 STD: 0.0559\n",
      "[390/600] Loss: 0.0031 MAE: 0.0034 Mean Error: -0.0000 STD: 0.0559\n",
      "[400/600] Loss: 0.0031 MAE: 0.0034 Mean Error: -0.0000 STD: 0.0559\n",
      "[410/600] Loss: 0.0031 MAE: 0.0034 Mean Error: -0.0000 STD: 0.0559\n",
      "[420/600] Loss: 0.0031 MAE: 0.0034 Mean Error: -0.0000 STD: 0.0559\n",
      "[430/600] Loss: 0.0031 MAE: 0.0034 Mean Error: -0.0000 STD: 0.0559\n",
      "[440/600] Loss: 0.0031 MAE: 0.0034 Mean Error: -0.0000 STD: 0.0559\n",
      "[450/600] Loss: 0.0031 MAE: 0.0034 Mean Error: -0.0000 STD: 0.0559\n",
      "[460/600] Loss: 0.0031 MAE: 0.0034 Mean Error: -0.0000 STD: 0.0559\n",
      "[470/600] Loss: 0.0031 MAE: 0.0034 Mean Error: -0.0000 STD: 0.0559\n",
      "[480/600] Loss: 0.0031 MAE: 0.0034 Mean Error: -0.0000 STD: 0.0559\n",
      "[490/600] Loss: 0.0031 MAE: 0.0034 Mean Error: -0.0000 STD: 0.0559\n",
      "[500/600] Loss: 0.0031 MAE: 0.0034 Mean Error: -0.0000 STD: 0.0559\n",
      "[510/600] Loss: 0.0031 MAE: 0.0033 Mean Error: -0.0000 STD: 0.0559\n",
      "[520/600] Loss: 0.0031 MAE: 0.0033 Mean Error: -0.0000 STD: 0.0559\n",
      "[530/600] Loss: 0.0031 MAE: 0.0033 Mean Error: -0.0000 STD: 0.0559\n",
      "[540/600] Loss: 0.0031 MAE: 0.0033 Mean Error: -0.0000 STD: 0.0559\n",
      "[550/600] Loss: 0.0031 MAE: 0.0033 Mean Error: -0.0000 STD: 0.0559\n",
      "[560/600] Loss: 0.0031 MAE: 0.0033 Mean Error: -0.0000 STD: 0.0559\n",
      "[570/600] Loss: 0.0031 MAE: 0.0033 Mean Error: -0.0000 STD: 0.0559\n",
      "[580/600] Loss: 0.0031 MAE: 0.0033 Mean Error: -0.0000 STD: 0.0559\n",
      "[590/600] Loss: 0.0031 MAE: 0.0033 Mean Error: -0.0000 STD: 0.0559\n",
      "[599/600] Loss: 0.0031 MAE: 0.0033 Mean Error: -0.0000 STD: 0.0559\n",
      "------------------------------------\n",
      "Training dataset with noise standard deviation 0.03\n",
      "[0/600] Loss: 0.2499 MAE: 0.4998 Mean Error: 0.0940 STD: 0.4910\n",
      "[10/600] Loss: 0.1424 MAE: 0.2056 Mean Error: 0.0137 STD: 0.3771\n",
      "[20/600] Loss: 0.1255 MAE: 0.2509 Mean Error: 0.0052 STD: 0.3542\n",
      "[30/600] Loss: 0.1083 MAE: 0.2294 Mean Error: 0.0062 STD: 0.3290\n",
      "[40/600] Loss: 0.0892 MAE: 0.1791 Mean Error: 0.0002 STD: 0.2987\n",
      "[50/600] Loss: 0.0758 MAE: 0.1574 Mean Error: 0.0017 STD: 0.2753\n",
      "[60/600] Loss: 0.0587 MAE: 0.1303 Mean Error: 0.0036 STD: 0.2422\n",
      "[70/600] Loss: 0.0357 MAE: 0.0823 Mean Error: 0.0023 STD: 0.1889\n",
      "[80/600] Loss: 0.0178 MAE: 0.0451 Mean Error: 0.0003 STD: 0.1332\n",
      "[90/600] Loss: 0.0069 MAE: 0.0168 Mean Error: 0.0012 STD: 0.0830\n",
      "[100/600] Loss: 0.0048 MAE: 0.0083 Mean Error: 0.0004 STD: 0.0695\n",
      "[110/600] Loss: 0.0042 MAE: 0.0060 Mean Error: 0.0008 STD: 0.0647\n",
      "[120/600] Loss: 0.0040 MAE: 0.0051 Mean Error: 0.0008 STD: 0.0634\n",
      "[130/600] Loss: 0.0039 MAE: 0.0048 Mean Error: 0.0007 STD: 0.0627\n",
      "[140/600] Loss: 0.0038 MAE: 0.0046 Mean Error: 0.0007 STD: 0.0618\n",
      "[150/600] Loss: 0.0036 MAE: 0.0045 Mean Error: 0.0009 STD: 0.0604\n",
      "[160/600] Loss: 0.0036 MAE: 0.0044 Mean Error: 0.0009 STD: 0.0602\n",
      "[170/600] Loss: 0.0034 MAE: 0.0042 Mean Error: 0.0007 STD: 0.0586\n",
      "[180/600] Loss: 0.0034 MAE: 0.0041 Mean Error: 0.0005 STD: 0.0580\n",
      "[190/600] Loss: 0.0033 MAE: 0.0039 Mean Error: 0.0005 STD: 0.0577\n",
      "[200/600] Loss: 0.0033 MAE: 0.0039 Mean Error: 0.0006 STD: 0.0577\n",
      "[210/600] Loss: 0.0033 MAE: 0.0038 Mean Error: 0.0006 STD: 0.0577\n",
      "[220/600] Loss: 0.0033 MAE: 0.0038 Mean Error: 0.0006 STD: 0.0577\n",
      "[230/600] Loss: 0.0033 MAE: 0.0038 Mean Error: 0.0006 STD: 0.0576\n",
      "[240/600] Loss: 0.0033 MAE: 0.0038 Mean Error: 0.0006 STD: 0.0576\n",
      "[250/600] Loss: 0.0033 MAE: 0.0038 Mean Error: 0.0006 STD: 0.0576\n",
      "[260/600] Loss: 0.0033 MAE: 0.0037 Mean Error: 0.0006 STD: 0.0576\n",
      "[270/600] Loss: 0.0033 MAE: 0.0037 Mean Error: 0.0006 STD: 0.0576\n",
      "[280/600] Loss: 0.0033 MAE: 0.0037 Mean Error: 0.0006 STD: 0.0576\n",
      "[290/600] Loss: 0.0033 MAE: 0.0037 Mean Error: 0.0006 STD: 0.0576\n",
      "[300/600] Loss: 0.0033 MAE: 0.0037 Mean Error: 0.0006 STD: 0.0576\n",
      "[310/600] Loss: 0.0033 MAE: 0.0037 Mean Error: 0.0006 STD: 0.0576\n",
      "[320/600] Loss: 0.0033 MAE: 0.0037 Mean Error: 0.0006 STD: 0.0576\n",
      "[330/600] Loss: 0.0033 MAE: 0.0037 Mean Error: 0.0006 STD: 0.0576\n",
      "[340/600] Loss: 0.0033 MAE: 0.0037 Mean Error: 0.0006 STD: 0.0576\n",
      "[350/600] Loss: 0.0033 MAE: 0.0037 Mean Error: 0.0006 STD: 0.0576\n",
      "[360/600] Loss: 0.0033 MAE: 0.0037 Mean Error: 0.0006 STD: 0.0576\n",
      "[370/600] Loss: 0.0033 MAE: 0.0036 Mean Error: 0.0006 STD: 0.0576\n",
      "[380/600] Loss: 0.0033 MAE: 0.0036 Mean Error: 0.0006 STD: 0.0576\n",
      "[390/600] Loss: 0.0033 MAE: 0.0036 Mean Error: 0.0006 STD: 0.0576\n",
      "[400/600] Loss: 0.0033 MAE: 0.0036 Mean Error: 0.0006 STD: 0.0576\n",
      "[410/600] Loss: 0.0033 MAE: 0.0036 Mean Error: 0.0006 STD: 0.0576\n",
      "[420/600] Loss: 0.0033 MAE: 0.0036 Mean Error: 0.0006 STD: 0.0576\n",
      "[430/600] Loss: 0.0033 MAE: 0.0036 Mean Error: 0.0006 STD: 0.0576\n",
      "[440/600] Loss: 0.0033 MAE: 0.0036 Mean Error: 0.0006 STD: 0.0576\n",
      "[450/600] Loss: 0.0033 MAE: 0.0036 Mean Error: 0.0006 STD: 0.0576\n",
      "[460/600] Loss: 0.0033 MAE: 0.0036 Mean Error: 0.0006 STD: 0.0576\n",
      "[470/600] Loss: 0.0033 MAE: 0.0036 Mean Error: 0.0006 STD: 0.0576\n",
      "[480/600] Loss: 0.0033 MAE: 0.0037 Mean Error: 0.0005 STD: 0.0577\n",
      "[490/600] Loss: 0.0032 MAE: 0.0036 Mean Error: 0.0007 STD: 0.0568\n",
      "[500/600] Loss: 0.0032 MAE: 0.0035 Mean Error: 0.0007 STD: 0.0568\n",
      "[510/600] Loss: 0.0032 MAE: 0.0035 Mean Error: 0.0007 STD: 0.0568\n",
      "[520/600] Loss: 0.0032 MAE: 0.0035 Mean Error: 0.0007 STD: 0.0568\n",
      "[530/600] Loss: 0.0032 MAE: 0.0035 Mean Error: 0.0007 STD: 0.0568\n",
      "[540/600] Loss: 0.0032 MAE: 0.0035 Mean Error: 0.0007 STD: 0.0568\n",
      "[550/600] Loss: 0.0032 MAE: 0.0035 Mean Error: 0.0007 STD: 0.0568\n",
      "[560/600] Loss: 0.0032 MAE: 0.0035 Mean Error: 0.0007 STD: 0.0568\n",
      "[570/600] Loss: 0.0032 MAE: 0.0035 Mean Error: 0.0007 STD: 0.0568\n",
      "[580/600] Loss: 0.0032 MAE: 0.0035 Mean Error: 0.0007 STD: 0.0568\n",
      "[590/600] Loss: 0.0032 MAE: 0.0034 Mean Error: 0.0007 STD: 0.0568\n",
      "[599/600] Loss: 0.0032 MAE: 0.0034 Mean Error: 0.0007 STD: 0.0568\n",
      "------------------------------------\n",
      "Training dataset with noise standard deviation 0.05\n",
      "[0/600] Loss: 0.2501 MAE: 0.5000 Mean Error: 0.0939 STD: 0.4912\n",
      "[10/600] Loss: 0.1402 MAE: 0.2101 Mean Error: 0.0092 STD: 0.3743\n",
      "[20/600] Loss: 0.1239 MAE: 0.2539 Mean Error: 0.0027 STD: 0.3520\n",
      "[30/600] Loss: 0.1037 MAE: 0.2164 Mean Error: 0.0011 STD: 0.3221\n",
      "[40/600] Loss: 0.0862 MAE: 0.1811 Mean Error: -0.0020 STD: 0.2936\n",
      "[50/600] Loss: 0.0630 MAE: 0.1368 Mean Error: -0.0041 STD: 0.2510\n",
      "[60/600] Loss: 0.0357 MAE: 0.0819 Mean Error: -0.0052 STD: 0.1888\n",
      "[70/600] Loss: 0.0151 MAE: 0.0354 Mean Error: -0.0001 STD: 0.1228\n",
      "[80/600] Loss: 0.0082 MAE: 0.0154 Mean Error: -0.0009 STD: 0.0903\n",
      "[90/600] Loss: 0.0065 MAE: 0.0096 Mean Error: -0.0000 STD: 0.0806\n",
      "[100/600] Loss: 0.0059 MAE: 0.0075 Mean Error: 0.0002 STD: 0.0769\n",
      "[110/600] Loss: 0.0058 MAE: 0.0069 Mean Error: 0.0002 STD: 0.0762\n",
      "[120/600] Loss: 0.0058 MAE: 0.0066 Mean Error: 0.0003 STD: 0.0760\n",
      "[130/600] Loss: 0.0056 MAE: 0.0064 Mean Error: 0.0004 STD: 0.0748\n",
      "[140/600] Loss: 0.0055 MAE: 0.0062 Mean Error: 0.0006 STD: 0.0741\n",
      "[150/600] Loss: 0.0055 MAE: 0.0061 Mean Error: 0.0006 STD: 0.0740\n",
      "[160/600] Loss: 0.0054 MAE: 0.0060 Mean Error: 0.0007 STD: 0.0734\n",
      "[170/600] Loss: 0.0054 MAE: 0.0059 Mean Error: 0.0007 STD: 0.0733\n",
      "[180/600] Loss: 0.0054 MAE: 0.0059 Mean Error: 0.0007 STD: 0.0733\n",
      "[190/600] Loss: 0.0054 MAE: 0.0058 Mean Error: 0.0007 STD: 0.0733\n",
      "[200/600] Loss: 0.0054 MAE: 0.0058 Mean Error: 0.0007 STD: 0.0733\n",
      "[210/600] Loss: 0.0053 MAE: 0.0058 Mean Error: 0.0008 STD: 0.0727\n",
      "[220/600] Loss: 0.0052 MAE: 0.0057 Mean Error: 0.0008 STD: 0.0720\n",
      "[230/600] Loss: 0.0052 MAE: 0.0057 Mean Error: 0.0008 STD: 0.0720\n",
      "[240/600] Loss: 0.0052 MAE: 0.0056 Mean Error: 0.0009 STD: 0.0720\n",
      "[250/600] Loss: 0.0051 MAE: 0.0056 Mean Error: 0.0008 STD: 0.0714\n",
      "[260/600] Loss: 0.0051 MAE: 0.0056 Mean Error: 0.0008 STD: 0.0713\n",
      "[270/600] Loss: 0.0051 MAE: 0.0056 Mean Error: 0.0007 STD: 0.0713\n",
      "[280/600] Loss: 0.0050 MAE: 0.0055 Mean Error: 0.0009 STD: 0.0706\n",
      "[290/600] Loss: 0.0049 MAE: 0.0053 Mean Error: 0.0008 STD: 0.0699\n",
      "[300/600] Loss: 0.0049 MAE: 0.0053 Mean Error: 0.0008 STD: 0.0699\n",
      "[310/600] Loss: 0.0049 MAE: 0.0053 Mean Error: 0.0008 STD: 0.0699\n",
      "[320/600] Loss: 0.0048 MAE: 0.0052 Mean Error: 0.0009 STD: 0.0692\n",
      "[330/600] Loss: 0.0048 MAE: 0.0052 Mean Error: 0.0009 STD: 0.0692\n",
      "[340/600] Loss: 0.0048 MAE: 0.0051 Mean Error: 0.0009 STD: 0.0692\n",
      "[350/600] Loss: 0.0048 MAE: 0.0051 Mean Error: 0.0009 STD: 0.0692\n",
      "[360/600] Loss: 0.0048 MAE: 0.0051 Mean Error: 0.0009 STD: 0.0692\n",
      "[370/600] Loss: 0.0048 MAE: 0.0051 Mean Error: 0.0009 STD: 0.0692\n",
      "[380/600] Loss: 0.0048 MAE: 0.0051 Mean Error: 0.0009 STD: 0.0692\n",
      "[390/600] Loss: 0.0048 MAE: 0.0051 Mean Error: 0.0009 STD: 0.0692\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[400/600] Loss: 0.0048 MAE: 0.0051 Mean Error: 0.0009 STD: 0.0692\n",
      "[410/600] Loss: 0.0047 MAE: 0.0050 Mean Error: 0.0010 STD: 0.0685\n",
      "[420/600] Loss: 0.0047 MAE: 0.0050 Mean Error: 0.0010 STD: 0.0685\n",
      "[430/600] Loss: 0.0047 MAE: 0.0050 Mean Error: 0.0010 STD: 0.0685\n",
      "[440/600] Loss: 0.0047 MAE: 0.0050 Mean Error: 0.0010 STD: 0.0685\n",
      "[450/600] Loss: 0.0047 MAE: 0.0049 Mean Error: 0.0010 STD: 0.0685\n",
      "[460/600] Loss: 0.0047 MAE: 0.0049 Mean Error: 0.0010 STD: 0.0685\n",
      "[470/600] Loss: 0.0047 MAE: 0.0049 Mean Error: 0.0010 STD: 0.0685\n",
      "[480/600] Loss: 0.0047 MAE: 0.0049 Mean Error: 0.0010 STD: 0.0685\n",
      "[490/600] Loss: 0.0047 MAE: 0.0049 Mean Error: 0.0010 STD: 0.0685\n",
      "[500/600] Loss: 0.0047 MAE: 0.0049 Mean Error: 0.0010 STD: 0.0685\n",
      "[510/600] Loss: 0.0047 MAE: 0.0049 Mean Error: 0.0010 STD: 0.0685\n",
      "[520/600] Loss: 0.0046 MAE: 0.0049 Mean Error: 0.0010 STD: 0.0678\n",
      "[530/600] Loss: 0.0046 MAE: 0.0049 Mean Error: 0.0011 STD: 0.0678\n",
      "[540/600] Loss: 0.0046 MAE: 0.0048 Mean Error: 0.0011 STD: 0.0678\n",
      "[550/600] Loss: 0.0046 MAE: 0.0048 Mean Error: 0.0011 STD: 0.0677\n",
      "[560/600] Loss: 0.0046 MAE: 0.0048 Mean Error: 0.0011 STD: 0.0677\n",
      "[570/600] Loss: 0.0045 MAE: 0.0048 Mean Error: 0.0012 STD: 0.0670\n",
      "[580/600] Loss: 0.0045 MAE: 0.0048 Mean Error: 0.0012 STD: 0.0670\n",
      "[590/600] Loss: 0.0045 MAE: 0.0048 Mean Error: 0.0012 STD: 0.0670\n",
      "[599/600] Loss: 0.0045 MAE: 0.0047 Mean Error: 0.0012 STD: 0.0670\n",
      "------------------------------------\n",
      "Training dataset with noise standard deviation 0.1\n",
      "[0/600] Loss: 0.2501 MAE: 0.5000 Mean Error: 0.0942 STD: 0.4911\n",
      "[10/600] Loss: 0.1406 MAE: 0.2089 Mean Error: 0.0117 STD: 0.3749\n",
      "[20/600] Loss: 0.1252 MAE: 0.2551 Mean Error: 0.0054 STD: 0.3538\n",
      "[30/600] Loss: 0.1107 MAE: 0.2364 Mean Error: 0.0053 STD: 0.3327\n",
      "[40/600] Loss: 0.0907 MAE: 0.1824 Mean Error: -0.0040 STD: 0.3012\n",
      "[50/600] Loss: 0.0752 MAE: 0.1593 Mean Error: -0.0040 STD: 0.2743\n",
      "[60/600] Loss: 0.0511 MAE: 0.1115 Mean Error: -0.0024 STD: 0.2261\n",
      "[70/600] Loss: 0.0307 MAE: 0.0711 Mean Error: -0.0004 STD: 0.1752\n",
      "[80/600] Loss: 0.0133 MAE: 0.0331 Mean Error: 0.0009 STD: 0.1152\n",
      "[90/600] Loss: 0.0079 MAE: 0.0152 Mean Error: 0.0001 STD: 0.0889\n",
      "[100/600] Loss: 0.0064 MAE: 0.0096 Mean Error: 0.0004 STD: 0.0803\n",
      "[110/600] Loss: 0.0059 MAE: 0.0077 Mean Error: 0.0005 STD: 0.0767\n",
      "[120/600] Loss: 0.0057 MAE: 0.0070 Mean Error: 0.0003 STD: 0.0756\n",
      "[130/600] Loss: 0.0055 MAE: 0.0065 Mean Error: 0.0004 STD: 0.0739\n",
      "[140/600] Loss: 0.0052 MAE: 0.0062 Mean Error: 0.0009 STD: 0.0721\n",
      "[150/600] Loss: 0.0051 MAE: 0.0059 Mean Error: 0.0008 STD: 0.0714\n",
      "[160/600] Loss: 0.0049 MAE: 0.0058 Mean Error: 0.0009 STD: 0.0703\n",
      "[170/600] Loss: 0.0049 MAE: 0.0056 Mean Error: 0.0009 STD: 0.0698\n",
      "[180/600] Loss: 0.0047 MAE: 0.0054 Mean Error: 0.0010 STD: 0.0686\n",
      "[190/600] Loss: 0.0046 MAE: 0.0052 Mean Error: 0.0009 STD: 0.0678\n",
      "[200/600] Loss: 0.0046 MAE: 0.0052 Mean Error: 0.0009 STD: 0.0678\n",
      "[210/600] Loss: 0.0046 MAE: 0.0051 Mean Error: 0.0011 STD: 0.0675\n",
      "[220/600] Loss: 0.0045 MAE: 0.0050 Mean Error: 0.0010 STD: 0.0671\n",
      "[230/600] Loss: 0.0045 MAE: 0.0050 Mean Error: 0.0010 STD: 0.0670\n",
      "[240/600] Loss: 0.0045 MAE: 0.0050 Mean Error: 0.0010 STD: 0.0670\n",
      "[250/600] Loss: 0.0045 MAE: 0.0050 Mean Error: 0.0010 STD: 0.0670\n",
      "[260/600] Loss: 0.0046 MAE: 0.0051 Mean Error: 0.0006 STD: 0.0677\n",
      "[270/600] Loss: 0.0044 MAE: 0.0050 Mean Error: 0.0009 STD: 0.0663\n",
      "[280/600] Loss: 0.0044 MAE: 0.0049 Mean Error: 0.0008 STD: 0.0663\n",
      "[290/600] Loss: 0.0044 MAE: 0.0048 Mean Error: 0.0009 STD: 0.0663\n",
      "[300/600] Loss: 0.0044 MAE: 0.0048 Mean Error: 0.0009 STD: 0.0663\n",
      "[310/600] Loss: 0.0044 MAE: 0.0048 Mean Error: 0.0009 STD: 0.0663\n",
      "[320/600] Loss: 0.0044 MAE: 0.0048 Mean Error: 0.0009 STD: 0.0663\n",
      "[330/600] Loss: 0.0044 MAE: 0.0048 Mean Error: 0.0009 STD: 0.0663\n",
      "[340/600] Loss: 0.0044 MAE: 0.0048 Mean Error: 0.0009 STD: 0.0663\n",
      "[350/600] Loss: 0.0044 MAE: 0.0047 Mean Error: 0.0009 STD: 0.0663\n",
      "[360/600] Loss: 0.0044 MAE: 0.0047 Mean Error: 0.0009 STD: 0.0663\n",
      "[370/600] Loss: 0.0044 MAE: 0.0047 Mean Error: 0.0009 STD: 0.0663\n",
      "[380/600] Loss: 0.0044 MAE: 0.0047 Mean Error: 0.0009 STD: 0.0663\n",
      "[390/600] Loss: 0.0044 MAE: 0.0047 Mean Error: 0.0009 STD: 0.0663\n",
      "[400/600] Loss: 0.0044 MAE: 0.0047 Mean Error: 0.0009 STD: 0.0663\n",
      "[410/600] Loss: 0.0044 MAE: 0.0047 Mean Error: 0.0009 STD: 0.0663\n",
      "[420/600] Loss: 0.0044 MAE: 0.0047 Mean Error: 0.0009 STD: 0.0663\n",
      "[430/600] Loss: 0.0044 MAE: 0.0047 Mean Error: 0.0009 STD: 0.0663\n",
      "[440/600] Loss: 0.0044 MAE: 0.0047 Mean Error: 0.0009 STD: 0.0663\n",
      "[450/600] Loss: 0.0044 MAE: 0.0047 Mean Error: 0.0009 STD: 0.0663\n",
      "[460/600] Loss: 0.0044 MAE: 0.0047 Mean Error: 0.0009 STD: 0.0663\n",
      "[470/600] Loss: 0.0044 MAE: 0.0047 Mean Error: 0.0009 STD: 0.0663\n",
      "[480/600] Loss: 0.0044 MAE: 0.0047 Mean Error: 0.0009 STD: 0.0663\n",
      "[490/600] Loss: 0.0044 MAE: 0.0047 Mean Error: 0.0009 STD: 0.0663\n",
      "[500/600] Loss: 0.0044 MAE: 0.0047 Mean Error: 0.0009 STD: 0.0663\n",
      "[510/600] Loss: 0.0044 MAE: 0.0047 Mean Error: 0.0009 STD: 0.0663\n",
      "[520/600] Loss: 0.0044 MAE: 0.0046 Mean Error: 0.0009 STD: 0.0663\n",
      "[530/600] Loss: 0.0044 MAE: 0.0046 Mean Error: 0.0009 STD: 0.0663\n",
      "[540/600] Loss: 0.0044 MAE: 0.0046 Mean Error: 0.0009 STD: 0.0663\n",
      "[550/600] Loss: 0.0044 MAE: 0.0046 Mean Error: 0.0009 STD: 0.0663\n",
      "[560/600] Loss: 0.0044 MAE: 0.0046 Mean Error: 0.0009 STD: 0.0663\n",
      "[570/600] Loss: 0.0044 MAE: 0.0046 Mean Error: 0.0009 STD: 0.0663\n",
      "[580/600] Loss: 0.0044 MAE: 0.0046 Mean Error: 0.0009 STD: 0.0663\n",
      "[590/600] Loss: 0.0044 MAE: 0.0046 Mean Error: 0.0009 STD: 0.0663\n",
      "[599/600] Loss: 0.0044 MAE: 0.0046 Mean Error: 0.0009 STD: 0.0663\n",
      "------------------------------------\n",
      "------------Fh_noise_array------------\n",
      "[[[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]]\n",
      "------------Ffa_noise_array------------\n",
      "[[[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]]\n"
     ]
    }
   ],
   "source": [
    "# Step 5\n",
    "def gaussian_noise(img, mean, sigma, percentage):\n",
    "    # Generate gauss noise\n",
    "    print(img)\n",
    "    gaussian_out=img\n",
    "    noise = np.random.normal(mean, sigma, int(percentage*input_size))\n",
    "    # Add the noise to image\n",
    "    gp = np.random.uniform(0,255,int(percentage*input_size))\n",
    "    for i in range(int(percentage*input_size)):\n",
    "        if gaussian_out[int(gp[i])]==1:\n",
    "            gaussian_out[int(gp[i])]-=abs(noise[i])\n",
    "        else:\n",
    "            gaussian_out[int(gp[i])]+=abs(noise[i])\n",
    "    #gaussian_out = img + noise\n",
    "    # Make the value between 0 and 1\n",
    "    return gaussian_out\n",
    "\n",
    "gaussian_dataset = np.zeros([5, 9, 10, 1024])\n",
    "std = [0.001, 0.002, 0.003, 0.005, 0.01, 0.02, 0.03, 0.05, 0.1]\n",
    "perc = [0.1, 0.2, 0.25, 0.3, 0.35]\n",
    "\n",
    "if not os.path.exists('./input_noise22/'):\n",
    "        os.mkdir('./input_noise22/')\n",
    "for k in range(5):\n",
    "    if not os.path.exists('./input_noise22/'+ str(perc[k]) + '/' ):\n",
    "        os.mkdir('./input_noise22/' + str(perc[k]) + '/' )\n",
    "\n",
    "for k in range(5):\n",
    "    for j in range(9):\n",
    "        if not os.path.exists('./input_noise22/' + str(perc[k]) + '/' + str(std[j])):\n",
    "            os.mkdir('./input_noise22/' + str(perc[k]) + '/' + str(std[j]))\n",
    "        for i in range(10):\n",
    "            inputImage = dataSet2[i].copy()\n",
    "            gaussian_data = gaussian_noise(inputImage, 0, std[j], perc[k])\n",
    "            img = gaussian_data.reshape(32, 32)*255\n",
    "            img = Image.fromarray(np.uint8(img))\n",
    "            img.convert(\"1\")\n",
    "            \n",
    "            inputImageDir = './input_noise22/' + str(perc[k]) + '/' + str(std[j]) + '/' + str(i) + '.png'\n",
    "            img.save(inputImageDir)\n",
    "            gaussian_dataset[k][j][i] = gaussian_data\n",
    "gaussian_dataset = np.array(gaussian_dataset)\n",
    "\n",
    "Fh_noise_array = np.zeros([5, 9, 36])\n",
    "Ffa_noise_array = np.zeros([5, 9, 36])\n",
    "\n",
    "# Train 9 datasets with noise\n",
    "if not os.path.exists('./output_noise22/'):\n",
    "        os.mkdir('./output_noise22/')\n",
    "for k in range(5):\n",
    "    if not os.path.exists('./output_noise22/' + str(perc[k]) + '/'):\n",
    "        os.mkdir('./output_noise22/' + str(perc[k]) + '/')\n",
    "for k in range(5):\n",
    "    for j in range(9):\n",
    "        train_noise_dataset = DigitDataset(dataset = gaussian_dataset[k][j], label_list = dataSet)\n",
    "        train_noise_loader = DataLoader(dataset=train_noise_dataset, batch_size=batch_size, shuffle=False)\n",
    "        print('Training dataset with noise standard deviation ' + str(std[j]))\n",
    "    #     model_noise = torch.load('./models/net_untrained.pkl') #  Load the model that trained before\n",
    "        model_noise = Perceptron(input_size=input_size, d_hidden = d_hidden, num_classes=num_classes).to(device)\n",
    "        criterion = nn.MSELoss()\n",
    "        optimizer = optim.Adam(model_noise.parameters(), lr=learning_rate)\n",
    "\n",
    "        output_noise, model_noise = train(train_noise_loader, model_noise, num_epochs)   # Train\n",
    "        torch.save(model_noise, './models21/' + str(k) + '/' + 'net_trained_' + str(std[j]) + '.pkl')\n",
    "        model_noise = torch.load('./models21/' + str(k) + '/' + 'net_trained_'+ str(std[j]) + '.pkl')\n",
    "    #     output_noise = model_noise(torch.from_numpy(gaussian_dataset[j]).float()) # Use the model trained before to test\n",
    "        print('------------------------------------')\n",
    "        output_noise = model_noise(torch.from_numpy(dataSet).float())\n",
    "        output_noise_np = output_noise.detach().numpy()     # Get the output\n",
    "    #     print(output_noise_np)\n",
    "        output_noise_dataset = np.zeros([10, 1024])\n",
    "    #     Make the output only has 0 or 1\n",
    "\n",
    "        if not os.path.exists('./output_noise22/' + str(perc[k]) + '/' + str(std[j])):\n",
    "            os.mkdir('./output_noise22/' + str(perc[k]) + '/' + str(std[j]))\n",
    "    \n",
    "    \n",
    "        for i in range(10):\n",
    "            output_noise_img = output_noise_np[i].reshape(32, 32)*255\n",
    "            img = Image.fromarray(np.uint8(output_noise_img))\n",
    "            img = img.convert(\"1\")\n",
    "            output_path = './output_noise22/' + str(perc[k]) + '/' + str(std[j]) + '/' + str(i) + '.png'\n",
    "            img.save(output_path)\n",
    "            data = img.getdata()\n",
    "            array = np.array(data)/255\n",
    "            output_noise_dataset[i] = array\n",
    "#     Calculate Fh and Ffa\n",
    "    #Fh = calculateFh(dataSet, output_noise_dataset)\n",
    "    #Ffa = calculateFfa(dataSet, output_noise_dataset)\n",
    "    #Fh_noise_array[j] = Fh\n",
    "    #Ffa_noise_array[j] = Ffa\n",
    "print('------------Fh_noise_array------------')\n",
    "print(Fh_noise_array)\n",
    "print('------------Ffa_noise_array------------')\n",
    "print(Ffa_noise_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4010e235",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remoaining \n",
    "# 1. 32x32\n",
    "# 2. noise visualization\n",
    "# 3. 4c Questions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43b32ebc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
