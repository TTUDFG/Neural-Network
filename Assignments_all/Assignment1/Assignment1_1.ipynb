{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c2abcc3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.autograd import Variable\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7f4f5e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1\n",
    "# Get the image and change every image to an 256-dimention vector\n",
    "dataSet = np.zeros([10, 256])\n",
    "for i in range(0, 10):\n",
    "    inputImageDir = './input/' + str(i) + '.png'\n",
    "    inputImage = Image.open(inputImageDir)\n",
    "    inputImage = inputImage.convert(\"1\")\n",
    "    inputImage.save(inputImageDir)\n",
    "    data = inputImage.getdata()\n",
    "    array = np.array(data)/255\n",
    "    dataSet[i] = array\n",
    "dataSet = np.array(dataSet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "91f55f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2\n",
    "# define a neural network\n",
    "class Perceptron(nn.Module):\n",
    "\n",
    "    def __init__(self, input_size, num_hidden, num_classes):\n",
    "        super(Perceptron, self).__init__()\n",
    "        self.inputlayer = nn.Linear(input_size, num_hidden)\n",
    "        self.hiddenlayer = nn.Linear(num_hidden, num_hidden)\n",
    "        self.outputlayer = nn.Linear(num_hidden, num_classes)\n",
    "        self.activate = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        res = self.inputlayer(x)\n",
    "        res = self.activate(res)\n",
    "        res = self.hiddenlayer(x)\n",
    "        res = self.activate(res)\n",
    "        res = self.outputlayer(x)\n",
    "        res = self.activate(res)\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fce7e73f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DigitDataset(Dataset):\n",
    "    def __init__(self, dataset, label_list):\n",
    "        self.dataset = dataset\n",
    "        self.label_list = label_list\n",
    "    def __len__(self):\n",
    "        return len(self.label_list)\n",
    "    def __getitem__(self, idx):\n",
    "        data = self.dataset[idx]\n",
    "        label = self.label_list[idx]\n",
    "        return {\n",
    "            'data': torch.from_numpy(data).float(),\n",
    "            'label': torch.from_numpy(label).float()\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1eebe268",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters of training\n",
    "input_size = 256\n",
    "num_classes = 256\n",
    "num_hidden = 256\n",
    "learning_rate = 0.001\n",
    "batch_size = 10\n",
    "num_epochs = 600\n",
    "\n",
    "# Load the dataset\n",
    "train_dataset = DigitDataset(dataset = dataSet, label_list = dataSet)\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=False)\n",
    "device = torch.device('cpu')\n",
    "model = Perceptron(input_size=input_size, num_hidden=num_hidden, num_classes=num_classes).to(device)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c653a506",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0/600] Loss: 0.2575 MAE: 0.4892 Mean Error: 0.4034 STD: 0.3079\n",
      "[10/600] Loss: 0.0439 MAE: 0.1558 Mean Error: 0.0956 STD: 0.1864\n",
      "[20/600] Loss: 0.0309 MAE: 0.0909 Mean Error: 0.0334 STD: 0.1726\n",
      "[30/600] Loss: 0.0282 MAE: 0.0780 Mean Error: 0.0196 STD: 0.1669\n",
      "[40/600] Loss: 0.0265 MAE: 0.0731 Mean Error: 0.0163 STD: 0.1621\n",
      "[50/600] Loss: 0.0250 MAE: 0.0704 Mean Error: 0.0153 STD: 0.1575\n",
      "[60/600] Loss: 0.0236 MAE: 0.0687 Mean Error: 0.0142 STD: 0.1531\n",
      "[70/600] Loss: 0.0223 MAE: 0.0671 Mean Error: 0.0134 STD: 0.1489\n",
      "[80/600] Loss: 0.0211 MAE: 0.0657 Mean Error: 0.0128 STD: 0.1448\n",
      "[90/600] Loss: 0.0200 MAE: 0.0640 Mean Error: 0.0123 STD: 0.1408\n",
      "[100/600] Loss: 0.0189 MAE: 0.0624 Mean Error: 0.0120 STD: 0.1369\n",
      "[110/600] Loss: 0.0179 MAE: 0.0607 Mean Error: 0.0118 STD: 0.1331\n",
      "[120/600] Loss: 0.0169 MAE: 0.0592 Mean Error: 0.0114 STD: 0.1295\n",
      "[130/600] Loss: 0.0160 MAE: 0.0576 Mean Error: 0.0111 STD: 0.1260\n",
      "[140/600] Loss: 0.0151 MAE: 0.0561 Mean Error: 0.0108 STD: 0.1226\n",
      "[150/600] Loss: 0.0143 MAE: 0.0547 Mean Error: 0.0105 STD: 0.1193\n",
      "[160/600] Loss: 0.0136 MAE: 0.0532 Mean Error: 0.0103 STD: 0.1161\n",
      "[170/600] Loss: 0.0129 MAE: 0.0519 Mean Error: 0.0100 STD: 0.1131\n",
      "[180/600] Loss: 0.0122 MAE: 0.0505 Mean Error: 0.0098 STD: 0.1101\n",
      "[190/600] Loss: 0.0116 MAE: 0.0492 Mean Error: 0.0095 STD: 0.1073\n",
      "[200/600] Loss: 0.0110 MAE: 0.0480 Mean Error: 0.0093 STD: 0.1046\n",
      "[210/600] Loss: 0.0105 MAE: 0.0468 Mean Error: 0.0091 STD: 0.1020\n",
      "[220/600] Loss: 0.0100 MAE: 0.0457 Mean Error: 0.0089 STD: 0.0995\n",
      "[230/600] Loss: 0.0095 MAE: 0.0446 Mean Error: 0.0087 STD: 0.0971\n",
      "[240/600] Loss: 0.0090 MAE: 0.0435 Mean Error: 0.0085 STD: 0.0948\n",
      "[250/600] Loss: 0.0086 MAE: 0.0425 Mean Error: 0.0083 STD: 0.0926\n",
      "[260/600] Loss: 0.0082 MAE: 0.0415 Mean Error: 0.0082 STD: 0.0904\n",
      "[270/600] Loss: 0.0079 MAE: 0.0406 Mean Error: 0.0080 STD: 0.0884\n",
      "[280/600] Loss: 0.0075 MAE: 0.0397 Mean Error: 0.0078 STD: 0.0864\n",
      "[290/600] Loss: 0.0072 MAE: 0.0388 Mean Error: 0.0077 STD: 0.0845\n",
      "[300/600] Loss: 0.0069 MAE: 0.0380 Mean Error: 0.0076 STD: 0.0827\n",
      "[310/600] Loss: 0.0066 MAE: 0.0372 Mean Error: 0.0074 STD: 0.0810\n",
      "[320/600] Loss: 0.0063 MAE: 0.0364 Mean Error: 0.0073 STD: 0.0793\n",
      "[330/600] Loss: 0.0061 MAE: 0.0357 Mean Error: 0.0072 STD: 0.0777\n",
      "[340/600] Loss: 0.0058 MAE: 0.0349 Mean Error: 0.0070 STD: 0.0761\n",
      "[350/600] Loss: 0.0056 MAE: 0.0343 Mean Error: 0.0069 STD: 0.0746\n",
      "[360/600] Loss: 0.0054 MAE: 0.0336 Mean Error: 0.0068 STD: 0.0732\n",
      "[370/600] Loss: 0.0052 MAE: 0.0330 Mean Error: 0.0067 STD: 0.0718\n",
      "[380/600] Loss: 0.0050 MAE: 0.0323 Mean Error: 0.0066 STD: 0.0705\n",
      "[390/600] Loss: 0.0048 MAE: 0.0318 Mean Error: 0.0065 STD: 0.0692\n",
      "[400/600] Loss: 0.0047 MAE: 0.0312 Mean Error: 0.0064 STD: 0.0679\n",
      "[410/600] Loss: 0.0045 MAE: 0.0306 Mean Error: 0.0063 STD: 0.0667\n",
      "[420/600] Loss: 0.0043 MAE: 0.0301 Mean Error: 0.0062 STD: 0.0655\n",
      "[430/600] Loss: 0.0042 MAE: 0.0296 Mean Error: 0.0061 STD: 0.0644\n",
      "[440/600] Loss: 0.0040 MAE: 0.0291 Mean Error: 0.0060 STD: 0.0633\n",
      "[450/600] Loss: 0.0039 MAE: 0.0286 Mean Error: 0.0059 STD: 0.0623\n",
      "[460/600] Loss: 0.0038 MAE: 0.0281 Mean Error: 0.0058 STD: 0.0612\n",
      "[470/600] Loss: 0.0037 MAE: 0.0277 Mean Error: 0.0057 STD: 0.0602\n",
      "[480/600] Loss: 0.0035 MAE: 0.0272 Mean Error: 0.0057 STD: 0.0593\n",
      "[490/600] Loss: 0.0034 MAE: 0.0268 Mean Error: 0.0056 STD: 0.0583\n",
      "[500/600] Loss: 0.0033 MAE: 0.0264 Mean Error: 0.0055 STD: 0.0574\n",
      "[510/600] Loss: 0.0032 MAE: 0.0260 Mean Error: 0.0054 STD: 0.0566\n",
      "[520/600] Loss: 0.0031 MAE: 0.0256 Mean Error: 0.0054 STD: 0.0557\n",
      "[530/600] Loss: 0.0030 MAE: 0.0252 Mean Error: 0.0053 STD: 0.0549\n",
      "[540/600] Loss: 0.0030 MAE: 0.0249 Mean Error: 0.0052 STD: 0.0541\n",
      "[550/600] Loss: 0.0029 MAE: 0.0245 Mean Error: 0.0052 STD: 0.0533\n",
      "[560/600] Loss: 0.0028 MAE: 0.0242 Mean Error: 0.0051 STD: 0.0525\n",
      "[570/600] Loss: 0.0027 MAE: 0.0238 Mean Error: 0.0050 STD: 0.0518\n",
      "[580/600] Loss: 0.0026 MAE: 0.0235 Mean Error: 0.0050 STD: 0.0511\n",
      "[590/600] Loss: 0.0026 MAE: 0.0232 Mean Error: 0.0049 STD: 0.0504\n",
      "[599/600] Loss: 0.0025 MAE: 0.0229 Mean Error: 0.0049 STD: 0.0498\n"
     ]
    }
   ],
   "source": [
    "# from transformers import AutoModelForSequenceClassification\n",
    "# Step 3\n",
    "def train(dataloader, model, num_epochs):\n",
    "    for epoch in range(num_epochs):\n",
    "        losses = []\n",
    "        ERROR_Train = [] \n",
    "        model.train() \n",
    "        for i, data in enumerate(dataloader, 0):\n",
    "            model.zero_grad()\n",
    "            real_cpu, label_cpu = data['data'], data['label']\n",
    "            if torch.cuda.is_available():\n",
    "                real_cpu = real_cpu.cuda() \n",
    "                label_cpu = label_cpu.cuda()\n",
    "            real = real_cpu\n",
    "            label = label_cpu\n",
    "            inputv = Variable(real)\n",
    "            labelv = Variable(label)\n",
    "            output = model(inputv)\n",
    "            err = criterion(output, labelv) \n",
    "            err.backward() \n",
    "            optimizer.step() \n",
    "\n",
    "            losses.append(err.data.item())\n",
    "            error = label - output.data\n",
    "#             print(error.shape)\n",
    "            ERROR_Train.extend(error)\n",
    "#         print(ERROR_Train)\n",
    "        MAE = torch.mean(torch.abs(torch.stack(ERROR_Train)))\n",
    "        ME = torch.mean(torch.stack(ERROR_Train))\n",
    "        STD = torch.std(torch.stack(ERROR_Train)) \n",
    "        if epoch % 10 == 0 or epoch == num_epochs - 1:\n",
    "            print('[%d/%d] Loss: %.4f MAE: %.4f Mean Error: %.4f STD: %.4f' % (epoch, num_epochs, np.average(losses), MAE, ME, STD))\n",
    "    return output\n",
    "\n",
    "# Start training      \n",
    "output = train(train_loader, model, num_epochs)\n",
    "# model = AutoModelForSequenceClassification.from_pretrained(output_dir).to(device)\n",
    "# print(output.type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d367612f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4\n",
    "# Step 4a\n",
    "# Export the image after training\n",
    "# Before executing this block, create a folder called \"output\"\n",
    "if not os.path.exists('./output'):\n",
    "    os.mkdir('./output')\n",
    "output_np = output.cpu().detach().numpy()\n",
    "print(output_np.shape)\n",
    "torch.save(model, 'net.pkl')\n",
    "output_dataset = np.zeros([10, 256])\n",
    "for i in range(10):\n",
    "    output_img = output_np[i].reshape(16, 16)*255\n",
    "    img = Image.fromarray(np.uint8(output_img))\n",
    "    img = img.convert(\"1\")\n",
    "    output_path = './output/' + str(i) + '.png'\n",
    "    img.save(output_path)\n",
    "    data = img.getdata()\n",
    "    array = np.array(data)/255\n",
    "    output_dataset[i] = array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48edd1ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4b\n",
    "# Calculate Fh\n",
    "def calculateFh(input_dataset, output_dataset):\n",
    "    x, y = input_dataset.shape\n",
    "    Fh_denominator = 0    # Fh分母\n",
    "    Fh_numerator = 0      # Fh分子\n",
    "    Fh_array = np.zeros([x])\n",
    "    for j in range(x):\n",
    "        for i in range(y):\n",
    "            if input_dataset[j][i] == 0:\n",
    "                Fh_denominator = Fh_denominator + 1\n",
    "                if output_dataset[j][i] == 0:\n",
    "                    Fh_numerator = Fh_numerator + 1\n",
    "        Fh = Fh_numerator / Fh_denominator\n",
    "        Fh_array[j] = Fh\n",
    "    return Fh_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db5c63b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Ffa\n",
    "def calculateFfa(input_dataset, output_dataset):\n",
    "    x, y = input_dataset.shape\n",
    "    Ffa_denominator = 0    # Ffa分母\n",
    "    Ffa_numerator = 0      # Ffa分子\n",
    "    Ffa_array = np.zeros([x])\n",
    "    for j in range(x):\n",
    "        for i in range(y):\n",
    "            if input_dataset[j][i] == 1:\n",
    "                Ffa_denominator = Ffa_denominator + 1\n",
    "            if output_dataset[j][i] == 0 and input_dataset[j][i] == 1:\n",
    "                Ffa_numerator = Ffa_numerator + 1\n",
    "        Ffa = Ffa_numerator / Ffa_denominator\n",
    "        Ffa_array[j] = Ffa\n",
    "    return Ffa_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6287172",
   "metadata": {},
   "outputs": [],
   "source": [
    "Fh_array = calculateFh(dataSet, output_dataset)\n",
    "Ffa_array = calculateFfa(dataSet, output_dataset)\n",
    "print(Fh_array)\n",
    "print(Ffa_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83f946bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Step 4c: Graph Fh as a function of Ffa for each exemplar in the input dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "154e1b2a",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument mat1 in method wrapper_addmm)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-57-acc1c86b6e73>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     40\u001b[0m     \u001b[0mmodel_noise\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'net.pkl'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#  Load the model that trained before\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[1;31m#     output_noise = train(train_noise_loader, model_noise, num_epochs)   # Train\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 42\u001b[1;33m     \u001b[0moutput_noise\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel_noise\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgaussian_dataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# Use the model trained before to test\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     43\u001b[0m \u001b[1;31m#     print('------------------------------------')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m     \u001b[0moutput_noise_np\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moutput_noise\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m     \u001b[1;31m# Get the output\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-53-9f27d5755b5f>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m         \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minputlayer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m         \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mactivate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mres\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhiddenlayer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\linear.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    101\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    102\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 103\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    104\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    105\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mlinear\u001b[1;34m(input, weight, bias)\u001b[0m\n\u001b[0;32m   1846\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhas_torch_function_variadic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1847\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1848\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1849\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1850\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument mat1 in method wrapper_addmm)"
     ]
    }
   ],
   "source": [
    "# Step 5\n",
    "def gaussian_noise(img, mean, sigma):\n",
    "    # Generate gauss noise\n",
    "    noise = np.random.normal(mean, sigma, img.shape)\n",
    "    # Add the noise to image\n",
    "    gaussian_out = img + noise\n",
    "    # Make the value between 0 and 1\n",
    "    gaussian_out = np.clip(gaussian_out, 0, 1)\n",
    "    return gaussian_out\n",
    "\n",
    "gaussian_dataset = np.zeros([9, 10, 256])\n",
    "std = [0.001, 0.002, 0.003, 0.005, 0.01, 0.02, 0.03, 0.05, 0.1]\n",
    "if not os.path.exists('./input_noise/'):\n",
    "    os.mkdir('./input_noise/')\n",
    "for j in range(9):\n",
    "    if not os.path.exists('./input_noise/' + str(std[j])):\n",
    "        os.mkdir('./input_noise/' + str(std[j]))\n",
    "    for i in range(10):\n",
    "        inputImage = dataSet[i]\n",
    "        gaussian_data = gaussian_noise(inputImage, 0, std[j])\n",
    "        img = gaussian_data.reshape(16, 16)*255\n",
    "        img = Image.fromarray(np.uint8(img))\n",
    "        img.convert(\"1\")\n",
    "        inputImageDir = './input_noise/' + str(std[j]) + '/' + str(i) + '.png'\n",
    "        img.save(inputImageDir)\n",
    "        gaussian_dataset[j][i] = gaussian_data\n",
    "gaussian_dataset = np.array(gaussian_dataset)\n",
    "\n",
    "\n",
    "Fh_noise_array = np.zeros([9, 10])\n",
    "Ffa_noise_array = np.zeros([9, 10])\n",
    "\n",
    "# Train 9 datasets with noise\n",
    "if not os.path.exists('./output_noise/'):\n",
    "    os.mkdir('./output_noise/')\n",
    "for j in range(9):\n",
    "    train_noise_dataset = DigitDataset(dataset = gaussian_dataset[j], label_list = gaussian_dataset[j])\n",
    "    train_noise_loader = DataLoader(dataset=train_noise_dataset, batch_size=batch_size, shuffle=False)\n",
    "#     print('Training dataset with noise standard deviation ' + str(std[j]))\n",
    "    model_noise = torch.load('net.pkl') #  Load the model that trained before\n",
    "#     output_noise = train(train_noise_loader, model_noise, num_epochs)   # Train\n",
    "    output_noise = model_noise(torch.from_numpy(gaussian_dataset[j]).float()) # Use the model trained before to test\n",
    "#     print('------------------------------------')\n",
    "    output_noise_np = output_noise.cpu().detach().numpy()     # Get the output\n",
    "    output_noise_dataset = np.zeros([10, 256])\n",
    "#     Make the output only has 0 or 1\n",
    "    if not os.path.exists('./output_noise/' + str(std[j])):\n",
    "        os.mkdir('./output_noise/' + str(std[j]))\n",
    "    for i in range(10):\n",
    "        output_noise_img = output_noise_np[i].reshape(16, 16)*255\n",
    "        img = Image.fromarray(np.uint8(output_noise_img))\n",
    "        img = img.convert(\"1\")\n",
    "        output_path = './output_noise/' + str(std[j]) + '/' + str(i) + '.png'\n",
    "        img.save(output_path)\n",
    "        data = img.getdata()\n",
    "        array = np.array(data)/255\n",
    "        output_noise_dataset[i] = array\n",
    "#     Calculate Fh and Ffa\n",
    "    Fh = calculateFh(gaussian_dataset[j], output_noise_dataset)\n",
    "    Ffa = calculateFfa(gaussian_dataset[j], output_noise_dataset)\n",
    "    Fh_noise_array[j] = Fh\n",
    "    Ffa_noise_array[j] = Ffa\n",
    "print('------------Fh_noise_array------------')\n",
    "print(Fh_noise_array)\n",
    "print('------------Ffa_noise_array------------')\n",
    "print(Ffa_noise_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dd78210",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Step 6: Display Data from your Tests in Step 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e584ac1e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
