{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c2abcc3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.autograd import Variable\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7f4f5e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1\n",
    "# Get the image and change every image to an 256-dimention vector\n",
    "dataSet = np.zeros([10, 256])\n",
    "for i in range(0, 10):\n",
    "    inputImageDir = './input/' + str(i) + '.png'\n",
    "    inputImage = Image.open(inputImageDir)\n",
    "    inputImage = inputImage.convert(\"1\")\n",
    "    inputImage.save(inputImageDir)\n",
    "    data = inputImage.getdata()\n",
    "    array = np.array(data)/255\n",
    "    dataSet[i] = array\n",
    "dataSet = np.array(dataSet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "91f55f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2\n",
    "# define a neural network\n",
    "class Perceptron(nn.Module):\n",
    "\n",
    "    def __init__(self, input_size, num_hidden, num_classes):\n",
    "        super(Perceptron, self).__init__()\n",
    "        self.inputlayer = nn.Linear(input_size, num_hidden)\n",
    "        self.hiddenlayer = nn.Linear(num_hidden, num_hidden)\n",
    "        self.outputlayer = nn.Linear(num_hidden, num_classes)\n",
    "        self.activate = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        res = self.inputlayer(x)\n",
    "        res = self.activate(res)\n",
    "        res = self.hiddenlayer(x)\n",
    "        res = self.activate(res)\n",
    "        res = self.outputlayer(x)\n",
    "        res = self.activate(res)\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "fce7e73f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DigitDataset(Dataset):\n",
    "    def __init__(self, dataset, label_list):\n",
    "        self.dataset = dataset\n",
    "        self.label_list = label_list\n",
    "    def __len__(self):\n",
    "        return len(self.label_list)\n",
    "    def __getitem__(self, idx):\n",
    "        data = self.dataset[idx]\n",
    "        label = self.label_list[idx]\n",
    "        return {\n",
    "            'data': torch.from_numpy(data).float(),\n",
    "            'label': torch.from_numpy(label).float()\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "1eebe268",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters of training\n",
    "input_size = 256\n",
    "num_classes = 256\n",
    "num_hidden = 256\n",
    "learning_rate = 0.001\n",
    "batch_size = 10\n",
    "num_epochs = 600\n",
    "\n",
    "# Load the dataset\n",
    "train_dataset = DigitDataset(dataset = dataSet, label_list = dataSet)\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=False)\n",
    "device = torch.device('cpu')\n",
    "model = Perceptron(input_size=input_size, num_hidden=num_hidden, num_classes=num_classes).to(device)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c653a506",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0/600] Loss: 0.2543 MAE: 0.4866 Mean Error: 0.3988 STD: 0.3087\n",
      "[10/600] Loss: 0.0430 MAE: 0.1537 Mean Error: 0.0925 STD: 0.1856\n",
      "[20/600] Loss: 0.0306 MAE: 0.0907 Mean Error: 0.0345 STD: 0.1714\n",
      "[30/600] Loss: 0.0282 MAE: 0.0777 Mean Error: 0.0191 STD: 0.1667\n",
      "[40/600] Loss: 0.0264 MAE: 0.0726 Mean Error: 0.0157 STD: 0.1617\n",
      "[50/600] Loss: 0.0249 MAE: 0.0707 Mean Error: 0.0145 STD: 0.1572\n",
      "[60/600] Loss: 0.0235 MAE: 0.0688 Mean Error: 0.0133 STD: 0.1529\n",
      "[70/600] Loss: 0.0223 MAE: 0.0670 Mean Error: 0.0129 STD: 0.1487\n",
      "[80/600] Loss: 0.0211 MAE: 0.0655 Mean Error: 0.0122 STD: 0.1446\n",
      "[90/600] Loss: 0.0199 MAE: 0.0639 Mean Error: 0.0123 STD: 0.1406\n",
      "[100/600] Loss: 0.0189 MAE: 0.0624 Mean Error: 0.0118 STD: 0.1368\n",
      "[110/600] Loss: 0.0178 MAE: 0.0608 Mean Error: 0.0115 STD: 0.1331\n",
      "[120/600] Loss: 0.0169 MAE: 0.0592 Mean Error: 0.0113 STD: 0.1295\n",
      "[130/600] Loss: 0.0160 MAE: 0.0576 Mean Error: 0.0110 STD: 0.1261\n",
      "[140/600] Loss: 0.0152 MAE: 0.0561 Mean Error: 0.0107 STD: 0.1227\n",
      "[150/600] Loss: 0.0144 MAE: 0.0547 Mean Error: 0.0105 STD: 0.1195\n",
      "[160/600] Loss: 0.0136 MAE: 0.0533 Mean Error: 0.0102 STD: 0.1164\n",
      "[170/600] Loss: 0.0129 MAE: 0.0519 Mean Error: 0.0100 STD: 0.1134\n",
      "[180/600] Loss: 0.0123 MAE: 0.0506 Mean Error: 0.0098 STD: 0.1105\n",
      "[190/600] Loss: 0.0117 MAE: 0.0493 Mean Error: 0.0095 STD: 0.1077\n",
      "[200/600] Loss: 0.0111 MAE: 0.0481 Mean Error: 0.0093 STD: 0.1050\n",
      "[210/600] Loss: 0.0106 MAE: 0.0469 Mean Error: 0.0091 STD: 0.1024\n",
      "[220/600] Loss: 0.0101 MAE: 0.0458 Mean Error: 0.0089 STD: 0.0999\n",
      "[230/600] Loss: 0.0096 MAE: 0.0447 Mean Error: 0.0087 STD: 0.0975\n",
      "[240/600] Loss: 0.0091 MAE: 0.0437 Mean Error: 0.0085 STD: 0.0952\n",
      "[250/600] Loss: 0.0087 MAE: 0.0426 Mean Error: 0.0084 STD: 0.0930\n",
      "[260/600] Loss: 0.0083 MAE: 0.0417 Mean Error: 0.0082 STD: 0.0909\n",
      "[270/600] Loss: 0.0080 MAE: 0.0407 Mean Error: 0.0080 STD: 0.0889\n",
      "[280/600] Loss: 0.0076 MAE: 0.0398 Mean Error: 0.0079 STD: 0.0869\n",
      "[290/600] Loss: 0.0073 MAE: 0.0390 Mean Error: 0.0077 STD: 0.0851\n",
      "[300/600] Loss: 0.0070 MAE: 0.0381 Mean Error: 0.0076 STD: 0.0833\n",
      "[310/600] Loss: 0.0067 MAE: 0.0374 Mean Error: 0.0074 STD: 0.0815\n",
      "[320/600] Loss: 0.0064 MAE: 0.0366 Mean Error: 0.0073 STD: 0.0798\n",
      "[330/600] Loss: 0.0062 MAE: 0.0358 Mean Error: 0.0072 STD: 0.0782\n",
      "[340/600] Loss: 0.0059 MAE: 0.0351 Mean Error: 0.0071 STD: 0.0767\n",
      "[350/600] Loss: 0.0057 MAE: 0.0344 Mean Error: 0.0069 STD: 0.0752\n",
      "[360/600] Loss: 0.0055 MAE: 0.0338 Mean Error: 0.0068 STD: 0.0737\n",
      "[370/600] Loss: 0.0053 MAE: 0.0331 Mean Error: 0.0067 STD: 0.0723\n",
      "[380/600] Loss: 0.0051 MAE: 0.0325 Mean Error: 0.0066 STD: 0.0710\n",
      "[390/600] Loss: 0.0049 MAE: 0.0319 Mean Error: 0.0065 STD: 0.0697\n",
      "[400/600] Loss: 0.0047 MAE: 0.0314 Mean Error: 0.0064 STD: 0.0684\n",
      "[410/600] Loss: 0.0046 MAE: 0.0308 Mean Error: 0.0063 STD: 0.0672\n",
      "[420/600] Loss: 0.0044 MAE: 0.0303 Mean Error: 0.0062 STD: 0.0660\n",
      "[430/600] Loss: 0.0042 MAE: 0.0297 Mean Error: 0.0061 STD: 0.0649\n",
      "[440/600] Loss: 0.0041 MAE: 0.0292 Mean Error: 0.0060 STD: 0.0638\n",
      "[450/600] Loss: 0.0040 MAE: 0.0288 Mean Error: 0.0059 STD: 0.0627\n",
      "[460/600] Loss: 0.0038 MAE: 0.0283 Mean Error: 0.0058 STD: 0.0617\n",
      "[470/600] Loss: 0.0037 MAE: 0.0278 Mean Error: 0.0058 STD: 0.0607\n",
      "[480/600] Loss: 0.0036 MAE: 0.0274 Mean Error: 0.0057 STD: 0.0597\n",
      "[490/600] Loss: 0.0035 MAE: 0.0270 Mean Error: 0.0056 STD: 0.0588\n",
      "[500/600] Loss: 0.0034 MAE: 0.0266 Mean Error: 0.0055 STD: 0.0579\n",
      "[510/600] Loss: 0.0033 MAE: 0.0262 Mean Error: 0.0054 STD: 0.0570\n",
      "[520/600] Loss: 0.0032 MAE: 0.0258 Mean Error: 0.0054 STD: 0.0561\n",
      "[530/600] Loss: 0.0031 MAE: 0.0254 Mean Error: 0.0053 STD: 0.0553\n",
      "[540/600] Loss: 0.0030 MAE: 0.0250 Mean Error: 0.0052 STD: 0.0545\n",
      "[550/600] Loss: 0.0029 MAE: 0.0247 Mean Error: 0.0052 STD: 0.0537\n",
      "[560/600] Loss: 0.0028 MAE: 0.0243 Mean Error: 0.0051 STD: 0.0529\n",
      "[570/600] Loss: 0.0027 MAE: 0.0240 Mean Error: 0.0050 STD: 0.0522\n",
      "[580/600] Loss: 0.0027 MAE: 0.0236 Mean Error: 0.0050 STD: 0.0515\n",
      "[590/600] Loss: 0.0026 MAE: 0.0233 Mean Error: 0.0049 STD: 0.0507\n",
      "[599/600] Loss: 0.0025 MAE: 0.0230 Mean Error: 0.0049 STD: 0.0501\n"
     ]
    }
   ],
   "source": [
    "# Step 3\n",
    "def train(dataloader, model, num_epochs):\n",
    "    for epoch in range(num_epochs):\n",
    "        losses = []\n",
    "        ERROR_Train = [] \n",
    "        model.train() \n",
    "        for i, data in enumerate(dataloader, 0):\n",
    "            model.zero_grad()\n",
    "            real_cpu, label_cpu = data['data'], data['label']\n",
    "            if torch.cuda.is_available():\n",
    "                real_cpu = real_cpu.cuda() \n",
    "                label_cpu = label_cpu.cuda()\n",
    "            real = real_cpu\n",
    "            label = label_cpu\n",
    "            inputv = Variable(real)\n",
    "            labelv = Variable(label)\n",
    "            output = model(inputv)\n",
    "            err = criterion(output, labelv) \n",
    "            err.backward() \n",
    "            optimizer.step() \n",
    "\n",
    "            losses.append(err.data.item())\n",
    "            error = label - output.data\n",
    "            ERROR_Train.extend(error)\n",
    "        MAE = torch.mean(torch.abs(torch.stack(ERROR_Train)))\n",
    "        ME = torch.mean(torch.stack(ERROR_Train))\n",
    "        STD = torch.std(torch.stack(ERROR_Train)) \n",
    "        if epoch % 10 == 0 or epoch == num_epochs - 1:\n",
    "            print('[%d/%d] Loss: %.4f MAE: %.4f Mean Error: %.4f STD: %.4f' % (epoch, num_epochs, np.average(losses), MAE, ME, STD))\n",
    "    return output\n",
    "\n",
    "# Start training        \n",
    "output = train(train_loader, model, num_epochs)\n",
    "# model = None\n",
    "# print(output.type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "d367612f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 256)\n"
     ]
    }
   ],
   "source": [
    "# Step 4\n",
    "# Step 4a\n",
    "# Export the image after training\n",
    "# Before executing this block, create a folder called \"output\"\n",
    "if not os.path.exists('./output'):\n",
    "    os.mkdir('./output')\n",
    "output_np = output.cpu().detach().numpy()\n",
    "print(output_np.shape)\n",
    "torch.save(model, 'net.pkl')\n",
    "output_dataset = np.zeros([10, 256])\n",
    "for i in range(10):\n",
    "    output_img = output_np[i].reshape(16, 16)*255\n",
    "    img = Image.fromarray(np.uint8(output_img))\n",
    "    img = img.convert(\"1\")\n",
    "    output_path = './output/' + str(i) + '.png'\n",
    "    img.save(output_path)\n",
    "    data = img.getdata()\n",
    "    array = np.array(data)/255\n",
    "    output_dataset[i] = array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "48edd1ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4b\n",
    "# Calculate Fh\n",
    "def calculateFh(input_dataset, output_dataset):\n",
    "    x, y = input_dataset.shape\n",
    "    Fh_denominator = 0    # Fh分母\n",
    "    Fh_numerator = 0      # Fh分子\n",
    "    Fh_array = np.zeros([x])\n",
    "    for j in range(x):\n",
    "        for i in range(y):\n",
    "            if input_dataset[j][i] == 0:\n",
    "                Fh_denominator = Fh_denominator + 1\n",
    "                if output_dataset[j][i] == 0:\n",
    "                    Fh_numerator = Fh_numerator + 1\n",
    "        Fh = Fh_numerator / Fh_denominator\n",
    "        Fh_array[j] = Fh\n",
    "    return Fh_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "db5c63b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Ffa\n",
    "def calculateFfa(input_dataset, output_dataset):\n",
    "    x, y = input_dataset.shape\n",
    "    Ffa_denominator = 0    # Ffa分母\n",
    "    Ffa_numerator = 0      # Ffa分子\n",
    "    Ffa_array = np.zeros([x])\n",
    "    for j in range(x):\n",
    "        for i in range(y):\n",
    "            if input_dataset[j][i] == 1:\n",
    "                Ffa_denominator = Ffa_denominator + 1\n",
    "            if output_dataset[j][i] == 0 and input_dataset[j][i] == 1:\n",
    "                Ffa_numerator = Ffa_numerator + 1\n",
    "        Ffa = Ffa_numerator / Ffa_denominator\n",
    "        Ffa_array[j] = Ffa\n",
    "    return Ffa_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c6287172",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "[0.         0.         0.         0.0010627  0.00085106 0.00071073\n",
      " 0.0006105  0.0005322  0.00047438 0.00042753]\n"
     ]
    }
   ],
   "source": [
    "Fh_array = calculateFh(dataSet, output_dataset)\n",
    "Ffa_array = calculateFfa(dataSet, output_dataset)\n",
    "print(Fh_array)\n",
    "print(Ffa_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "83f946bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Step 4c: Graph Fh as a function of Ffa for each exemplar in the input dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "154e1b2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset with noise standard deviation 0.001\n",
      "[0/600] Loss: 0.0204 MAE: 0.0215 Mean Error: -0.0023 STD: 0.1430\n",
      "[10/600] Loss: 0.0204 MAE: 0.0215 Mean Error: -0.0023 STD: 0.1430\n",
      "[20/600] Loss: 0.0204 MAE: 0.0215 Mean Error: -0.0023 STD: 0.1430\n",
      "[30/600] Loss: 0.0204 MAE: 0.0215 Mean Error: -0.0023 STD: 0.1430\n",
      "[40/600] Loss: 0.0204 MAE: 0.0215 Mean Error: -0.0023 STD: 0.1430\n",
      "[50/600] Loss: 0.0204 MAE: 0.0215 Mean Error: -0.0023 STD: 0.1430\n",
      "[60/600] Loss: 0.0204 MAE: 0.0215 Mean Error: -0.0023 STD: 0.1430\n",
      "[70/600] Loss: 0.0204 MAE: 0.0215 Mean Error: -0.0023 STD: 0.1430\n",
      "[80/600] Loss: 0.0204 MAE: 0.0215 Mean Error: -0.0023 STD: 0.1430\n",
      "[90/600] Loss: 0.0204 MAE: 0.0215 Mean Error: -0.0023 STD: 0.1430\n",
      "[100/600] Loss: 0.0204 MAE: 0.0215 Mean Error: -0.0023 STD: 0.1430\n",
      "[110/600] Loss: 0.0204 MAE: 0.0215 Mean Error: -0.0023 STD: 0.1430\n",
      "[120/600] Loss: 0.0204 MAE: 0.0215 Mean Error: -0.0023 STD: 0.1430\n",
      "[130/600] Loss: 0.0204 MAE: 0.0215 Mean Error: -0.0023 STD: 0.1430\n",
      "[140/600] Loss: 0.0204 MAE: 0.0215 Mean Error: -0.0023 STD: 0.1430\n",
      "[150/600] Loss: 0.0204 MAE: 0.0215 Mean Error: -0.0023 STD: 0.1430\n",
      "[160/600] Loss: 0.0204 MAE: 0.0215 Mean Error: -0.0023 STD: 0.1430\n",
      "[170/600] Loss: 0.0204 MAE: 0.0215 Mean Error: -0.0023 STD: 0.1430\n",
      "[180/600] Loss: 0.0204 MAE: 0.0215 Mean Error: -0.0023 STD: 0.1430\n",
      "[190/600] Loss: 0.0204 MAE: 0.0215 Mean Error: -0.0023 STD: 0.1430\n",
      "[200/600] Loss: 0.0204 MAE: 0.0215 Mean Error: -0.0023 STD: 0.1430\n",
      "[210/600] Loss: 0.0204 MAE: 0.0215 Mean Error: -0.0023 STD: 0.1430\n",
      "[220/600] Loss: 0.0204 MAE: 0.0215 Mean Error: -0.0023 STD: 0.1430\n",
      "[230/600] Loss: 0.0204 MAE: 0.0215 Mean Error: -0.0023 STD: 0.1430\n",
      "[240/600] Loss: 0.0204 MAE: 0.0215 Mean Error: -0.0023 STD: 0.1430\n",
      "[250/600] Loss: 0.0204 MAE: 0.0215 Mean Error: -0.0023 STD: 0.1430\n",
      "[260/600] Loss: 0.0204 MAE: 0.0215 Mean Error: -0.0023 STD: 0.1430\n",
      "[270/600] Loss: 0.0204 MAE: 0.0215 Mean Error: -0.0023 STD: 0.1430\n",
      "[280/600] Loss: 0.0204 MAE: 0.0215 Mean Error: -0.0023 STD: 0.1430\n",
      "[290/600] Loss: 0.0204 MAE: 0.0215 Mean Error: -0.0023 STD: 0.1430\n",
      "[300/600] Loss: 0.0204 MAE: 0.0215 Mean Error: -0.0023 STD: 0.1430\n",
      "[310/600] Loss: 0.0204 MAE: 0.0215 Mean Error: -0.0023 STD: 0.1430\n",
      "[320/600] Loss: 0.0204 MAE: 0.0215 Mean Error: -0.0023 STD: 0.1430\n",
      "[330/600] Loss: 0.0204 MAE: 0.0215 Mean Error: -0.0023 STD: 0.1430\n",
      "[340/600] Loss: 0.0204 MAE: 0.0215 Mean Error: -0.0023 STD: 0.1430\n",
      "[350/600] Loss: 0.0204 MAE: 0.0215 Mean Error: -0.0023 STD: 0.1430\n",
      "[360/600] Loss: 0.0204 MAE: 0.0215 Mean Error: -0.0023 STD: 0.1430\n",
      "[370/600] Loss: 0.0204 MAE: 0.0215 Mean Error: -0.0023 STD: 0.1430\n",
      "[380/600] Loss: 0.0204 MAE: 0.0215 Mean Error: -0.0023 STD: 0.1430\n",
      "[390/600] Loss: 0.0204 MAE: 0.0215 Mean Error: -0.0023 STD: 0.1430\n",
      "[400/600] Loss: 0.0204 MAE: 0.0215 Mean Error: -0.0023 STD: 0.1430\n",
      "[410/600] Loss: 0.0204 MAE: 0.0215 Mean Error: -0.0023 STD: 0.1430\n",
      "[420/600] Loss: 0.0204 MAE: 0.0215 Mean Error: -0.0023 STD: 0.1430\n",
      "[430/600] Loss: 0.0204 MAE: 0.0215 Mean Error: -0.0023 STD: 0.1430\n",
      "[440/600] Loss: 0.0204 MAE: 0.0215 Mean Error: -0.0023 STD: 0.1430\n",
      "[450/600] Loss: 0.0204 MAE: 0.0215 Mean Error: -0.0023 STD: 0.1430\n",
      "[460/600] Loss: 0.0204 MAE: 0.0215 Mean Error: -0.0023 STD: 0.1430\n",
      "[470/600] Loss: 0.0204 MAE: 0.0215 Mean Error: -0.0023 STD: 0.1430\n",
      "[480/600] Loss: 0.0204 MAE: 0.0215 Mean Error: -0.0023 STD: 0.1430\n",
      "[490/600] Loss: 0.0204 MAE: 0.0215 Mean Error: -0.0023 STD: 0.1430\n",
      "[500/600] Loss: 0.0204 MAE: 0.0215 Mean Error: -0.0023 STD: 0.1430\n",
      "[510/600] Loss: 0.0204 MAE: 0.0215 Mean Error: -0.0023 STD: 0.1430\n",
      "[520/600] Loss: 0.0204 MAE: 0.0215 Mean Error: -0.0023 STD: 0.1430\n",
      "[530/600] Loss: 0.0204 MAE: 0.0215 Mean Error: -0.0023 STD: 0.1430\n",
      "[540/600] Loss: 0.0204 MAE: 0.0215 Mean Error: -0.0023 STD: 0.1430\n",
      "[550/600] Loss: 0.0204 MAE: 0.0215 Mean Error: -0.0023 STD: 0.1430\n",
      "[560/600] Loss: 0.0204 MAE: 0.0215 Mean Error: -0.0023 STD: 0.1430\n",
      "[570/600] Loss: 0.0204 MAE: 0.0215 Mean Error: -0.0023 STD: 0.1430\n",
      "[580/600] Loss: 0.0204 MAE: 0.0215 Mean Error: -0.0023 STD: 0.1430\n",
      "[590/600] Loss: 0.0204 MAE: 0.0215 Mean Error: -0.0023 STD: 0.1430\n",
      "[599/600] Loss: 0.0204 MAE: 0.0215 Mean Error: -0.0023 STD: 0.1430\n",
      "------------------------------------\n",
      "Training dataset with noise standard deviation 0.002\n",
      "[0/600] Loss: 0.0204 MAE: 0.0219 Mean Error: -0.0026 STD: 0.1430\n",
      "[10/600] Loss: 0.0204 MAE: 0.0219 Mean Error: -0.0026 STD: 0.1430\n",
      "[20/600] Loss: 0.0204 MAE: 0.0219 Mean Error: -0.0026 STD: 0.1430\n",
      "[30/600] Loss: 0.0204 MAE: 0.0219 Mean Error: -0.0026 STD: 0.1430\n",
      "[40/600] Loss: 0.0204 MAE: 0.0219 Mean Error: -0.0026 STD: 0.1430\n",
      "[50/600] Loss: 0.0204 MAE: 0.0219 Mean Error: -0.0026 STD: 0.1430\n",
      "[60/600] Loss: 0.0204 MAE: 0.0219 Mean Error: -0.0026 STD: 0.1430\n",
      "[70/600] Loss: 0.0204 MAE: 0.0219 Mean Error: -0.0026 STD: 0.1430\n",
      "[80/600] Loss: 0.0204 MAE: 0.0219 Mean Error: -0.0026 STD: 0.1430\n",
      "[90/600] Loss: 0.0204 MAE: 0.0219 Mean Error: -0.0026 STD: 0.1430\n",
      "[100/600] Loss: 0.0204 MAE: 0.0219 Mean Error: -0.0026 STD: 0.1430\n",
      "[110/600] Loss: 0.0204 MAE: 0.0219 Mean Error: -0.0026 STD: 0.1430\n",
      "[120/600] Loss: 0.0204 MAE: 0.0219 Mean Error: -0.0026 STD: 0.1430\n",
      "[130/600] Loss: 0.0204 MAE: 0.0219 Mean Error: -0.0026 STD: 0.1430\n",
      "[140/600] Loss: 0.0204 MAE: 0.0219 Mean Error: -0.0026 STD: 0.1430\n",
      "[150/600] Loss: 0.0204 MAE: 0.0219 Mean Error: -0.0026 STD: 0.1430\n",
      "[160/600] Loss: 0.0204 MAE: 0.0219 Mean Error: -0.0026 STD: 0.1430\n",
      "[170/600] Loss: 0.0204 MAE: 0.0219 Mean Error: -0.0026 STD: 0.1430\n",
      "[180/600] Loss: 0.0204 MAE: 0.0219 Mean Error: -0.0026 STD: 0.1430\n",
      "[190/600] Loss: 0.0204 MAE: 0.0219 Mean Error: -0.0026 STD: 0.1430\n",
      "[200/600] Loss: 0.0204 MAE: 0.0219 Mean Error: -0.0026 STD: 0.1430\n",
      "[210/600] Loss: 0.0204 MAE: 0.0219 Mean Error: -0.0026 STD: 0.1430\n",
      "[220/600] Loss: 0.0204 MAE: 0.0219 Mean Error: -0.0026 STD: 0.1430\n",
      "[230/600] Loss: 0.0204 MAE: 0.0219 Mean Error: -0.0026 STD: 0.1430\n",
      "[240/600] Loss: 0.0204 MAE: 0.0219 Mean Error: -0.0026 STD: 0.1430\n",
      "[250/600] Loss: 0.0204 MAE: 0.0219 Mean Error: -0.0026 STD: 0.1430\n",
      "[260/600] Loss: 0.0204 MAE: 0.0219 Mean Error: -0.0026 STD: 0.1430\n",
      "[270/600] Loss: 0.0204 MAE: 0.0219 Mean Error: -0.0026 STD: 0.1430\n",
      "[280/600] Loss: 0.0204 MAE: 0.0219 Mean Error: -0.0026 STD: 0.1430\n",
      "[290/600] Loss: 0.0204 MAE: 0.0219 Mean Error: -0.0026 STD: 0.1430\n",
      "[300/600] Loss: 0.0204 MAE: 0.0219 Mean Error: -0.0026 STD: 0.1430\n",
      "[310/600] Loss: 0.0204 MAE: 0.0219 Mean Error: -0.0026 STD: 0.1430\n",
      "[320/600] Loss: 0.0204 MAE: 0.0219 Mean Error: -0.0026 STD: 0.1430\n",
      "[330/600] Loss: 0.0204 MAE: 0.0219 Mean Error: -0.0026 STD: 0.1430\n",
      "[340/600] Loss: 0.0204 MAE: 0.0219 Mean Error: -0.0026 STD: 0.1430\n",
      "[350/600] Loss: 0.0204 MAE: 0.0219 Mean Error: -0.0026 STD: 0.1430\n",
      "[360/600] Loss: 0.0204 MAE: 0.0219 Mean Error: -0.0026 STD: 0.1430\n",
      "[370/600] Loss: 0.0204 MAE: 0.0219 Mean Error: -0.0026 STD: 0.1430\n",
      "[380/600] Loss: 0.0204 MAE: 0.0219 Mean Error: -0.0026 STD: 0.1430\n",
      "[390/600] Loss: 0.0204 MAE: 0.0219 Mean Error: -0.0026 STD: 0.1430\n",
      "[400/600] Loss: 0.0204 MAE: 0.0219 Mean Error: -0.0026 STD: 0.1430\n",
      "[410/600] Loss: 0.0204 MAE: 0.0219 Mean Error: -0.0026 STD: 0.1430\n",
      "[420/600] Loss: 0.0204 MAE: 0.0219 Mean Error: -0.0026 STD: 0.1430\n",
      "[430/600] Loss: 0.0204 MAE: 0.0219 Mean Error: -0.0026 STD: 0.1430\n",
      "[440/600] Loss: 0.0204 MAE: 0.0219 Mean Error: -0.0026 STD: 0.1430\n",
      "[450/600] Loss: 0.0204 MAE: 0.0219 Mean Error: -0.0026 STD: 0.1430\n",
      "[460/600] Loss: 0.0204 MAE: 0.0219 Mean Error: -0.0026 STD: 0.1430\n",
      "[470/600] Loss: 0.0204 MAE: 0.0219 Mean Error: -0.0026 STD: 0.1430\n",
      "[480/600] Loss: 0.0204 MAE: 0.0219 Mean Error: -0.0026 STD: 0.1430\n",
      "[490/600] Loss: 0.0204 MAE: 0.0219 Mean Error: -0.0026 STD: 0.1430\n",
      "[500/600] Loss: 0.0204 MAE: 0.0219 Mean Error: -0.0026 STD: 0.1430\n",
      "[510/600] Loss: 0.0204 MAE: 0.0219 Mean Error: -0.0026 STD: 0.1430\n",
      "[520/600] Loss: 0.0204 MAE: 0.0219 Mean Error: -0.0026 STD: 0.1430\n",
      "[530/600] Loss: 0.0204 MAE: 0.0219 Mean Error: -0.0026 STD: 0.1430\n",
      "[540/600] Loss: 0.0204 MAE: 0.0219 Mean Error: -0.0026 STD: 0.1430\n",
      "[550/600] Loss: 0.0204 MAE: 0.0219 Mean Error: -0.0026 STD: 0.1430\n",
      "[560/600] Loss: 0.0204 MAE: 0.0219 Mean Error: -0.0026 STD: 0.1430\n",
      "[570/600] Loss: 0.0204 MAE: 0.0219 Mean Error: -0.0026 STD: 0.1430\n",
      "[580/600] Loss: 0.0204 MAE: 0.0219 Mean Error: -0.0026 STD: 0.1430\n",
      "[590/600] Loss: 0.0204 MAE: 0.0219 Mean Error: -0.0026 STD: 0.1430\n",
      "[599/600] Loss: 0.0204 MAE: 0.0219 Mean Error: -0.0026 STD: 0.1430\n",
      "------------------------------------\n",
      "Training dataset with noise standard deviation 0.003\n",
      "[0/600] Loss: 0.0204 MAE: 0.0222 Mean Error: -0.0029 STD: 0.1428\n",
      "[10/600] Loss: 0.0204 MAE: 0.0222 Mean Error: -0.0029 STD: 0.1428\n",
      "[20/600] Loss: 0.0204 MAE: 0.0222 Mean Error: -0.0029 STD: 0.1428\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30/600] Loss: 0.0204 MAE: 0.0222 Mean Error: -0.0029 STD: 0.1428\n",
      "[40/600] Loss: 0.0204 MAE: 0.0222 Mean Error: -0.0029 STD: 0.1428\n",
      "[50/600] Loss: 0.0204 MAE: 0.0222 Mean Error: -0.0029 STD: 0.1428\n",
      "[60/600] Loss: 0.0204 MAE: 0.0222 Mean Error: -0.0029 STD: 0.1428\n",
      "[70/600] Loss: 0.0204 MAE: 0.0222 Mean Error: -0.0029 STD: 0.1428\n",
      "[80/600] Loss: 0.0204 MAE: 0.0222 Mean Error: -0.0029 STD: 0.1428\n",
      "[90/600] Loss: 0.0204 MAE: 0.0222 Mean Error: -0.0029 STD: 0.1428\n",
      "[100/600] Loss: 0.0204 MAE: 0.0222 Mean Error: -0.0029 STD: 0.1428\n",
      "[110/600] Loss: 0.0204 MAE: 0.0222 Mean Error: -0.0029 STD: 0.1428\n",
      "[120/600] Loss: 0.0204 MAE: 0.0222 Mean Error: -0.0029 STD: 0.1428\n",
      "[130/600] Loss: 0.0204 MAE: 0.0222 Mean Error: -0.0029 STD: 0.1428\n",
      "[140/600] Loss: 0.0204 MAE: 0.0222 Mean Error: -0.0029 STD: 0.1428\n",
      "[150/600] Loss: 0.0204 MAE: 0.0222 Mean Error: -0.0029 STD: 0.1428\n",
      "[160/600] Loss: 0.0204 MAE: 0.0222 Mean Error: -0.0029 STD: 0.1428\n",
      "[170/600] Loss: 0.0204 MAE: 0.0222 Mean Error: -0.0029 STD: 0.1428\n",
      "[180/600] Loss: 0.0204 MAE: 0.0222 Mean Error: -0.0029 STD: 0.1428\n",
      "[190/600] Loss: 0.0204 MAE: 0.0222 Mean Error: -0.0029 STD: 0.1428\n",
      "[200/600] Loss: 0.0204 MAE: 0.0222 Mean Error: -0.0029 STD: 0.1428\n",
      "[210/600] Loss: 0.0204 MAE: 0.0222 Mean Error: -0.0029 STD: 0.1428\n",
      "[220/600] Loss: 0.0204 MAE: 0.0222 Mean Error: -0.0029 STD: 0.1428\n",
      "[230/600] Loss: 0.0204 MAE: 0.0222 Mean Error: -0.0029 STD: 0.1428\n",
      "[240/600] Loss: 0.0204 MAE: 0.0222 Mean Error: -0.0029 STD: 0.1428\n",
      "[250/600] Loss: 0.0204 MAE: 0.0222 Mean Error: -0.0029 STD: 0.1428\n",
      "[260/600] Loss: 0.0204 MAE: 0.0222 Mean Error: -0.0029 STD: 0.1428\n",
      "[270/600] Loss: 0.0204 MAE: 0.0222 Mean Error: -0.0029 STD: 0.1428\n",
      "[280/600] Loss: 0.0204 MAE: 0.0222 Mean Error: -0.0029 STD: 0.1428\n",
      "[290/600] Loss: 0.0204 MAE: 0.0222 Mean Error: -0.0029 STD: 0.1428\n",
      "[300/600] Loss: 0.0204 MAE: 0.0222 Mean Error: -0.0029 STD: 0.1428\n",
      "[310/600] Loss: 0.0204 MAE: 0.0222 Mean Error: -0.0029 STD: 0.1428\n",
      "[320/600] Loss: 0.0204 MAE: 0.0222 Mean Error: -0.0029 STD: 0.1428\n",
      "[330/600] Loss: 0.0204 MAE: 0.0222 Mean Error: -0.0029 STD: 0.1428\n",
      "[340/600] Loss: 0.0204 MAE: 0.0222 Mean Error: -0.0029 STD: 0.1428\n",
      "[350/600] Loss: 0.0204 MAE: 0.0222 Mean Error: -0.0029 STD: 0.1428\n",
      "[360/600] Loss: 0.0204 MAE: 0.0222 Mean Error: -0.0029 STD: 0.1428\n",
      "[370/600] Loss: 0.0204 MAE: 0.0222 Mean Error: -0.0029 STD: 0.1428\n",
      "[380/600] Loss: 0.0204 MAE: 0.0222 Mean Error: -0.0029 STD: 0.1428\n",
      "[390/600] Loss: 0.0204 MAE: 0.0222 Mean Error: -0.0029 STD: 0.1428\n",
      "[400/600] Loss: 0.0204 MAE: 0.0222 Mean Error: -0.0029 STD: 0.1428\n",
      "[410/600] Loss: 0.0204 MAE: 0.0222 Mean Error: -0.0029 STD: 0.1428\n",
      "[420/600] Loss: 0.0204 MAE: 0.0222 Mean Error: -0.0029 STD: 0.1428\n",
      "[430/600] Loss: 0.0204 MAE: 0.0222 Mean Error: -0.0029 STD: 0.1428\n",
      "[440/600] Loss: 0.0204 MAE: 0.0222 Mean Error: -0.0029 STD: 0.1428\n",
      "[450/600] Loss: 0.0204 MAE: 0.0222 Mean Error: -0.0029 STD: 0.1428\n",
      "[460/600] Loss: 0.0204 MAE: 0.0222 Mean Error: -0.0029 STD: 0.1428\n",
      "[470/600] Loss: 0.0204 MAE: 0.0222 Mean Error: -0.0029 STD: 0.1428\n",
      "[480/600] Loss: 0.0204 MAE: 0.0222 Mean Error: -0.0029 STD: 0.1428\n",
      "[490/600] Loss: 0.0204 MAE: 0.0222 Mean Error: -0.0029 STD: 0.1428\n",
      "[500/600] Loss: 0.0204 MAE: 0.0222 Mean Error: -0.0029 STD: 0.1428\n",
      "[510/600] Loss: 0.0204 MAE: 0.0222 Mean Error: -0.0029 STD: 0.1428\n",
      "[520/600] Loss: 0.0204 MAE: 0.0222 Mean Error: -0.0029 STD: 0.1428\n",
      "[530/600] Loss: 0.0204 MAE: 0.0222 Mean Error: -0.0029 STD: 0.1428\n",
      "[540/600] Loss: 0.0204 MAE: 0.0222 Mean Error: -0.0029 STD: 0.1428\n",
      "[550/600] Loss: 0.0204 MAE: 0.0222 Mean Error: -0.0029 STD: 0.1428\n",
      "[560/600] Loss: 0.0204 MAE: 0.0222 Mean Error: -0.0029 STD: 0.1428\n",
      "[570/600] Loss: 0.0204 MAE: 0.0222 Mean Error: -0.0029 STD: 0.1428\n",
      "[580/600] Loss: 0.0204 MAE: 0.0222 Mean Error: -0.0029 STD: 0.1428\n",
      "[590/600] Loss: 0.0204 MAE: 0.0222 Mean Error: -0.0029 STD: 0.1428\n",
      "[599/600] Loss: 0.0204 MAE: 0.0222 Mean Error: -0.0029 STD: 0.1428\n",
      "------------------------------------\n",
      "Training dataset with noise standard deviation 0.005\n",
      "[0/600] Loss: 0.0204 MAE: 0.0230 Mean Error: -0.0035 STD: 0.1427\n",
      "[10/600] Loss: 0.0204 MAE: 0.0230 Mean Error: -0.0035 STD: 0.1427\n",
      "[20/600] Loss: 0.0204 MAE: 0.0230 Mean Error: -0.0035 STD: 0.1427\n",
      "[30/600] Loss: 0.0204 MAE: 0.0230 Mean Error: -0.0035 STD: 0.1427\n",
      "[40/600] Loss: 0.0204 MAE: 0.0230 Mean Error: -0.0035 STD: 0.1427\n",
      "[50/600] Loss: 0.0204 MAE: 0.0230 Mean Error: -0.0035 STD: 0.1427\n",
      "[60/600] Loss: 0.0204 MAE: 0.0230 Mean Error: -0.0035 STD: 0.1427\n",
      "[70/600] Loss: 0.0204 MAE: 0.0230 Mean Error: -0.0035 STD: 0.1427\n",
      "[80/600] Loss: 0.0204 MAE: 0.0230 Mean Error: -0.0035 STD: 0.1427\n",
      "[90/600] Loss: 0.0204 MAE: 0.0230 Mean Error: -0.0035 STD: 0.1427\n",
      "[100/600] Loss: 0.0204 MAE: 0.0230 Mean Error: -0.0035 STD: 0.1427\n",
      "[110/600] Loss: 0.0204 MAE: 0.0230 Mean Error: -0.0035 STD: 0.1427\n",
      "[120/600] Loss: 0.0204 MAE: 0.0230 Mean Error: -0.0035 STD: 0.1427\n",
      "[130/600] Loss: 0.0204 MAE: 0.0230 Mean Error: -0.0035 STD: 0.1427\n",
      "[140/600] Loss: 0.0204 MAE: 0.0230 Mean Error: -0.0035 STD: 0.1427\n",
      "[150/600] Loss: 0.0204 MAE: 0.0230 Mean Error: -0.0035 STD: 0.1427\n",
      "[160/600] Loss: 0.0204 MAE: 0.0230 Mean Error: -0.0035 STD: 0.1427\n",
      "[170/600] Loss: 0.0204 MAE: 0.0230 Mean Error: -0.0035 STD: 0.1427\n",
      "[180/600] Loss: 0.0204 MAE: 0.0230 Mean Error: -0.0035 STD: 0.1427\n",
      "[190/600] Loss: 0.0204 MAE: 0.0230 Mean Error: -0.0035 STD: 0.1427\n",
      "[200/600] Loss: 0.0204 MAE: 0.0230 Mean Error: -0.0035 STD: 0.1427\n",
      "[210/600] Loss: 0.0204 MAE: 0.0230 Mean Error: -0.0035 STD: 0.1427\n",
      "[220/600] Loss: 0.0204 MAE: 0.0230 Mean Error: -0.0035 STD: 0.1427\n",
      "[230/600] Loss: 0.0204 MAE: 0.0230 Mean Error: -0.0035 STD: 0.1427\n",
      "[240/600] Loss: 0.0204 MAE: 0.0230 Mean Error: -0.0035 STD: 0.1427\n",
      "[250/600] Loss: 0.0204 MAE: 0.0230 Mean Error: -0.0035 STD: 0.1427\n",
      "[260/600] Loss: 0.0204 MAE: 0.0230 Mean Error: -0.0035 STD: 0.1427\n",
      "[270/600] Loss: 0.0204 MAE: 0.0230 Mean Error: -0.0035 STD: 0.1427\n",
      "[280/600] Loss: 0.0204 MAE: 0.0230 Mean Error: -0.0035 STD: 0.1427\n",
      "[290/600] Loss: 0.0204 MAE: 0.0230 Mean Error: -0.0035 STD: 0.1427\n",
      "[300/600] Loss: 0.0204 MAE: 0.0230 Mean Error: -0.0035 STD: 0.1427\n",
      "[310/600] Loss: 0.0204 MAE: 0.0230 Mean Error: -0.0035 STD: 0.1427\n",
      "[320/600] Loss: 0.0204 MAE: 0.0230 Mean Error: -0.0035 STD: 0.1427\n",
      "[330/600] Loss: 0.0204 MAE: 0.0230 Mean Error: -0.0035 STD: 0.1427\n",
      "[340/600] Loss: 0.0204 MAE: 0.0230 Mean Error: -0.0035 STD: 0.1427\n",
      "[350/600] Loss: 0.0204 MAE: 0.0230 Mean Error: -0.0035 STD: 0.1427\n",
      "[360/600] Loss: 0.0204 MAE: 0.0230 Mean Error: -0.0035 STD: 0.1427\n",
      "[370/600] Loss: 0.0204 MAE: 0.0230 Mean Error: -0.0035 STD: 0.1427\n",
      "[380/600] Loss: 0.0204 MAE: 0.0230 Mean Error: -0.0035 STD: 0.1427\n",
      "[390/600] Loss: 0.0204 MAE: 0.0230 Mean Error: -0.0035 STD: 0.1427\n",
      "[400/600] Loss: 0.0204 MAE: 0.0230 Mean Error: -0.0035 STD: 0.1427\n",
      "[410/600] Loss: 0.0204 MAE: 0.0230 Mean Error: -0.0035 STD: 0.1427\n",
      "[420/600] Loss: 0.0204 MAE: 0.0230 Mean Error: -0.0035 STD: 0.1427\n",
      "[430/600] Loss: 0.0204 MAE: 0.0230 Mean Error: -0.0035 STD: 0.1427\n",
      "[440/600] Loss: 0.0204 MAE: 0.0230 Mean Error: -0.0035 STD: 0.1427\n",
      "[450/600] Loss: 0.0204 MAE: 0.0230 Mean Error: -0.0035 STD: 0.1427\n",
      "[460/600] Loss: 0.0204 MAE: 0.0230 Mean Error: -0.0035 STD: 0.1427\n",
      "[470/600] Loss: 0.0204 MAE: 0.0230 Mean Error: -0.0035 STD: 0.1427\n",
      "[480/600] Loss: 0.0204 MAE: 0.0230 Mean Error: -0.0035 STD: 0.1427\n",
      "[490/600] Loss: 0.0204 MAE: 0.0230 Mean Error: -0.0035 STD: 0.1427\n",
      "[500/600] Loss: 0.0204 MAE: 0.0230 Mean Error: -0.0035 STD: 0.1427\n",
      "[510/600] Loss: 0.0204 MAE: 0.0230 Mean Error: -0.0035 STD: 0.1427\n",
      "[520/600] Loss: 0.0204 MAE: 0.0230 Mean Error: -0.0035 STD: 0.1427\n",
      "[530/600] Loss: 0.0204 MAE: 0.0230 Mean Error: -0.0035 STD: 0.1427\n",
      "[540/600] Loss: 0.0204 MAE: 0.0230 Mean Error: -0.0035 STD: 0.1427\n",
      "[550/600] Loss: 0.0204 MAE: 0.0230 Mean Error: -0.0035 STD: 0.1427\n",
      "[560/600] Loss: 0.0204 MAE: 0.0230 Mean Error: -0.0035 STD: 0.1427\n",
      "[570/600] Loss: 0.0204 MAE: 0.0230 Mean Error: -0.0035 STD: 0.1427\n",
      "[580/600] Loss: 0.0204 MAE: 0.0230 Mean Error: -0.0035 STD: 0.1427\n",
      "[590/600] Loss: 0.0204 MAE: 0.0230 Mean Error: -0.0035 STD: 0.1427\n",
      "[599/600] Loss: 0.0204 MAE: 0.0230 Mean Error: -0.0035 STD: 0.1427\n",
      "------------------------------------\n",
      "Training dataset with noise standard deviation 0.01\n",
      "[0/600] Loss: 0.0204 MAE: 0.0251 Mean Error: -0.0055 STD: 0.1426\n",
      "[10/600] Loss: 0.0204 MAE: 0.0251 Mean Error: -0.0055 STD: 0.1426\n",
      "[20/600] Loss: 0.0204 MAE: 0.0251 Mean Error: -0.0055 STD: 0.1426\n",
      "[30/600] Loss: 0.0204 MAE: 0.0251 Mean Error: -0.0055 STD: 0.1426\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[40/600] Loss: 0.0204 MAE: 0.0251 Mean Error: -0.0055 STD: 0.1426\n",
      "[50/600] Loss: 0.0204 MAE: 0.0251 Mean Error: -0.0055 STD: 0.1426\n",
      "[60/600] Loss: 0.0204 MAE: 0.0251 Mean Error: -0.0055 STD: 0.1426\n",
      "[70/600] Loss: 0.0204 MAE: 0.0251 Mean Error: -0.0055 STD: 0.1426\n",
      "[80/600] Loss: 0.0204 MAE: 0.0251 Mean Error: -0.0055 STD: 0.1426\n",
      "[90/600] Loss: 0.0204 MAE: 0.0251 Mean Error: -0.0055 STD: 0.1426\n",
      "[100/600] Loss: 0.0204 MAE: 0.0251 Mean Error: -0.0055 STD: 0.1426\n",
      "[110/600] Loss: 0.0204 MAE: 0.0251 Mean Error: -0.0055 STD: 0.1426\n",
      "[120/600] Loss: 0.0204 MAE: 0.0251 Mean Error: -0.0055 STD: 0.1426\n",
      "[130/600] Loss: 0.0204 MAE: 0.0251 Mean Error: -0.0055 STD: 0.1426\n",
      "[140/600] Loss: 0.0204 MAE: 0.0251 Mean Error: -0.0055 STD: 0.1426\n",
      "[150/600] Loss: 0.0204 MAE: 0.0251 Mean Error: -0.0055 STD: 0.1426\n",
      "[160/600] Loss: 0.0204 MAE: 0.0251 Mean Error: -0.0055 STD: 0.1426\n",
      "[170/600] Loss: 0.0204 MAE: 0.0251 Mean Error: -0.0055 STD: 0.1426\n",
      "[180/600] Loss: 0.0204 MAE: 0.0251 Mean Error: -0.0055 STD: 0.1426\n",
      "[190/600] Loss: 0.0204 MAE: 0.0251 Mean Error: -0.0055 STD: 0.1426\n",
      "[200/600] Loss: 0.0204 MAE: 0.0251 Mean Error: -0.0055 STD: 0.1426\n",
      "[210/600] Loss: 0.0204 MAE: 0.0251 Mean Error: -0.0055 STD: 0.1426\n",
      "[220/600] Loss: 0.0204 MAE: 0.0251 Mean Error: -0.0055 STD: 0.1426\n",
      "[230/600] Loss: 0.0204 MAE: 0.0251 Mean Error: -0.0055 STD: 0.1426\n",
      "[240/600] Loss: 0.0204 MAE: 0.0251 Mean Error: -0.0055 STD: 0.1426\n",
      "[250/600] Loss: 0.0204 MAE: 0.0251 Mean Error: -0.0055 STD: 0.1426\n",
      "[260/600] Loss: 0.0204 MAE: 0.0251 Mean Error: -0.0055 STD: 0.1426\n",
      "[270/600] Loss: 0.0204 MAE: 0.0251 Mean Error: -0.0055 STD: 0.1426\n",
      "[280/600] Loss: 0.0204 MAE: 0.0251 Mean Error: -0.0055 STD: 0.1426\n",
      "[290/600] Loss: 0.0204 MAE: 0.0251 Mean Error: -0.0055 STD: 0.1426\n",
      "[300/600] Loss: 0.0204 MAE: 0.0251 Mean Error: -0.0055 STD: 0.1426\n",
      "[310/600] Loss: 0.0204 MAE: 0.0251 Mean Error: -0.0055 STD: 0.1426\n",
      "[320/600] Loss: 0.0204 MAE: 0.0251 Mean Error: -0.0055 STD: 0.1426\n",
      "[330/600] Loss: 0.0204 MAE: 0.0251 Mean Error: -0.0055 STD: 0.1426\n",
      "[340/600] Loss: 0.0204 MAE: 0.0251 Mean Error: -0.0055 STD: 0.1426\n",
      "[350/600] Loss: 0.0204 MAE: 0.0251 Mean Error: -0.0055 STD: 0.1426\n",
      "[360/600] Loss: 0.0204 MAE: 0.0251 Mean Error: -0.0055 STD: 0.1426\n",
      "[370/600] Loss: 0.0204 MAE: 0.0251 Mean Error: -0.0055 STD: 0.1426\n",
      "[380/600] Loss: 0.0204 MAE: 0.0251 Mean Error: -0.0055 STD: 0.1426\n",
      "[390/600] Loss: 0.0204 MAE: 0.0251 Mean Error: -0.0055 STD: 0.1426\n",
      "[400/600] Loss: 0.0204 MAE: 0.0251 Mean Error: -0.0055 STD: 0.1426\n",
      "[410/600] Loss: 0.0204 MAE: 0.0251 Mean Error: -0.0055 STD: 0.1426\n",
      "[420/600] Loss: 0.0204 MAE: 0.0251 Mean Error: -0.0055 STD: 0.1426\n",
      "[430/600] Loss: 0.0204 MAE: 0.0251 Mean Error: -0.0055 STD: 0.1426\n",
      "[440/600] Loss: 0.0204 MAE: 0.0251 Mean Error: -0.0055 STD: 0.1426\n",
      "[450/600] Loss: 0.0204 MAE: 0.0251 Mean Error: -0.0055 STD: 0.1426\n",
      "[460/600] Loss: 0.0204 MAE: 0.0251 Mean Error: -0.0055 STD: 0.1426\n",
      "[470/600] Loss: 0.0204 MAE: 0.0251 Mean Error: -0.0055 STD: 0.1426\n",
      "[480/600] Loss: 0.0204 MAE: 0.0251 Mean Error: -0.0055 STD: 0.1426\n",
      "[490/600] Loss: 0.0204 MAE: 0.0251 Mean Error: -0.0055 STD: 0.1426\n",
      "[500/600] Loss: 0.0204 MAE: 0.0251 Mean Error: -0.0055 STD: 0.1426\n",
      "[510/600] Loss: 0.0204 MAE: 0.0251 Mean Error: -0.0055 STD: 0.1426\n",
      "[520/600] Loss: 0.0204 MAE: 0.0251 Mean Error: -0.0055 STD: 0.1426\n",
      "[530/600] Loss: 0.0204 MAE: 0.0251 Mean Error: -0.0055 STD: 0.1426\n",
      "[540/600] Loss: 0.0204 MAE: 0.0251 Mean Error: -0.0055 STD: 0.1426\n",
      "[550/600] Loss: 0.0204 MAE: 0.0251 Mean Error: -0.0055 STD: 0.1426\n",
      "[560/600] Loss: 0.0204 MAE: 0.0251 Mean Error: -0.0055 STD: 0.1426\n",
      "[570/600] Loss: 0.0204 MAE: 0.0251 Mean Error: -0.0055 STD: 0.1426\n",
      "[580/600] Loss: 0.0204 MAE: 0.0251 Mean Error: -0.0055 STD: 0.1426\n",
      "[590/600] Loss: 0.0204 MAE: 0.0251 Mean Error: -0.0055 STD: 0.1426\n",
      "[599/600] Loss: 0.0204 MAE: 0.0251 Mean Error: -0.0055 STD: 0.1426\n",
      "------------------------------------\n",
      "Training dataset with noise standard deviation 0.02\n",
      "[0/600] Loss: 0.0204 MAE: 0.0287 Mean Error: -0.0084 STD: 0.1425\n",
      "[10/600] Loss: 0.0204 MAE: 0.0287 Mean Error: -0.0084 STD: 0.1425\n",
      "[20/600] Loss: 0.0204 MAE: 0.0287 Mean Error: -0.0084 STD: 0.1425\n",
      "[30/600] Loss: 0.0204 MAE: 0.0287 Mean Error: -0.0084 STD: 0.1425\n",
      "[40/600] Loss: 0.0204 MAE: 0.0287 Mean Error: -0.0084 STD: 0.1425\n",
      "[50/600] Loss: 0.0204 MAE: 0.0287 Mean Error: -0.0084 STD: 0.1425\n",
      "[60/600] Loss: 0.0204 MAE: 0.0287 Mean Error: -0.0084 STD: 0.1425\n",
      "[70/600] Loss: 0.0204 MAE: 0.0287 Mean Error: -0.0084 STD: 0.1425\n",
      "[80/600] Loss: 0.0204 MAE: 0.0287 Mean Error: -0.0084 STD: 0.1425\n",
      "[90/600] Loss: 0.0204 MAE: 0.0287 Mean Error: -0.0084 STD: 0.1425\n",
      "[100/600] Loss: 0.0204 MAE: 0.0287 Mean Error: -0.0084 STD: 0.1425\n",
      "[110/600] Loss: 0.0204 MAE: 0.0287 Mean Error: -0.0084 STD: 0.1425\n",
      "[120/600] Loss: 0.0204 MAE: 0.0287 Mean Error: -0.0084 STD: 0.1425\n",
      "[130/600] Loss: 0.0204 MAE: 0.0287 Mean Error: -0.0084 STD: 0.1425\n",
      "[140/600] Loss: 0.0204 MAE: 0.0287 Mean Error: -0.0084 STD: 0.1425\n",
      "[150/600] Loss: 0.0204 MAE: 0.0287 Mean Error: -0.0084 STD: 0.1425\n",
      "[160/600] Loss: 0.0204 MAE: 0.0287 Mean Error: -0.0084 STD: 0.1425\n",
      "[170/600] Loss: 0.0204 MAE: 0.0287 Mean Error: -0.0084 STD: 0.1425\n",
      "[180/600] Loss: 0.0204 MAE: 0.0287 Mean Error: -0.0084 STD: 0.1425\n",
      "[190/600] Loss: 0.0204 MAE: 0.0287 Mean Error: -0.0084 STD: 0.1425\n",
      "[200/600] Loss: 0.0204 MAE: 0.0287 Mean Error: -0.0084 STD: 0.1425\n",
      "[210/600] Loss: 0.0204 MAE: 0.0287 Mean Error: -0.0084 STD: 0.1425\n",
      "[220/600] Loss: 0.0204 MAE: 0.0287 Mean Error: -0.0084 STD: 0.1425\n",
      "[230/600] Loss: 0.0204 MAE: 0.0287 Mean Error: -0.0084 STD: 0.1425\n",
      "[240/600] Loss: 0.0204 MAE: 0.0287 Mean Error: -0.0084 STD: 0.1425\n",
      "[250/600] Loss: 0.0204 MAE: 0.0287 Mean Error: -0.0084 STD: 0.1425\n",
      "[260/600] Loss: 0.0204 MAE: 0.0287 Mean Error: -0.0084 STD: 0.1425\n",
      "[270/600] Loss: 0.0204 MAE: 0.0287 Mean Error: -0.0084 STD: 0.1425\n",
      "[280/600] Loss: 0.0204 MAE: 0.0287 Mean Error: -0.0084 STD: 0.1425\n",
      "[290/600] Loss: 0.0204 MAE: 0.0287 Mean Error: -0.0084 STD: 0.1425\n",
      "[300/600] Loss: 0.0204 MAE: 0.0287 Mean Error: -0.0084 STD: 0.1425\n",
      "[310/600] Loss: 0.0204 MAE: 0.0287 Mean Error: -0.0084 STD: 0.1425\n",
      "[320/600] Loss: 0.0204 MAE: 0.0287 Mean Error: -0.0084 STD: 0.1425\n",
      "[330/600] Loss: 0.0204 MAE: 0.0287 Mean Error: -0.0084 STD: 0.1425\n",
      "[340/600] Loss: 0.0204 MAE: 0.0287 Mean Error: -0.0084 STD: 0.1425\n",
      "[350/600] Loss: 0.0204 MAE: 0.0287 Mean Error: -0.0084 STD: 0.1425\n",
      "[360/600] Loss: 0.0204 MAE: 0.0287 Mean Error: -0.0084 STD: 0.1425\n",
      "[370/600] Loss: 0.0204 MAE: 0.0287 Mean Error: -0.0084 STD: 0.1425\n",
      "[380/600] Loss: 0.0204 MAE: 0.0287 Mean Error: -0.0084 STD: 0.1425\n",
      "[390/600] Loss: 0.0204 MAE: 0.0287 Mean Error: -0.0084 STD: 0.1425\n",
      "[400/600] Loss: 0.0204 MAE: 0.0287 Mean Error: -0.0084 STD: 0.1425\n",
      "[410/600] Loss: 0.0204 MAE: 0.0287 Mean Error: -0.0084 STD: 0.1425\n",
      "[420/600] Loss: 0.0204 MAE: 0.0287 Mean Error: -0.0084 STD: 0.1425\n",
      "[430/600] Loss: 0.0204 MAE: 0.0287 Mean Error: -0.0084 STD: 0.1425\n",
      "[440/600] Loss: 0.0204 MAE: 0.0287 Mean Error: -0.0084 STD: 0.1425\n",
      "[450/600] Loss: 0.0204 MAE: 0.0287 Mean Error: -0.0084 STD: 0.1425\n",
      "[460/600] Loss: 0.0204 MAE: 0.0287 Mean Error: -0.0084 STD: 0.1425\n",
      "[470/600] Loss: 0.0204 MAE: 0.0287 Mean Error: -0.0084 STD: 0.1425\n",
      "[480/600] Loss: 0.0204 MAE: 0.0287 Mean Error: -0.0084 STD: 0.1425\n",
      "[490/600] Loss: 0.0204 MAE: 0.0287 Mean Error: -0.0084 STD: 0.1425\n",
      "[500/600] Loss: 0.0204 MAE: 0.0287 Mean Error: -0.0084 STD: 0.1425\n",
      "[510/600] Loss: 0.0204 MAE: 0.0287 Mean Error: -0.0084 STD: 0.1425\n",
      "[520/600] Loss: 0.0204 MAE: 0.0287 Mean Error: -0.0084 STD: 0.1425\n",
      "[530/600] Loss: 0.0204 MAE: 0.0287 Mean Error: -0.0084 STD: 0.1425\n",
      "[540/600] Loss: 0.0204 MAE: 0.0287 Mean Error: -0.0084 STD: 0.1425\n",
      "[550/600] Loss: 0.0204 MAE: 0.0287 Mean Error: -0.0084 STD: 0.1425\n",
      "[560/600] Loss: 0.0204 MAE: 0.0287 Mean Error: -0.0084 STD: 0.1425\n",
      "[570/600] Loss: 0.0204 MAE: 0.0287 Mean Error: -0.0084 STD: 0.1425\n",
      "[580/600] Loss: 0.0204 MAE: 0.0287 Mean Error: -0.0084 STD: 0.1425\n",
      "[590/600] Loss: 0.0204 MAE: 0.0287 Mean Error: -0.0084 STD: 0.1425\n",
      "[599/600] Loss: 0.0204 MAE: 0.0287 Mean Error: -0.0084 STD: 0.1425\n",
      "------------------------------------\n",
      "Training dataset with noise standard deviation 0.03\n",
      "[0/600] Loss: 0.0205 MAE: 0.0326 Mean Error: -0.0117 STD: 0.1429\n",
      "[10/600] Loss: 0.0205 MAE: 0.0326 Mean Error: -0.0117 STD: 0.1429\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20/600] Loss: 0.0205 MAE: 0.0326 Mean Error: -0.0117 STD: 0.1429\n",
      "[30/600] Loss: 0.0205 MAE: 0.0326 Mean Error: -0.0117 STD: 0.1429\n",
      "[40/600] Loss: 0.0205 MAE: 0.0326 Mean Error: -0.0117 STD: 0.1429\n",
      "[50/600] Loss: 0.0205 MAE: 0.0326 Mean Error: -0.0117 STD: 0.1429\n",
      "[60/600] Loss: 0.0205 MAE: 0.0326 Mean Error: -0.0117 STD: 0.1429\n",
      "[70/600] Loss: 0.0205 MAE: 0.0326 Mean Error: -0.0117 STD: 0.1429\n",
      "[80/600] Loss: 0.0205 MAE: 0.0326 Mean Error: -0.0117 STD: 0.1429\n",
      "[90/600] Loss: 0.0205 MAE: 0.0326 Mean Error: -0.0117 STD: 0.1429\n",
      "[100/600] Loss: 0.0205 MAE: 0.0326 Mean Error: -0.0117 STD: 0.1429\n",
      "[110/600] Loss: 0.0205 MAE: 0.0326 Mean Error: -0.0117 STD: 0.1429\n",
      "[120/600] Loss: 0.0205 MAE: 0.0326 Mean Error: -0.0117 STD: 0.1429\n",
      "[130/600] Loss: 0.0205 MAE: 0.0326 Mean Error: -0.0117 STD: 0.1429\n",
      "[140/600] Loss: 0.0205 MAE: 0.0326 Mean Error: -0.0117 STD: 0.1429\n",
      "[150/600] Loss: 0.0205 MAE: 0.0326 Mean Error: -0.0117 STD: 0.1429\n",
      "[160/600] Loss: 0.0205 MAE: 0.0326 Mean Error: -0.0117 STD: 0.1429\n",
      "[170/600] Loss: 0.0205 MAE: 0.0326 Mean Error: -0.0117 STD: 0.1429\n",
      "[180/600] Loss: 0.0205 MAE: 0.0326 Mean Error: -0.0117 STD: 0.1429\n",
      "[190/600] Loss: 0.0205 MAE: 0.0326 Mean Error: -0.0117 STD: 0.1429\n",
      "[200/600] Loss: 0.0205 MAE: 0.0326 Mean Error: -0.0117 STD: 0.1429\n",
      "[210/600] Loss: 0.0205 MAE: 0.0326 Mean Error: -0.0117 STD: 0.1429\n",
      "[220/600] Loss: 0.0205 MAE: 0.0326 Mean Error: -0.0117 STD: 0.1429\n",
      "[230/600] Loss: 0.0205 MAE: 0.0326 Mean Error: -0.0117 STD: 0.1429\n",
      "[240/600] Loss: 0.0205 MAE: 0.0326 Mean Error: -0.0117 STD: 0.1429\n",
      "[250/600] Loss: 0.0205 MAE: 0.0326 Mean Error: -0.0117 STD: 0.1429\n",
      "[260/600] Loss: 0.0205 MAE: 0.0326 Mean Error: -0.0117 STD: 0.1429\n",
      "[270/600] Loss: 0.0205 MAE: 0.0326 Mean Error: -0.0117 STD: 0.1429\n",
      "[280/600] Loss: 0.0205 MAE: 0.0326 Mean Error: -0.0117 STD: 0.1429\n",
      "[290/600] Loss: 0.0205 MAE: 0.0326 Mean Error: -0.0117 STD: 0.1429\n",
      "[300/600] Loss: 0.0205 MAE: 0.0326 Mean Error: -0.0117 STD: 0.1429\n",
      "[310/600] Loss: 0.0205 MAE: 0.0326 Mean Error: -0.0117 STD: 0.1429\n",
      "[320/600] Loss: 0.0205 MAE: 0.0326 Mean Error: -0.0117 STD: 0.1429\n",
      "[330/600] Loss: 0.0205 MAE: 0.0326 Mean Error: -0.0117 STD: 0.1429\n",
      "[340/600] Loss: 0.0205 MAE: 0.0326 Mean Error: -0.0117 STD: 0.1429\n",
      "[350/600] Loss: 0.0205 MAE: 0.0326 Mean Error: -0.0117 STD: 0.1429\n",
      "[360/600] Loss: 0.0205 MAE: 0.0326 Mean Error: -0.0117 STD: 0.1429\n",
      "[370/600] Loss: 0.0205 MAE: 0.0326 Mean Error: -0.0117 STD: 0.1429\n",
      "[380/600] Loss: 0.0205 MAE: 0.0326 Mean Error: -0.0117 STD: 0.1429\n",
      "[390/600] Loss: 0.0205 MAE: 0.0326 Mean Error: -0.0117 STD: 0.1429\n",
      "[400/600] Loss: 0.0205 MAE: 0.0326 Mean Error: -0.0117 STD: 0.1429\n",
      "[410/600] Loss: 0.0205 MAE: 0.0326 Mean Error: -0.0117 STD: 0.1429\n",
      "[420/600] Loss: 0.0205 MAE: 0.0326 Mean Error: -0.0117 STD: 0.1429\n",
      "[430/600] Loss: 0.0205 MAE: 0.0326 Mean Error: -0.0117 STD: 0.1429\n",
      "[440/600] Loss: 0.0205 MAE: 0.0326 Mean Error: -0.0117 STD: 0.1429\n",
      "[450/600] Loss: 0.0205 MAE: 0.0326 Mean Error: -0.0117 STD: 0.1429\n",
      "[460/600] Loss: 0.0205 MAE: 0.0326 Mean Error: -0.0117 STD: 0.1429\n",
      "[470/600] Loss: 0.0205 MAE: 0.0326 Mean Error: -0.0117 STD: 0.1429\n",
      "[480/600] Loss: 0.0205 MAE: 0.0326 Mean Error: -0.0117 STD: 0.1429\n",
      "[490/600] Loss: 0.0205 MAE: 0.0326 Mean Error: -0.0117 STD: 0.1429\n",
      "[500/600] Loss: 0.0205 MAE: 0.0326 Mean Error: -0.0117 STD: 0.1429\n",
      "[510/600] Loss: 0.0205 MAE: 0.0326 Mean Error: -0.0117 STD: 0.1429\n",
      "[520/600] Loss: 0.0205 MAE: 0.0326 Mean Error: -0.0117 STD: 0.1429\n",
      "[530/600] Loss: 0.0205 MAE: 0.0326 Mean Error: -0.0117 STD: 0.1429\n",
      "[540/600] Loss: 0.0205 MAE: 0.0326 Mean Error: -0.0117 STD: 0.1429\n",
      "[550/600] Loss: 0.0205 MAE: 0.0326 Mean Error: -0.0117 STD: 0.1429\n",
      "[560/600] Loss: 0.0205 MAE: 0.0326 Mean Error: -0.0117 STD: 0.1429\n",
      "[570/600] Loss: 0.0205 MAE: 0.0326 Mean Error: -0.0117 STD: 0.1429\n",
      "[580/600] Loss: 0.0205 MAE: 0.0326 Mean Error: -0.0117 STD: 0.1429\n",
      "[590/600] Loss: 0.0205 MAE: 0.0326 Mean Error: -0.0117 STD: 0.1429\n",
      "[599/600] Loss: 0.0205 MAE: 0.0326 Mean Error: -0.0117 STD: 0.1429\n",
      "------------------------------------\n",
      "Training dataset with noise standard deviation 0.05\n",
      "[0/600] Loss: 0.0208 MAE: 0.0397 Mean Error: -0.0187 STD: 0.1432\n",
      "[10/600] Loss: 0.0208 MAE: 0.0397 Mean Error: -0.0187 STD: 0.1432\n",
      "[20/600] Loss: 0.0208 MAE: 0.0397 Mean Error: -0.0187 STD: 0.1432\n",
      "[30/600] Loss: 0.0208 MAE: 0.0397 Mean Error: -0.0187 STD: 0.1432\n",
      "[40/600] Loss: 0.0208 MAE: 0.0397 Mean Error: -0.0187 STD: 0.1432\n",
      "[50/600] Loss: 0.0208 MAE: 0.0397 Mean Error: -0.0187 STD: 0.1432\n",
      "[60/600] Loss: 0.0208 MAE: 0.0397 Mean Error: -0.0187 STD: 0.1432\n",
      "[70/600] Loss: 0.0208 MAE: 0.0397 Mean Error: -0.0187 STD: 0.1432\n",
      "[80/600] Loss: 0.0208 MAE: 0.0397 Mean Error: -0.0187 STD: 0.1432\n",
      "[90/600] Loss: 0.0208 MAE: 0.0397 Mean Error: -0.0187 STD: 0.1432\n",
      "[100/600] Loss: 0.0208 MAE: 0.0397 Mean Error: -0.0187 STD: 0.1432\n",
      "[110/600] Loss: 0.0208 MAE: 0.0397 Mean Error: -0.0187 STD: 0.1432\n",
      "[120/600] Loss: 0.0208 MAE: 0.0397 Mean Error: -0.0187 STD: 0.1432\n",
      "[130/600] Loss: 0.0208 MAE: 0.0397 Mean Error: -0.0187 STD: 0.1432\n",
      "[140/600] Loss: 0.0208 MAE: 0.0397 Mean Error: -0.0187 STD: 0.1432\n",
      "[150/600] Loss: 0.0208 MAE: 0.0397 Mean Error: -0.0187 STD: 0.1432\n",
      "[160/600] Loss: 0.0208 MAE: 0.0397 Mean Error: -0.0187 STD: 0.1432\n",
      "[170/600] Loss: 0.0208 MAE: 0.0397 Mean Error: -0.0187 STD: 0.1432\n",
      "[180/600] Loss: 0.0208 MAE: 0.0397 Mean Error: -0.0187 STD: 0.1432\n",
      "[190/600] Loss: 0.0208 MAE: 0.0397 Mean Error: -0.0187 STD: 0.1432\n",
      "[200/600] Loss: 0.0208 MAE: 0.0397 Mean Error: -0.0187 STD: 0.1432\n",
      "[210/600] Loss: 0.0208 MAE: 0.0397 Mean Error: -0.0187 STD: 0.1432\n",
      "[220/600] Loss: 0.0208 MAE: 0.0397 Mean Error: -0.0187 STD: 0.1432\n",
      "[230/600] Loss: 0.0208 MAE: 0.0397 Mean Error: -0.0187 STD: 0.1432\n",
      "[240/600] Loss: 0.0208 MAE: 0.0397 Mean Error: -0.0187 STD: 0.1432\n",
      "[250/600] Loss: 0.0208 MAE: 0.0397 Mean Error: -0.0187 STD: 0.1432\n",
      "[260/600] Loss: 0.0208 MAE: 0.0397 Mean Error: -0.0187 STD: 0.1432\n",
      "[270/600] Loss: 0.0208 MAE: 0.0397 Mean Error: -0.0187 STD: 0.1432\n",
      "[280/600] Loss: 0.0208 MAE: 0.0397 Mean Error: -0.0187 STD: 0.1432\n",
      "[290/600] Loss: 0.0208 MAE: 0.0397 Mean Error: -0.0187 STD: 0.1432\n",
      "[300/600] Loss: 0.0208 MAE: 0.0397 Mean Error: -0.0187 STD: 0.1432\n",
      "[310/600] Loss: 0.0208 MAE: 0.0397 Mean Error: -0.0187 STD: 0.1432\n",
      "[320/600] Loss: 0.0208 MAE: 0.0397 Mean Error: -0.0187 STD: 0.1432\n",
      "[330/600] Loss: 0.0208 MAE: 0.0397 Mean Error: -0.0187 STD: 0.1432\n",
      "[340/600] Loss: 0.0208 MAE: 0.0397 Mean Error: -0.0187 STD: 0.1432\n",
      "[350/600] Loss: 0.0208 MAE: 0.0397 Mean Error: -0.0187 STD: 0.1432\n",
      "[360/600] Loss: 0.0208 MAE: 0.0397 Mean Error: -0.0187 STD: 0.1432\n",
      "[370/600] Loss: 0.0208 MAE: 0.0397 Mean Error: -0.0187 STD: 0.1432\n",
      "[380/600] Loss: 0.0208 MAE: 0.0397 Mean Error: -0.0187 STD: 0.1432\n",
      "[390/600] Loss: 0.0208 MAE: 0.0397 Mean Error: -0.0187 STD: 0.1432\n",
      "[400/600] Loss: 0.0208 MAE: 0.0397 Mean Error: -0.0187 STD: 0.1432\n",
      "[410/600] Loss: 0.0208 MAE: 0.0397 Mean Error: -0.0187 STD: 0.1432\n",
      "[420/600] Loss: 0.0208 MAE: 0.0397 Mean Error: -0.0187 STD: 0.1432\n",
      "[430/600] Loss: 0.0208 MAE: 0.0397 Mean Error: -0.0187 STD: 0.1432\n",
      "[440/600] Loss: 0.0208 MAE: 0.0397 Mean Error: -0.0187 STD: 0.1432\n",
      "[450/600] Loss: 0.0208 MAE: 0.0397 Mean Error: -0.0187 STD: 0.1432\n",
      "[460/600] Loss: 0.0208 MAE: 0.0397 Mean Error: -0.0187 STD: 0.1432\n",
      "[470/600] Loss: 0.0208 MAE: 0.0397 Mean Error: -0.0187 STD: 0.1432\n",
      "[480/600] Loss: 0.0208 MAE: 0.0397 Mean Error: -0.0187 STD: 0.1432\n",
      "[490/600] Loss: 0.0208 MAE: 0.0397 Mean Error: -0.0187 STD: 0.1432\n",
      "[500/600] Loss: 0.0208 MAE: 0.0397 Mean Error: -0.0187 STD: 0.1432\n",
      "[510/600] Loss: 0.0208 MAE: 0.0397 Mean Error: -0.0187 STD: 0.1432\n",
      "[520/600] Loss: 0.0208 MAE: 0.0397 Mean Error: -0.0187 STD: 0.1432\n",
      "[530/600] Loss: 0.0208 MAE: 0.0397 Mean Error: -0.0187 STD: 0.1432\n",
      "[540/600] Loss: 0.0208 MAE: 0.0397 Mean Error: -0.0187 STD: 0.1432\n",
      "[550/600] Loss: 0.0208 MAE: 0.0397 Mean Error: -0.0187 STD: 0.1432\n",
      "[560/600] Loss: 0.0208 MAE: 0.0397 Mean Error: -0.0187 STD: 0.1432\n",
      "[570/600] Loss: 0.0208 MAE: 0.0397 Mean Error: -0.0187 STD: 0.1432\n",
      "[580/600] Loss: 0.0208 MAE: 0.0397 Mean Error: -0.0187 STD: 0.1432\n",
      "[590/600] Loss: 0.0208 MAE: 0.0397 Mean Error: -0.0187 STD: 0.1432\n",
      "[599/600] Loss: 0.0208 MAE: 0.0397 Mean Error: -0.0187 STD: 0.1432\n",
      "------------------------------------\n",
      "Training dataset with noise standard deviation 0.1\n",
      "[0/600] Loss: 0.0236 MAE: 0.0590 Mean Error: -0.0352 STD: 0.1496\n",
      "[10/600] Loss: 0.0236 MAE: 0.0590 Mean Error: -0.0352 STD: 0.1496\n",
      "[20/600] Loss: 0.0236 MAE: 0.0590 Mean Error: -0.0352 STD: 0.1496\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30/600] Loss: 0.0236 MAE: 0.0590 Mean Error: -0.0352 STD: 0.1496\n",
      "[40/600] Loss: 0.0236 MAE: 0.0590 Mean Error: -0.0352 STD: 0.1496\n",
      "[50/600] Loss: 0.0236 MAE: 0.0590 Mean Error: -0.0352 STD: 0.1496\n",
      "[60/600] Loss: 0.0236 MAE: 0.0590 Mean Error: -0.0352 STD: 0.1496\n",
      "[70/600] Loss: 0.0236 MAE: 0.0590 Mean Error: -0.0352 STD: 0.1496\n",
      "[80/600] Loss: 0.0236 MAE: 0.0590 Mean Error: -0.0352 STD: 0.1496\n",
      "[90/600] Loss: 0.0236 MAE: 0.0590 Mean Error: -0.0352 STD: 0.1496\n",
      "[100/600] Loss: 0.0236 MAE: 0.0590 Mean Error: -0.0352 STD: 0.1496\n",
      "[110/600] Loss: 0.0236 MAE: 0.0590 Mean Error: -0.0352 STD: 0.1496\n",
      "[120/600] Loss: 0.0236 MAE: 0.0590 Mean Error: -0.0352 STD: 0.1496\n",
      "[130/600] Loss: 0.0236 MAE: 0.0590 Mean Error: -0.0352 STD: 0.1496\n",
      "[140/600] Loss: 0.0236 MAE: 0.0590 Mean Error: -0.0352 STD: 0.1496\n",
      "[150/600] Loss: 0.0236 MAE: 0.0590 Mean Error: -0.0352 STD: 0.1496\n",
      "[160/600] Loss: 0.0236 MAE: 0.0590 Mean Error: -0.0352 STD: 0.1496\n",
      "[170/600] Loss: 0.0236 MAE: 0.0590 Mean Error: -0.0352 STD: 0.1496\n",
      "[180/600] Loss: 0.0236 MAE: 0.0590 Mean Error: -0.0352 STD: 0.1496\n",
      "[190/600] Loss: 0.0236 MAE: 0.0590 Mean Error: -0.0352 STD: 0.1496\n",
      "[200/600] Loss: 0.0236 MAE: 0.0590 Mean Error: -0.0352 STD: 0.1496\n",
      "[210/600] Loss: 0.0236 MAE: 0.0590 Mean Error: -0.0352 STD: 0.1496\n",
      "[220/600] Loss: 0.0236 MAE: 0.0590 Mean Error: -0.0352 STD: 0.1496\n",
      "[230/600] Loss: 0.0236 MAE: 0.0590 Mean Error: -0.0352 STD: 0.1496\n",
      "[240/600] Loss: 0.0236 MAE: 0.0590 Mean Error: -0.0352 STD: 0.1496\n",
      "[250/600] Loss: 0.0236 MAE: 0.0590 Mean Error: -0.0352 STD: 0.1496\n",
      "[260/600] Loss: 0.0236 MAE: 0.0590 Mean Error: -0.0352 STD: 0.1496\n",
      "[270/600] Loss: 0.0236 MAE: 0.0590 Mean Error: -0.0352 STD: 0.1496\n",
      "[280/600] Loss: 0.0236 MAE: 0.0590 Mean Error: -0.0352 STD: 0.1496\n",
      "[290/600] Loss: 0.0236 MAE: 0.0590 Mean Error: -0.0352 STD: 0.1496\n",
      "[300/600] Loss: 0.0236 MAE: 0.0590 Mean Error: -0.0352 STD: 0.1496\n",
      "[310/600] Loss: 0.0236 MAE: 0.0590 Mean Error: -0.0352 STD: 0.1496\n",
      "[320/600] Loss: 0.0236 MAE: 0.0590 Mean Error: -0.0352 STD: 0.1496\n",
      "[330/600] Loss: 0.0236 MAE: 0.0590 Mean Error: -0.0352 STD: 0.1496\n",
      "[340/600] Loss: 0.0236 MAE: 0.0590 Mean Error: -0.0352 STD: 0.1496\n",
      "[350/600] Loss: 0.0236 MAE: 0.0590 Mean Error: -0.0352 STD: 0.1496\n",
      "[360/600] Loss: 0.0236 MAE: 0.0590 Mean Error: -0.0352 STD: 0.1496\n",
      "[370/600] Loss: 0.0236 MAE: 0.0590 Mean Error: -0.0352 STD: 0.1496\n",
      "[380/600] Loss: 0.0236 MAE: 0.0590 Mean Error: -0.0352 STD: 0.1496\n",
      "[390/600] Loss: 0.0236 MAE: 0.0590 Mean Error: -0.0352 STD: 0.1496\n",
      "[400/600] Loss: 0.0236 MAE: 0.0590 Mean Error: -0.0352 STD: 0.1496\n",
      "[410/600] Loss: 0.0236 MAE: 0.0590 Mean Error: -0.0352 STD: 0.1496\n",
      "[420/600] Loss: 0.0236 MAE: 0.0590 Mean Error: -0.0352 STD: 0.1496\n",
      "[430/600] Loss: 0.0236 MAE: 0.0590 Mean Error: -0.0352 STD: 0.1496\n",
      "[440/600] Loss: 0.0236 MAE: 0.0590 Mean Error: -0.0352 STD: 0.1496\n",
      "[450/600] Loss: 0.0236 MAE: 0.0590 Mean Error: -0.0352 STD: 0.1496\n",
      "[460/600] Loss: 0.0236 MAE: 0.0590 Mean Error: -0.0352 STD: 0.1496\n",
      "[470/600] Loss: 0.0236 MAE: 0.0590 Mean Error: -0.0352 STD: 0.1496\n",
      "[480/600] Loss: 0.0236 MAE: 0.0590 Mean Error: -0.0352 STD: 0.1496\n",
      "[490/600] Loss: 0.0236 MAE: 0.0590 Mean Error: -0.0352 STD: 0.1496\n",
      "[500/600] Loss: 0.0236 MAE: 0.0590 Mean Error: -0.0352 STD: 0.1496\n",
      "[510/600] Loss: 0.0236 MAE: 0.0590 Mean Error: -0.0352 STD: 0.1496\n",
      "[520/600] Loss: 0.0236 MAE: 0.0590 Mean Error: -0.0352 STD: 0.1496\n",
      "[530/600] Loss: 0.0236 MAE: 0.0590 Mean Error: -0.0352 STD: 0.1496\n",
      "[540/600] Loss: 0.0236 MAE: 0.0590 Mean Error: -0.0352 STD: 0.1496\n",
      "[550/600] Loss: 0.0236 MAE: 0.0590 Mean Error: -0.0352 STD: 0.1496\n",
      "[560/600] Loss: 0.0236 MAE: 0.0590 Mean Error: -0.0352 STD: 0.1496\n",
      "[570/600] Loss: 0.0236 MAE: 0.0590 Mean Error: -0.0352 STD: 0.1496\n",
      "[580/600] Loss: 0.0236 MAE: 0.0590 Mean Error: -0.0352 STD: 0.1496\n",
      "[590/600] Loss: 0.0236 MAE: 0.0590 Mean Error: -0.0352 STD: 0.1496\n",
      "[599/600] Loss: 0.0236 MAE: 0.0590 Mean Error: -0.0352 STD: 0.1496\n",
      "------------------------------------\n",
      "------------Fh_noise_array------------\n",
      "[[0.91666667 0.83333333 0.87878788 0.85106383 0.85483871 0.875\n",
      "  0.87058824 0.86666667 0.88349515 0.8974359 ]\n",
      " [0.86666667 0.7826087  0.80645161 0.83333333 0.83636364 0.8358209\n",
      "  0.84146341 0.83146067 0.84313725 0.84955752]\n",
      " [0.9        0.875      0.86206897 0.8372093  0.84       0.85\n",
      "  0.85135135 0.85542169 0.86868687 0.86725664]\n",
      " [0.85714286 0.8        0.82142857 0.85       0.85964912 0.88059701\n",
      "  0.8961039  0.90361446 0.91304348 0.90384615]\n",
      " [0.84615385 0.80952381 0.87878788 0.86363636 0.86792453 0.84126984\n",
      "  0.81578947 0.81176471 0.84313725 0.84482759]\n",
      " [0.85714286 0.85714286 0.875      0.88571429 0.89361702 0.87931034\n",
      "  0.84057971 0.82051282 0.84615385 0.85294118]\n",
      " [0.90909091 0.8        0.82142857 0.86842105 0.89130435 0.89473684\n",
      "  0.88888889 0.86904762 0.87755102 0.88288288]\n",
      " [0.92307692 0.88235294 0.92307692 0.9        0.89795918 0.89830508\n",
      "  0.86666667 0.85542169 0.88235294 0.88235294]\n",
      " [0.9        0.92307692 0.96296296 0.97222222 0.97959184 0.95081967\n",
      "  0.93243243 0.91463415 0.91578947 0.90740741]]\n",
      "------------Ffa_noise_array------------\n",
      "[[0.00970874 0.03070175 0.01988636 0.01698514 0.01346801 0.01282051\n",
      "  0.01118012 0.01300108 0.01166181 0.01041667]\n",
      " [0.00826446 0.0242915  0.01657459 0.01677149 0.01686341 0.01551481\n",
      "  0.01445783 0.01605996 0.01434034 0.01290878]\n",
      " [0.         0.01680672 0.01139601 0.01287554 0.01211073 0.01136364\n",
      "  0.01215067 0.01162791 0.01032864 0.00927487]\n",
      " [0.         0.01731602 0.01142857 0.0106383  0.00856164 0.00718391\n",
      "  0.00619579 0.00764192 0.00673725 0.00605013]\n",
      " [0.00900901 0.01754386 0.01142857 0.01068376 0.01333333 0.01265823\n",
      "  0.01230012 0.01375661 0.01232227 0.0113438 ]\n",
      " [0.         0.0167364  0.01120448 0.00860215 0.01052632 0.00882353\n",
      "  0.00754717 0.00983607 0.00873786 0.00784656]\n",
      " [0.         0.01877934 0.01173021 0.01094092 0.01041667 0.01020408\n",
      "  0.00998752 0.01077586 0.00956023 0.00857633]\n",
      " [0.0078125  0.01532567 0.01072386 0.01419878 0.01145663 0.01075269\n",
      "  0.00936768 0.01022495 0.00915751 0.00829187]\n",
      " [0.01724138 0.03673469 0.02549575 0.02155172 0.01880342 0.01564723\n",
      "  0.01575758 0.01685985 0.01489758 0.01351351]]\n"
     ]
    }
   ],
   "source": [
    "# Step 5\n",
    "def gaussian_noise(img, mean, sigma):\n",
    "    # Generate gauss noise\n",
    "    noise = np.random.normal(mean, sigma, img.shape)\n",
    "    # Add the noise to image\n",
    "    gaussian_out = img + noise\n",
    "    # Make the value between 0 and 1\n",
    "    gaussian_out = np.clip(gaussian_out, 0, 1)\n",
    "    return gaussian_out\n",
    "\n",
    "gaussian_dataset = np.zeros([9, 10, 256])\n",
    "std = [0.001, 0.002, 0.003, 0.005, 0.01, 0.02, 0.03, 0.05, 0.1]\n",
    "if not os.path.exists('./input_noise/'):\n",
    "    os.mkdir('./input_noise/')\n",
    "for j in range(9):\n",
    "    if not os.path.exists('./input_noise/' + str(std[j])):\n",
    "        os.mkdir('./input_noise/' + str(std[j]))\n",
    "    for i in range(10):\n",
    "        inputImage = dataSet[i]\n",
    "        gaussian_data = gaussian_noise(inputImage, 0, std[j])\n",
    "        img = gaussian_data.reshape(16, 16)*255\n",
    "        img = Image.fromarray(np.uint8(img))\n",
    "        img.convert(\"1\")\n",
    "        inputImageDir = './input_noise/' + str(std[j]) + '/' + str(i) + '.png'\n",
    "        img.save(inputImageDir)\n",
    "        gaussian_dataset[j][i] = gaussian_data\n",
    "gaussian_dataset = np.array(gaussian_dataset)\n",
    "\n",
    "\n",
    "Fh_noise_array = np.zeros([9, 10])\n",
    "Ffa_noise_array = np.zeros([9, 10])\n",
    "\n",
    "# Train 9 datasets with noise\n",
    "if not os.path.exists('./output_noise/'):\n",
    "    os.mkdir('./output_noise/')\n",
    "for j in range(9):\n",
    "    train_noise_dataset = DigitDataset(dataset = gaussian_dataset[j], label_list = gaussian_dataset[j])\n",
    "    train_noise_loader = DataLoader(dataset=train_noise_dataset, batch_size=batch_size, shuffle=False)\n",
    "    print('Training dataset with noise standard deviation ' + str(std[j]))\n",
    "    model_noise = torch.load('net.pkl') #  Load the model that trained before\n",
    "    output_noise = train(train_noise_loader, model_noise, num_epochs)   # Train\n",
    "    output_noise = model_noise(torch.from_numpy(gaussian_dataset[j]).float()) # Use the model trained before to test\n",
    "    print('------------------------------------')\n",
    "    output_noise_np = output_noise.cpu().detach().numpy()     # Get the output\n",
    "    output_noise_dataset = np.zeros([10, 256])\n",
    "#     Make the output only has 0 or 1\n",
    "    if not os.path.exists('./output_noise/' + str(std[j])):\n",
    "        os.mkdir('./output_noise/' + str(std[j]))\n",
    "    for i in range(10):\n",
    "        output_noise_img = output_noise_np[i].reshape(16, 16)*255\n",
    "        img = Image.fromarray(np.uint8(output_noise_img))\n",
    "        img = img.convert(\"1\")\n",
    "        output_path = './output_noise/' + str(std[j]) + '/' + str(i) + '.png'\n",
    "        img.save(output_path)\n",
    "        data = img.getdata()\n",
    "        array = np.array(data)/255\n",
    "        output_noise_dataset[i] = array\n",
    "#     Calculate Fh and Ffa\n",
    "    Fh = calculateFh(gaussian_dataset[j], output_noise_dataset)\n",
    "    Ffa = calculateFfa(gaussian_dataset[j], output_noise_dataset)\n",
    "    Fh_noise_array[j] = Fh\n",
    "    Ffa_noise_array[j] = Ffa\n",
    "print('------------Fh_noise_array------------')\n",
    "print(Fh_noise_array)\n",
    "print('------------Ffa_noise_array------------')\n",
    "print(Ffa_noise_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dd78210",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Step 6: Display Data from your Tests in Step 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e584ac1e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
